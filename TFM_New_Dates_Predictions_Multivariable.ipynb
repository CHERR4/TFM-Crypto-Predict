{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFM-New-Dates-Predictions-Multivariable",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPY-KHb7ysv7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca3f804-16cd-470b-f6bc-46a23a227f9d"
      },
      "source": [
        "!pip install --upgrade matplotlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.4.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We5POU4by3Xh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.random import seed"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSfjApBpy4a2"
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(0)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2F5fvG9y6aX"
      },
      "source": [
        "stocks = pd.read_csv('stocks.csv', index_col=0)\n",
        "new_stocks = pd.read_csv('actualStocks.csv', index_col=0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "xyjjAoN9zF74",
        "outputId": "385a8429-bb55-4a84-c4a4-9b0c1975b77c"
      },
      "source": [
        "stocks.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>btcClose</th>\n",
              "      <th>ethClose</th>\n",
              "      <th>adaClose</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-10-01</th>\n",
              "      <td>4403.740234</td>\n",
              "      <td>302.337006</td>\n",
              "      <td>0.024969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-10-02</th>\n",
              "      <td>4409.319824</td>\n",
              "      <td>297.475006</td>\n",
              "      <td>0.025932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-10-03</th>\n",
              "      <td>4317.479980</td>\n",
              "      <td>292.463013</td>\n",
              "      <td>0.020816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-10-04</th>\n",
              "      <td>4229.359863</td>\n",
              "      <td>292.657990</td>\n",
              "      <td>0.021931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-10-05</th>\n",
              "      <td>4328.410156</td>\n",
              "      <td>295.863007</td>\n",
              "      <td>0.021489</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               btcClose    ethClose  adaClose\n",
              "date                                         \n",
              "2017-10-01  4403.740234  302.337006  0.024969\n",
              "2017-10-02  4409.319824  297.475006  0.025932\n",
              "2017-10-03  4317.479980  292.463013  0.020816\n",
              "2017-10-04  4229.359863  292.657990  0.021931\n",
              "2017-10-05  4328.410156  295.863007  0.021489"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "itfPrYemzL1s",
        "outputId": "b71c305a-0033-4fcf-dee5-1d97ac06d2af"
      },
      "source": [
        "new_stocks.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>btcClose</th>\n",
              "      <th>ethClose</th>\n",
              "      <th>adaClose</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-07-13</th>\n",
              "      <td>32702.025391</td>\n",
              "      <td>1940.083984</td>\n",
              "      <td>1.265083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-14</th>\n",
              "      <td>32822.347656</td>\n",
              "      <td>1994.331299</td>\n",
              "      <td>1.262258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-15</th>\n",
              "      <td>31780.730469</td>\n",
              "      <td>1911.175659</td>\n",
              "      <td>1.223192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-16</th>\n",
              "      <td>31421.539063</td>\n",
              "      <td>1880.382935</td>\n",
              "      <td>1.173715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-17</th>\n",
              "      <td>31533.068359</td>\n",
              "      <td>1898.825195</td>\n",
              "      <td>1.172302</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                btcClose     ethClose  adaClose\n",
              "date                                           \n",
              "2021-07-13  32702.025391  1940.083984  1.265083\n",
              "2021-07-14  32822.347656  1994.331299  1.262258\n",
              "2021-07-15  31780.730469  1911.175659  1.223192\n",
              "2021-07-16  31421.539063  1880.382935  1.173715\n",
              "2021-07-17  31533.068359  1898.825195  1.172302"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_ZWMQ9LSf2I",
        "outputId": "2298a024-2f47-45ce-c4aa-95158a02b587"
      },
      "source": [
        "monovariable_stocks = stocks['btcClose']\n",
        "monovariable_new_stocks = stocks['btcClose']\n",
        "monovariable_stocks.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date\n",
              "2017-10-01    4403.740234\n",
              "2017-10-02    4409.319824\n",
              "2017-10-03    4317.479980\n",
              "2017-10-04    4229.359863\n",
              "2017-10-05    4328.410156\n",
              "Name: btcClose, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRmOkeh6zofr"
      },
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def build_prediction_dataframe(training_ts, predictions_ts):\n",
        "  last_training_predictions = [training_ts.tail(1), predictions_ts]\n",
        "  last_training_predictions_ts = pd.concat(last_training_predictions)\n",
        "  last_training_predictions_df = last_training_predictions_ts.reset_index()\n",
        "  last_training_predictions_df['positive_delta'] = last_training_predictions_df.apply(lambda row: row.name > 0 and last_training_predictions_df.loc[row.name-1, :][last_training_predictions_df.columns[1]] < row[last_training_predictions_df.columns[1]], axis=1)\n",
        "  predictions_df = last_training_predictions_df.iloc[1: , :][['positive_delta']]\n",
        "  return predictions_df\n",
        "\n",
        "def add_row_confusion_matrix(list_of_cm, df_row):\n",
        "  row = 0\n",
        "  column = 0\n",
        "  if df_row.positive_delta_predict:\n",
        "    column = 1\n",
        "  if df_row.positive_delta_actual:\n",
        "    row = 1\n",
        "  list_of_cm[df_row.name-1][row, column] += 1\n",
        "  return list_of_cm\n",
        "\n",
        "def evaluate(model, train_ts, test_ts, n_evaluations=10, n_test=3, n_steps=1, n_epochs=100, batch_size=16, full_test=False):\n",
        "  total_hits = 0\n",
        "  total_tries = 0\n",
        "  confusion_matrix = [np.zeros((2,2)), np.zeros((2,2)), np.zeros((2,2))]\n",
        "  print('Training on train_ts')\n",
        "  # This line is to replicate the other script\n",
        "\n",
        "  model.train(train_ts, n_epochs, batch_size)\n",
        "\n",
        "  print('Iteration 1 started on test')\n",
        "  steps_to_predict = test_ts[:n_steps]\n",
        "  steps_result = test_ts[n_steps:n_steps+n_test]\n",
        "  if full_test:\n",
        "    i=1\n",
        "    while n_steps + (n_test * i) < len(test_ts):\n",
        "      steps_to_predict_model = pd.concat([steps_to_predict, steps_result])\n",
        "      predictions = model.predict(steps_to_predict_model)\n",
        "      predictions = predictions.reshape(predictions.shape[0])\n",
        "      predictions_ts = pd.DataFrame({steps_to_predict.columns[0]: predictions}, steps_result.index)\n",
        "\n",
        "      predictions_df = build_prediction_dataframe(steps_to_predict, predictions_ts)\n",
        "      predictions_df.rename(columns={'positive_delta': 'positive_delta_predict'}, inplace=True)\n",
        "\n",
        "      test_df = build_prediction_dataframe(steps_to_predict, steps_result)\n",
        "      test_df.rename(columns={'positive_delta': 'positive_delta_actual'}, inplace=True)\n",
        "\n",
        "      predictions_and_test = pd.concat([test_df, predictions_df], axis=1)\n",
        "      predictions_and_test['equal'] = predictions_and_test.apply(lambda row: row['positive_delta_actual'] == row['positive_delta_predict'], axis=1)\n",
        "      predictions_and_test.apply(lambda row: add_row_confusion_matrix(confusion_matrix, row), axis=1)\n",
        "\n",
        "      hits = predictions_and_test['equal'].sum()\n",
        "      print('Accuracy: {}/{}'.format(hits, predictions_and_test.shape[0]))\n",
        "      total_hits += hits\n",
        "      total_tries += predictions_and_test.shape[0]\n",
        "\n",
        "      print('Iteration {} started'.format(i))\n",
        "      new_train = pd.concat([steps_to_predict, steps_result])\n",
        "      model.retrain(new_train, epochs=1, batch_size=len(new_train), validation_split=0)\n",
        "      steps_to_predict = test_ts[(n_test * (i-1)):n_steps + (n_test * (i-1))]\n",
        "      steps_result = test_ts[n_steps + (n_test * (i-1)):n_steps + (n_test * i)]\n",
        "      i+=1\n",
        "  else:\n",
        "    for i in reversed(range(1, n_evaluations + 1)):\n",
        "      print('Last training {} {}'.format(i, steps_to_predict))\n",
        "      steps_to_predict_model = pd.concat([steps_to_predict, steps_result])\n",
        "      predictions = model.predict(steps_to_predict_model)\n",
        "      predictions = predictions.reshape(predictions.shape[0])\n",
        "      predictions_ts = pd.DataFrame({steps_to_predict.columns[0]: predictions}, test_evaluate.index)\n",
        "      \n",
        "      predictions_df = build_prediction_dataframe(steps_to_predict, predictions_ts)\n",
        "      predictions_df.rename(columns={'positive_delta': 'positive_delta_predict'}, inplace=True)\n",
        "      \n",
        "      test_df = build_prediction_dataframe(steps_to_predict, steps_result)\n",
        "      test_df.rename(columns={'positive_delta': 'positive_delta_actual'}, inplace=True)\n",
        "\n",
        "      predictions_and_test = pd.concat([test_df, predictions_df], axis=1)\n",
        "      predictions_and_test['equal'] = predictions_and_test.apply(lambda row: row['positive_delta_actual'] == row['positive_delta_predict'], axis=1)\n",
        "      predictions_and_test.apply(lambda row: add_row_confusion_matrix(confusion_matrix, row), axis=1)\n",
        "\n",
        "      hits = predictions_and_test['equal'].sum()\n",
        "      print('Accuracy: {}/{}'.format(hits, predictions_and_test.shape[0]))\n",
        "      total_hits += hits\n",
        "      total_tries += predictions_and_test.shape[0]\n",
        "\n",
        "      print('Iteration {} started'.format(n_evaluations + 1 - i))\n",
        "      new_train = pd.concat([steps_to_predict, test_evaluate])\n",
        "      model.retrain(new_train, epochs=1, batch_size=len(new_train), validation_split=0)\n",
        "      steps_to_predict = new_train[-n_steps:]\n",
        "\n",
        "  print('Total hits: {}. Total tries: {}. Accuracy: {:0.2f}'.format(total_hits, total_tries, total_hits / total_tries))\n",
        "  \n",
        "  return confusion_matrix"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH6pIRYfzqiu"
      },
      "source": [
        "def plot_confusion_matrix(confusion_matrix):\n",
        "  fig, axs = plt.subplots(2, 2)\n",
        "  fig.supxlabel('Predicted')\n",
        "  fig.supylabel('Actual')\n",
        "  for i in range(0, len(confusion_matrix)):\n",
        "    ax = axs[int(i/2), i%2]\n",
        "    ax.title.set_text('Index {}'.format(i+1))\n",
        "    sns.heatmap(data=confusion_matrix[i], annot=True, cbar=False, ax=ax)\n",
        "  sum_cm = sum(confusion_matrix)\n",
        "  axs[1,1].title.set_text('Total')\n",
        "  sns.heatmap(data=sum_cm, annot=True, cbar=False, ax=axs[1,1])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itEojPe3eJpW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a3702f3-186e-45af-cd3d-e92b29ce3046"
      },
      "source": [
        "from VanillaMultivariableLSTM import VanillaLSTM\n",
        "from StackedMultivariableLSTM import StackedLSTM\n",
        "from BidirectionalMultivariableLSTM import BidirectionalLSTM\n",
        "from ConvMultivariableLSTM import ConvLSTM\n",
        "from CnnMultivariableLSTM import CnnLSTM\n",
        "\n",
        "n_outputs = 1\n",
        "n_features = 3\n",
        "n_evaluations = 10\n",
        "epochs = 50\n",
        "n_neurons = 30\n",
        "batch_size = 16\n",
        "n_steps = 5\n",
        "n_seed = 0\n",
        "optimizer = 'adam'\n",
        "loss = 'mean_squared_error'\n",
        "model_type = ConvLSTM\n",
        "\n",
        "seed(n_seed)\n",
        "tf.random.set_seed(n_seed)\n",
        "model = model_type(n_neurons=n_neurons,n_features=n_features, n_steps=n_steps, n_outputs=n_outputs, loss=loss, optimizer=optimizer)\n",
        "\n",
        "cm = evaluate(model, stocks, new_stocks, n_test=n_outputs, n_steps=n_steps, n_epochs=epochs, batch_size=batch_size, full_test=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_lst_m2d (ConvLSTM2D)    (None, 1, 4, 64)          34560     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 34,817\n",
            "Trainable params: 34,817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training on train_ts\n",
            "Epoch 1/50\n",
            "78/78 [==============================] - 3s 8ms/step - loss: 0.0119 - accuracy: 8.0775e-04 - val_loss: 0.0428 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 8.0775e-04 - val_loss: 0.0308 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 8.0208e-04 - accuracy: 8.0775e-04 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.6044e-04 - accuracy: 8.0775e-04 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.8815e-04 - accuracy: 8.0775e-04 - val_loss: 0.0102 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.7848e-04 - accuracy: 8.0775e-04 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.7811e-04 - accuracy: 8.0775e-04 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.5968e-04 - accuracy: 8.0775e-04 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.5314e-04 - accuracy: 8.0775e-04 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.5175e-04 - accuracy: 8.0775e-04 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4247e-04 - accuracy: 8.0775e-04 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.3720e-04 - accuracy: 8.0775e-04 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4438e-04 - accuracy: 8.0775e-04 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.2743e-04 - accuracy: 8.0775e-04 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4912e-04 - accuracy: 8.0775e-04 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.1884e-04 - accuracy: 8.0775e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.1869e-04 - accuracy: 8.0775e-04 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.1578e-04 - accuracy: 8.0775e-04 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.2382e-04 - accuracy: 8.0775e-04 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0517e-04 - accuracy: 8.0775e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9514e-04 - accuracy: 8.0775e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.1010e-04 - accuracy: 8.0775e-04 - val_loss: 0.0083 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0134e-04 - accuracy: 8.0775e-04 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0789e-04 - accuracy: 8.0775e-04 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9728e-04 - accuracy: 8.0775e-04 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9861e-04 - accuracy: 8.0775e-04 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.1395e-04 - accuracy: 8.0775e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0249e-04 - accuracy: 8.0775e-04 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9007e-04 - accuracy: 8.0775e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8550e-04 - accuracy: 8.0775e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9845e-04 - accuracy: 8.0775e-04 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8799e-04 - accuracy: 8.0775e-04 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.6944e-04 - accuracy: 8.0775e-04 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7564e-04 - accuracy: 8.0775e-04 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7202e-04 - accuracy: 8.0775e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.6626e-04 - accuracy: 8.0775e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.6848e-04 - accuracy: 8.0775e-04 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.6524e-04 - accuracy: 8.0775e-04 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.6481e-04 - accuracy: 8.0775e-04 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.5418e-04 - accuracy: 8.0775e-04 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.6370e-04 - accuracy: 8.0775e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9570e-04 - accuracy: 8.0775e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.5225e-04 - accuracy: 8.0775e-04 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.6505e-04 - accuracy: 8.0775e-04 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7468e-04 - accuracy: 8.0775e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.6899e-04 - accuracy: 8.0775e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.4976e-04 - accuracy: 8.0775e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.5276e-04 - accuracy: 8.0775e-04 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.5459e-04 - accuracy: 8.0775e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.5064e-04 - accuracy: 8.0775e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Iteration 1 started on test\n",
            "Accuracy: 0/1\n",
            "Iteration 1 started\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1170e-04 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 2 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6429e-07 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 3 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 4 started\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0897e-04 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 5 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 6 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.1259e-04 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 7 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0261e-04 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 8 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 9 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 10 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1540e-04 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 11 started\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 12 started\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2831e-05 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 13 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 14 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.7565e-06 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 15 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.2430e-04 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 16 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 17 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7413e-04 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 18 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 19 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 20 started\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 21 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.7479e-04 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 22 started\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0066 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 23 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0208 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 24 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 25 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.2981e-07 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 26 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 27 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 28 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 29 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 30 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.9297e-04 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 31 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 32 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 33 started\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8304e-05 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 34 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 35 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 36 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6909e-04 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 37 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0938e-04 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 38 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4764e-04 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 39 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 40 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.0000e+00\n",
            "Accuracy: 1/1\n",
            "Iteration 41 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6257e-04 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 42 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0082 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 43 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7191e-04 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 44 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0000e+00\n",
            "Accuracy: 0/1\n",
            "Iteration 45 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.0000e+00\n",
            "Total hits: 20. Total tries: 45. Accuracy: 0.44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "zGtyAcBALP_O",
        "outputId": "f459bdf8-436e-46a1-eb5d-1c97cd5905f8"
      },
      "source": [
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}