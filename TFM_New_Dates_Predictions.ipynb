{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFM-New-Dates-Predictions",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPY-KHb7ysv7",
        "outputId": "f1b6a1f7-cf03-4256-b9c8-83f298fd1636"
      },
      "source": [
        "!pip install --upgrade matplotlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (7.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We5POU4by3Xh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.random import seed"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSfjApBpy4a2"
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(0)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2F5fvG9y6aX"
      },
      "source": [
        "btc_stocks = pd.read_csv('btcStocks.csv')\n",
        "eth_stocks = pd.read_csv('ethStocks.csv')\n",
        "ada_stocks = pd.read_csv('adaStocks.csv')\n",
        "\n",
        "btc_new_stocks = pd.read_csv('btcActualStocks.csv')\n",
        "eth_new_stocks = pd.read_csv('ethActualStocks.csv')\n",
        "ada_new_stocks = pd.read_csv('adaActualStocks.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xyjjAoN9zF74",
        "outputId": "3a59c5a6-f100-425c-b31a-eb563ade392a"
      },
      "source": [
        "btc_stocks_close = btc_stocks.close\n",
        "btc_stocks_close = btc_stocks_close.to_frame()\n",
        "btc_stocks_close.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>457.334015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>424.440002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>394.795990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>408.903992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>398.821014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        close\n",
              "0  457.334015\n",
              "1  424.440002\n",
              "2  394.795990\n",
              "3  408.903992\n",
              "4  398.821014"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "itfPrYemzL1s",
        "outputId": "869fda7e-3b26-4077-f8e3-e431f34fb773"
      },
      "source": [
        "btc_new_stocks_close = btc_new_stocks.close\n",
        "btc_new_stocks_close = btc_new_stocks_close.to_frame()\n",
        "btc_new_stocks_close.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32702.025391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32822.347656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31780.730469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31421.539063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31533.068359</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          close\n",
              "0  32702.025391\n",
              "1  32822.347656\n",
              "2  31780.730469\n",
              "3  31421.539063\n",
              "4  31533.068359"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-Ni-_XgtzKK1",
        "outputId": "7517eefe-7d8f-439f-e4f5-17d88b6bbb40"
      },
      "source": [
        "eth_stocks_close = eth_stocks.close\n",
        "eth_stocks_close = eth_stocks_close.to_frame()\n",
        "eth_stocks_close.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.772120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.753325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.701897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.708448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.067860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      close\n",
              "0  2.772120\n",
              "1  0.753325\n",
              "2  0.701897\n",
              "3  0.708448\n",
              "4  1.067860"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yFuhs_CZzVEf",
        "outputId": "81fc0271-8900-43ac-97ff-e67332227c8c"
      },
      "source": [
        "eth_new_stocks_close = eth_new_stocks.close\n",
        "eth_new_stocks_close = eth_new_stocks_close.to_frame()\n",
        "eth_new_stocks_close.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1940.083984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1994.331299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1911.175659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1880.382935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1898.825195</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         close\n",
              "0  1940.083984\n",
              "1  1994.331299\n",
              "2  1911.175659\n",
              "3  1880.382935\n",
              "4  1898.825195"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "apuG_v3rzcbO",
        "outputId": "e814909e-93a8-43b0-a829-9391d593aaeb"
      },
      "source": [
        "ada_stocks_close = ada_stocks.close\n",
        "ada_stocks_close = ada_stocks_close.to_frame()\n",
        "ada_stocks_close.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.024969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.025932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.020816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.021931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.021489</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      close\n",
              "0  0.024969\n",
              "1  0.025932\n",
              "2  0.020816\n",
              "3  0.021931\n",
              "4  0.021489"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6qoAIjuRzeIQ",
        "outputId": "1c421888-371a-444c-d25c-8dcaf070b3ac"
      },
      "source": [
        "ada_new_stocks_close = ada_new_stocks.close\n",
        "ada_new_stocks_close = ada_new_stocks_close.to_frame()\n",
        "ada_new_stocks_close.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.265083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.262258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.223192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.173715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.172302</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      close\n",
              "0  1.265083\n",
              "1  1.262258\n",
              "2  1.223192\n",
              "3  1.173715\n",
              "4  1.172302"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRmOkeh6zofr"
      },
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def build_prediction_dataframe(training_ts, predictions_ts):\n",
        "  last_training_predictions = [training_ts.tail(1), predictions_ts]\n",
        "  last_training_predictions_ts = pd.concat(last_training_predictions)\n",
        "  last_training_predictions_df = last_training_predictions_ts.reset_index()\n",
        "  last_training_predictions_df['positive_delta'] = last_training_predictions_df.apply(lambda row: row.name > 0 and last_training_predictions_df.loc[row.name-1, :]['close'] < row['close'], axis=1)\n",
        "  predictions_df = last_training_predictions_df.iloc[1: , :][['positive_delta']]\n",
        "  return predictions_df\n",
        "\n",
        "def add_row_confusion_matrix(list_of_cm, df_row):\n",
        "  row = 0\n",
        "  column = 0\n",
        "  if df_row.positive_delta_predict:\n",
        "    column = 1\n",
        "  if df_row.positive_delta_actual:\n",
        "    row = 1\n",
        "  list_of_cm[df_row.name-1][row, column] += 1\n",
        "  return list_of_cm\n",
        "\n",
        "def evaluate(model, train_ts, test_ts, n_evaluations=10, n_test=3, n_steps=1, n_epochs=100, batch_size=16, full_test=True):\n",
        "  total_hits = 0\n",
        "  total_tries = 0\n",
        "  confusion_matrix = [np.zeros((2,2)), np.zeros((2,2)), np.zeros((2,2))]\n",
        "  print('Training on train_ts')\n",
        "  # This line is to replicate the other script\n",
        "\n",
        "  model.train(train_ts, n_epochs, batch_size)\n",
        "\n",
        "  print('Iteration 1 started on test')\n",
        "  steps_to_predict = test_ts[:n_steps]\n",
        "  steps_result = test_ts[n_steps:n_steps+n_test]\n",
        "  if full_test:\n",
        "    i=1\n",
        "    while n_steps + (n_test * i) < len(test_ts):\n",
        "      print(steps_to_predict)\n",
        "      predictions = model.predict(steps_to_predict)\n",
        "      predictions = predictions.reshape(predictions.shape[1])\n",
        "      predictions_ts = pd.DataFrame({'close': predictions}, steps_result.index)\n",
        "      print(predictions_ts)\n",
        "\n",
        "      predictions_df = build_prediction_dataframe(steps_to_predict, predictions_ts)\n",
        "      predictions_df.rename(columns={'positive_delta': 'positive_delta_predict'}, inplace=True)\n",
        "\n",
        "      test_df = build_prediction_dataframe(steps_to_predict, steps_result)\n",
        "      test_df.rename(columns={'positive_delta': 'positive_delta_actual'}, inplace=True)\n",
        "\n",
        "      predictions_and_test = pd.concat([test_df, predictions_df], axis=1)\n",
        "      predictions_and_test['equal'] = predictions_and_test.apply(lambda row: row['positive_delta_actual'] == row['positive_delta_predict'], axis=1)\n",
        "      predictions_and_test.apply(lambda row: add_row_confusion_matrix(confusion_matrix, row), axis=1)\n",
        "\n",
        "      hits = predictions_and_test['equal'].sum()\n",
        "      print('Accuracy: {}/{}'.format(hits, predictions_and_test.shape[0]))\n",
        "      total_hits += hits\n",
        "      total_tries += predictions_and_test.shape[0]\n",
        "\n",
        "      print('Iteration {} started'.format(i))\n",
        "      new_train = pd.concat([steps_to_predict, steps_result])\n",
        "      model.train(new_train, epochs=1, batch_size=len(new_train), validation_split=0)\n",
        "      steps_to_predict = test_ts[(n_test * (i-1)):n_steps + (n_test * (i-1))]\n",
        "      steps_result = test_ts[n_steps + (n_test * (i-1)):n_steps + (n_test * i)]\n",
        "      i+=1\n",
        "  else:\n",
        "    for i in reversed(range(1, n_evaluations + 1)):\n",
        "      print('Last training {} {}'.format(i, steps_to_predict))\n",
        "      predictions = model.predict(steps_to_predict)\n",
        "      predictions = predictions.reshape(predictions.shape[1])\n",
        "      predictions_ts = pd.DataFrame({'close': predictions}, test_evaluate.index)\n",
        "      \n",
        "      predictions_df = build_prediction_dataframe(steps_to_predict, predictions_ts)\n",
        "      predictions_df.rename(columns={'positive_delta': 'positive_delta_predict'}, inplace=True)\n",
        "      \n",
        "      test_df = build_prediction_dataframe(steps_to_predict, steps_result)\n",
        "      test_df.rename(columns={'positive_delta': 'positive_delta_actual'}, inplace=True)\n",
        "\n",
        "      predictions_and_test = pd.concat([test_df, predictions_df], axis=1)\n",
        "      predictions_and_test['equal'] = predictions_and_test.apply(lambda row: row['positive_delta_actual'] == row['positive_delta_predict'], axis=1)\n",
        "      predictions_and_test.apply(lambda row: add_row_confusion_matrix(confusion_matrix, row), axis=1)\n",
        "\n",
        "      hits = predictions_and_test['equal'].sum()\n",
        "      print('Accuracy: {}/{}'.format(hits, predictions_and_test.shape[0]))\n",
        "      total_hits += hits\n",
        "      total_tries += predictions_and_test.shape[0]\n",
        "\n",
        "      print('Iteration {} started'.format(n_evaluations + 1 - i))\n",
        "      new_train = pd.concat([steps_to_predict, test_evaluate])\n",
        "      model.retrain(new_train, epochs=1, batch_size=len(new_train), validation_split=0)\n",
        "      steps_to_predict = new_train[-n_steps:]\n",
        "\n",
        "  print('Total hits: {}. Total tries: {}. Accuracy: {:0.2f}'.format(total_hits, total_tries, total_hits / total_tries))\n",
        "  \n",
        "  return confusion_matrix"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH6pIRYfzqiu"
      },
      "source": [
        "def plot_confusion_matrix(confusion_matrix):\n",
        "  fig, axs = plt.subplots(2, 2)\n",
        "  fig.supxlabel('Predicted')\n",
        "  fig.supylabel('Actual')\n",
        "  for i in range(0, len(confusion_matrix)):\n",
        "    ax = axs[int(i/2), i%2]\n",
        "    ax.title.set_text('Index {}'.format(i+1))\n",
        "    sns.heatmap(data=confusion_matrix[i], annot=True, cbar=False, ax=ax)\n",
        "  sum_cm = sum(confusion_matrix)\n",
        "  axs[1,1].title.set_text('Total')\n",
        "  sns.heatmap(data=sum_cm, annot=True, cbar=False, ax=axs[1,1])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "itEojPe3eJpW",
        "outputId": "d4ddcc0b-37c6-4e5b-e726-6aa16ffc2cea"
      },
      "source": [
        "from VanillaLSTM import VanillaLSTM\n",
        "from StackedLSTM import StackedLSTM\n",
        "from BidirectionalLSTM import BidirectionalLSTM\n",
        "from ConvLSTM import ConvLSTM\n",
        "from CnnLSTM import CnnLSTM\n",
        "\n",
        "epochs = 70\n",
        "batch_size = 16\n",
        "n_steps = 5\n",
        "n_outputs = 2\n",
        "n_evaluations = 10\n",
        "n_neurons = 30\n",
        "n_seed = 0\n",
        "optimizer = 'adam'\n",
        "loss = 'mean_squared_error'\n",
        "model_type = VanillaLSTM\n",
        "\n",
        "seed(n_seed)\n",
        "tf.random.set_seed(n_seed)\n",
        "model = model_type(n_neurons=n_neurons, n_steps=n_steps, n_outputs=n_outputs, loss=loss, optimizer=optimizer)\n",
        "\n",
        "cm = evaluate(model, btc_stocks_close, btc_new_stocks_close, n_test=n_outputs, n_steps=n_steps, n_epochs=epochs, batch_size=batch_size)\n",
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 30)                3840      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 62        \n",
            "=================================================================\n",
            "Total params: 3,902\n",
            "Trainable params: 3,902\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training on train_ts\n",
            "Epoch 1/70\n",
            "140/140 [==============================] - 2s 7ms/step - loss: 0.0016 - accuracy: 0.5255 - val_loss: 0.0056 - val_accuracy: 0.5301\n",
            "Epoch 2/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.1606e-05 - accuracy: 0.5027 - val_loss: 0.0052 - val_accuracy: 0.5301\n",
            "Epoch 3/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.0187e-05 - accuracy: 0.5022 - val_loss: 0.0061 - val_accuracy: 0.5261\n",
            "Epoch 4/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.5907e-05 - accuracy: 0.5018 - val_loss: 0.0048 - val_accuracy: 0.5663\n",
            "Epoch 5/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.1027e-05 - accuracy: 0.5000 - val_loss: 0.0044 - val_accuracy: 0.5341\n",
            "Epoch 6/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.8326e-05 - accuracy: 0.5013 - val_loss: 0.0047 - val_accuracy: 0.4699\n",
            "Epoch 7/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.1840e-05 - accuracy: 0.5107 - val_loss: 0.0048 - val_accuracy: 0.4739\n",
            "Epoch 8/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.1354e-05 - accuracy: 0.4942 - val_loss: 0.0045 - val_accuracy: 0.4739\n",
            "Epoch 9/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.7872e-05 - accuracy: 0.5085 - val_loss: 0.0044 - val_accuracy: 0.4699\n",
            "Epoch 10/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.8591e-05 - accuracy: 0.5045 - val_loss: 0.0047 - val_accuracy: 0.4739\n",
            "Epoch 11/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.8831e-05 - accuracy: 0.4911 - val_loss: 0.0041 - val_accuracy: 0.4699\n",
            "Epoch 12/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.5677e-05 - accuracy: 0.4870 - val_loss: 0.0040 - val_accuracy: 0.4659\n",
            "Epoch 13/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.7543e-05 - accuracy: 0.5072 - val_loss: 0.0046 - val_accuracy: 0.4699\n",
            "Epoch 14/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.6541e-05 - accuracy: 0.5076 - val_loss: 0.0042 - val_accuracy: 0.4699\n",
            "Epoch 15/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.7532e-05 - accuracy: 0.4852 - val_loss: 0.0044 - val_accuracy: 0.4699\n",
            "Epoch 16/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.6836e-05 - accuracy: 0.5040 - val_loss: 0.0042 - val_accuracy: 0.4699\n",
            "Epoch 17/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.5413e-05 - accuracy: 0.4955 - val_loss: 0.0043 - val_accuracy: 0.4699\n",
            "Epoch 18/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.4794e-05 - accuracy: 0.5121 - val_loss: 0.0045 - val_accuracy: 0.4699\n",
            "Epoch 19/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.3343e-05 - accuracy: 0.4839 - val_loss: 0.0042 - val_accuracy: 0.4659\n",
            "Epoch 20/70\n",
            "140/140 [==============================] - 0s 4ms/step - loss: 5.4330e-05 - accuracy: 0.4893 - val_loss: 0.0043 - val_accuracy: 0.4699\n",
            "Epoch 21/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.4883e-05 - accuracy: 0.4946 - val_loss: 0.0043 - val_accuracy: 0.4699\n",
            "Epoch 22/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.5540e-05 - accuracy: 0.5054 - val_loss: 0.0042 - val_accuracy: 0.4699\n",
            "Epoch 23/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.3338e-05 - accuracy: 0.5063 - val_loss: 0.0041 - val_accuracy: 0.4699\n",
            "Epoch 24/70\n",
            "140/140 [==============================] - 0s 4ms/step - loss: 5.2009e-05 - accuracy: 0.4973 - val_loss: 0.0043 - val_accuracy: 0.4699\n",
            "Epoch 25/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.3009e-05 - accuracy: 0.4911 - val_loss: 0.0045 - val_accuracy: 0.4659\n",
            "Epoch 26/70\n",
            "140/140 [==============================] - 0s 4ms/step - loss: 5.3565e-05 - accuracy: 0.5228 - val_loss: 0.0042 - val_accuracy: 0.4699\n",
            "Epoch 27/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.9918e-05 - accuracy: 0.4933 - val_loss: 0.0042 - val_accuracy: 0.4699\n",
            "Epoch 28/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 4.9342e-05 - accuracy: 0.4969 - val_loss: 0.0040 - val_accuracy: 0.4699\n",
            "Epoch 29/70\n",
            "140/140 [==============================] - 0s 4ms/step - loss: 5.2838e-05 - accuracy: 0.5027 - val_loss: 0.0044 - val_accuracy: 0.4699\n",
            "Epoch 30/70\n",
            "140/140 [==============================] - 0s 4ms/step - loss: 5.1567e-05 - accuracy: 0.5013 - val_loss: 0.0044 - val_accuracy: 0.4699\n",
            "Epoch 31/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.0074e-05 - accuracy: 0.5157 - val_loss: 0.0046 - val_accuracy: 0.4699\n",
            "Epoch 32/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.8780e-05 - accuracy: 0.4987 - val_loss: 0.0053 - val_accuracy: 0.4699\n",
            "Epoch 33/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.8938e-05 - accuracy: 0.4924 - val_loss: 0.0049 - val_accuracy: 0.4699\n",
            "Epoch 34/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.8725e-05 - accuracy: 0.4919 - val_loss: 0.0050 - val_accuracy: 0.4699\n",
            "Epoch 35/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.0214e-05 - accuracy: 0.4897 - val_loss: 0.0050 - val_accuracy: 0.4699\n",
            "Epoch 36/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.7109e-05 - accuracy: 0.5009 - val_loss: 0.0047 - val_accuracy: 0.4779\n",
            "Epoch 37/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.7903e-05 - accuracy: 0.4826 - val_loss: 0.0049 - val_accuracy: 0.4699\n",
            "Epoch 38/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.5522e-05 - accuracy: 0.5134 - val_loss: 0.0047 - val_accuracy: 0.4699\n",
            "Epoch 39/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.6601e-05 - accuracy: 0.5072 - val_loss: 0.0040 - val_accuracy: 0.4699\n",
            "Epoch 40/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.7290e-05 - accuracy: 0.4718 - val_loss: 0.0064 - val_accuracy: 0.4699\n",
            "Epoch 41/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.4545e-05 - accuracy: 0.5054 - val_loss: 0.0053 - val_accuracy: 0.4739\n",
            "Epoch 42/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.4019e-05 - accuracy: 0.4955 - val_loss: 0.0055 - val_accuracy: 0.4699\n",
            "Epoch 43/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.4685e-05 - accuracy: 0.5031 - val_loss: 0.0053 - val_accuracy: 0.4699\n",
            "Epoch 44/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.5345e-05 - accuracy: 0.5063 - val_loss: 0.0047 - val_accuracy: 0.4699\n",
            "Epoch 45/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.3426e-05 - accuracy: 0.4879 - val_loss: 0.0051 - val_accuracy: 0.4699\n",
            "Epoch 46/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.3848e-05 - accuracy: 0.5000 - val_loss: 0.0045 - val_accuracy: 0.4699\n",
            "Epoch 47/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.2447e-05 - accuracy: 0.5018 - val_loss: 0.0051 - val_accuracy: 0.4699\n",
            "Epoch 48/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.3559e-05 - accuracy: 0.5063 - val_loss: 0.0041 - val_accuracy: 0.4699\n",
            "Epoch 49/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.2689e-05 - accuracy: 0.5013 - val_loss: 0.0033 - val_accuracy: 0.4699\n",
            "Epoch 50/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.2925e-05 - accuracy: 0.4978 - val_loss: 0.0045 - val_accuracy: 0.4699\n",
            "Epoch 51/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.1634e-05 - accuracy: 0.5143 - val_loss: 0.0039 - val_accuracy: 0.4699\n",
            "Epoch 52/70\n",
            "140/140 [==============================] - 0s 4ms/step - loss: 4.3645e-05 - accuracy: 0.4951 - val_loss: 0.0034 - val_accuracy: 0.4859\n",
            "Epoch 53/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.0844e-05 - accuracy: 0.5036 - val_loss: 0.0050 - val_accuracy: 0.4699\n",
            "Epoch 54/70\n",
            "140/140 [==============================] - 0s 4ms/step - loss: 4.1386e-05 - accuracy: 0.4964 - val_loss: 0.0038 - val_accuracy: 0.4659\n",
            "Epoch 55/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.0226e-05 - accuracy: 0.4933 - val_loss: 0.0032 - val_accuracy: 0.4699\n",
            "Epoch 56/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.2942e-05 - accuracy: 0.5076 - val_loss: 0.0040 - val_accuracy: 0.4699\n",
            "Epoch 57/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.1228e-05 - accuracy: 0.5098 - val_loss: 0.0030 - val_accuracy: 0.4699\n",
            "Epoch 58/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.1331e-05 - accuracy: 0.4754 - val_loss: 0.0026 - val_accuracy: 0.4699\n",
            "Epoch 59/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.0467e-05 - accuracy: 0.4969 - val_loss: 0.0019 - val_accuracy: 0.4739\n",
            "Epoch 60/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8899e-05 - accuracy: 0.4996 - val_loss: 0.0019 - val_accuracy: 0.4739\n",
            "Epoch 61/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.9122e-05 - accuracy: 0.4888 - val_loss: 0.0019 - val_accuracy: 0.4699\n",
            "Epoch 62/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8390e-05 - accuracy: 0.4857 - val_loss: 0.0017 - val_accuracy: 0.4659\n",
            "Epoch 63/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 3.9128e-05 - accuracy: 0.4933 - val_loss: 0.0018 - val_accuracy: 0.4699\n",
            "Epoch 64/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8412e-05 - accuracy: 0.4884 - val_loss: 0.0023 - val_accuracy: 0.4699\n",
            "Epoch 65/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8668e-05 - accuracy: 0.5125 - val_loss: 0.0017 - val_accuracy: 0.4699\n",
            "Epoch 66/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8547e-05 - accuracy: 0.4964 - val_loss: 0.0016 - val_accuracy: 0.4699\n",
            "Epoch 67/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8867e-05 - accuracy: 0.5045 - val_loss: 0.0018 - val_accuracy: 0.4699\n",
            "Epoch 68/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.0064e-05 - accuracy: 0.5063 - val_loss: 0.0016 - val_accuracy: 0.4699\n",
            "Epoch 69/70\n",
            "140/140 [==============================] - 0s 4ms/step - loss: 3.6658e-05 - accuracy: 0.5130 - val_loss: 0.0015 - val_accuracy: 0.4699\n",
            "Epoch 70/70\n",
            "140/140 [==============================] - 0s 4ms/step - loss: 3.7412e-05 - accuracy: 0.5049 - val_loss: 0.0015 - val_accuracy: 0.4699\n",
            "Iteration 1 started on test\n",
            "          close\n",
            "0  32702.025391\n",
            "1  32822.347656\n",
            "2  31780.730469\n",
            "3  31421.539063\n",
            "4  31533.068359\n",
            "          close\n",
            "5  31791.783203\n",
            "6  30711.595703\n",
            "Accuracy: 2/2\n",
            "Iteration 1 started\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "          close\n",
            "0  32702.025391\n",
            "1  32822.347656\n",
            "2  31780.730469\n",
            "3  31421.539063\n",
            "4  31533.068359\n",
            "          close\n",
            "5  31274.808594\n",
            "6  31183.615234\n",
            "Accuracy: 1/2\n",
            "Iteration 2 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 1.0000\n",
            "          close\n",
            "2  31780.730469\n",
            "3  31421.539063\n",
            "4  31533.068359\n",
            "5  31796.810547\n",
            "6  30817.832031\n",
            "          close\n",
            "7  31182.041016\n",
            "8  31093.433594\n",
            "Accuracy: 0/2\n",
            "Iteration 3 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3206 - accuracy: 0.0000e+00\n",
            "          close\n",
            "4  31533.068359\n",
            "5  31796.810547\n",
            "6  30817.832031\n",
            "7  29807.347656\n",
            "8  32110.693359\n",
            "           close\n",
            "9   31531.173828\n",
            "10  31022.173828\n",
            "Accuracy: 0/2\n",
            "Iteration 4 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2650 - accuracy: 0.0000e+00\n",
            "           close\n",
            "6   30817.832031\n",
            "7   29807.347656\n",
            "8   32110.693359\n",
            "9   32313.105469\n",
            "10  33581.550781\n",
            "           close\n",
            "11  33306.808594\n",
            "12  32660.378906\n",
            "Accuracy: 0/2\n",
            "Iteration 5 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1564 - accuracy: 0.0000e+00\n",
            "           close\n",
            "8   32110.693359\n",
            "9   32313.105469\n",
            "10  33581.550781\n",
            "11  34292.445313\n",
            "12  35350.187500\n",
            "           close\n",
            "13  36079.710938\n",
            "14  35230.328125\n",
            "Accuracy: 1/2\n",
            "Iteration 6 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2848 - accuracy: 0.0000e+00\n",
            "           close\n",
            "10  33581.550781\n",
            "11  34292.445313\n",
            "12  35350.187500\n",
            "13  37337.535156\n",
            "14  39406.941406\n",
            "           close\n",
            "15  39752.335938\n",
            "16  38850.449219\n",
            "Accuracy: 1/2\n",
            "Iteration 7 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0523 - accuracy: 0.0000e+00\n",
            "           close\n",
            "12  35350.187500\n",
            "13  37337.535156\n",
            "14  39406.941406\n",
            "15  39995.906250\n",
            "16  40008.421875\n",
            "           close\n",
            "17  42419.707031\n",
            "18  41802.902344\n",
            "Accuracy: 2/2\n",
            "Iteration 8 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0234 - accuracy: 1.0000\n",
            "           close\n",
            "14  39406.941406\n",
            "15  39995.906250\n",
            "16  40008.421875\n",
            "17  42235.546875\n",
            "18  41626.195313\n",
            "           close\n",
            "19  44800.687500\n",
            "20  44408.246094\n",
            "Accuracy: 1/2\n",
            "Iteration 9 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7801 - accuracy: 1.0000\n",
            "           close\n",
            "16  40008.421875\n",
            "17  42235.546875\n",
            "18  41626.195313\n",
            "19  39974.894531\n",
            "20  39201.945313\n",
            "           close\n",
            "21  39618.125000\n",
            "22  39885.039062\n",
            "Accuracy: 1/2\n",
            "Iteration 10 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0986 - accuracy: 1.0000\n",
            "           close\n",
            "18  41626.195313\n",
            "19  39974.894531\n",
            "20  39201.945313\n",
            "21  38152.980469\n",
            "22  39747.503906\n",
            "           close\n",
            "23  39829.515625\n",
            "24  39702.539062\n",
            "Accuracy: 1/2\n",
            "Iteration 11 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2359 - accuracy: 0.0000e+00\n",
            "           close\n",
            "20  39201.945313\n",
            "21  38152.980469\n",
            "22  39747.503906\n",
            "23  40869.554688\n",
            "24  42816.500000\n",
            "           close\n",
            "25  42755.539062\n",
            "26  42473.160156\n",
            "Accuracy: 1/2\n",
            "Iteration 12 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0695 - accuracy: 1.0000\n",
            "           close\n",
            "22  39747.503906\n",
            "23  40869.554688\n",
            "24  42816.500000\n",
            "25  44555.800781\n",
            "26  43798.117188\n",
            "           close\n",
            "27  45584.992188\n",
            "28  45706.625000\n",
            "Accuracy: 1/2\n",
            "Iteration 13 started\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0376 - accuracy: 1.0000\n",
            "           close\n",
            "24  42816.500000\n",
            "25  44555.800781\n",
            "26  43798.117188\n",
            "27  46365.402344\n",
            "28  45585.031250\n",
            "           close\n",
            "29  47644.882812\n",
            "30  47951.933594\n",
            "Accuracy: 1/2\n",
            "Iteration 14 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1552 - accuracy: 0.0000e+00\n",
            "           close\n",
            "26  43798.117188\n",
            "27  46365.402344\n",
            "28  45585.031250\n",
            "29  45593.636719\n",
            "30  44428.289063\n",
            "           close\n",
            "31  45079.519531\n",
            "32  45526.800781\n",
            "Accuracy: 1/2\n",
            "Iteration 15 started\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3056 - accuracy: 0.0000e+00\n",
            "           close\n",
            "28  45585.031250\n",
            "29  45593.636719\n",
            "30  44428.289063\n",
            "31  47793.320313\n",
            "32  47096.945313\n",
            "           close\n",
            "33  47771.496094\n",
            "34  47831.042969\n",
            "Accuracy: 0/2\n",
            "Iteration 16 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1078 - accuracy: 0.0000e+00\n",
            "           close\n",
            "30  44428.289063\n",
            "31  47793.320313\n",
            "32  47096.945313\n",
            "33  47047.003906\n",
            "34  46004.484375\n",
            "           close\n",
            "35  46651.777344\n",
            "36  47005.714844\n",
            "Accuracy: 1/2\n",
            "Iteration 17 started\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3836 - accuracy: 1.0000\n",
            "           close\n",
            "32  47096.945313\n",
            "33  47047.003906\n",
            "34  46004.484375\n",
            "35  44695.359375\n",
            "36  44801.187500\n",
            "           close\n",
            "37  45049.683594\n",
            "38  45289.738281\n",
            "Accuracy: 2/2\n",
            "Iteration 18 started\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3739 - accuracy: 1.0000\n",
            "           close\n",
            "34  46004.484375\n",
            "35  44695.359375\n",
            "36  44801.187500\n",
            "37  46717.578125\n",
            "38  49339.175781\n",
            "           close\n",
            "39  48618.332031\n",
            "40  48323.136719\n",
            "Accuracy: 1/2\n",
            "Iteration 19 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 0.0000e+00\n",
            "           close\n",
            "36  44801.187500\n",
            "37  46717.578125\n",
            "38  49339.175781\n",
            "39  48905.492188\n",
            "40  49321.652344\n",
            "           close\n",
            "41  50041.871094\n",
            "42  50042.640625\n",
            "Accuracy: 1/2\n",
            "Iteration 20 started\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1197 - accuracy: 1.0000\n",
            "           close\n",
            "38  49339.175781\n",
            "39  48905.492188\n",
            "40  49321.652344\n",
            "41  49546.148438\n",
            "42  47706.117188\n",
            "           close\n",
            "43  48121.660156\n",
            "44  48712.582031\n",
            "Accuracy: 1/2\n",
            "Iteration 21 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2243 - accuracy: 0.0000e+00\n",
            "           close\n",
            "40  49321.652344\n",
            "41  49546.148438\n",
            "42  47706.117188\n",
            "43  48960.789063\n",
            "44  46942.218750\n",
            "           close\n",
            "45  47234.714844\n",
            "46  47523.460938\n",
            "Accuracy: 1/2\n",
            "Iteration 22 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.0000e+00\n",
            "Total hits: 21. Total tries: 44. Accuracy: 0.48\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "skfdSAWalNhR",
        "outputId": "1fd54aea-3aa9-4846-93a5-ee7c570381b3"
      },
      "source": [
        "seed(n_seed)\n",
        "tf.random.set_seed(n_seed)\n",
        "model = model_type(n_neurons=n_neurons, n_steps=n_steps, n_outputs=n_outputs, loss=loss, optimizer=optimizer)\n",
        "\n",
        "cm = evaluate(model, btc_stocks_close, eth_new_stocks_close, n_evaluations=n_evaluations, n_test=n_outputs, n_steps=n_steps, n_epochs=epochs, batch_size=batch_size)\n",
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 30)                3840      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 62        \n",
            "=================================================================\n",
            "Total params: 3,902\n",
            "Trainable params: 3,902\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training on train_ts\n",
            "Epoch 1/70\n",
            "140/140 [==============================] - 2s 6ms/step - loss: 0.0016 - accuracy: 0.5255 - val_loss: 0.0056 - val_accuracy: 0.5301\n",
            "Epoch 2/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.1606e-05 - accuracy: 0.5027 - val_loss: 0.0052 - val_accuracy: 0.5301\n",
            "Epoch 3/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.0187e-05 - accuracy: 0.5022 - val_loss: 0.0061 - val_accuracy: 0.5261\n",
            "Epoch 4/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.5907e-05 - accuracy: 0.5018 - val_loss: 0.0048 - val_accuracy: 0.5663\n",
            "Epoch 5/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.1027e-05 - accuracy: 0.5000 - val_loss: 0.0044 - val_accuracy: 0.5341\n",
            "Epoch 6/70\n",
            "140/140 [==============================] - 0s 4ms/step - loss: 5.8326e-05 - accuracy: 0.5013 - val_loss: 0.0047 - val_accuracy: 0.4699\n",
            "Epoch 7/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 6.1840e-05 - accuracy: 0.5107 - val_loss: 0.0048 - val_accuracy: 0.4739\n",
            "Epoch 8/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.1354e-05 - accuracy: 0.4942 - val_loss: 0.0045 - val_accuracy: 0.4739\n",
            "Epoch 9/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.7872e-05 - accuracy: 0.5085 - val_loss: 0.0044 - val_accuracy: 0.4699\n",
            "Epoch 10/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.8591e-05 - accuracy: 0.5045 - val_loss: 0.0047 - val_accuracy: 0.4739\n",
            "Epoch 11/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.8831e-05 - accuracy: 0.4911 - val_loss: 0.0041 - val_accuracy: 0.4699\n",
            "Epoch 12/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.5677e-05 - accuracy: 0.4870 - val_loss: 0.0040 - val_accuracy: 0.4659\n",
            "Epoch 13/70\n",
            "140/140 [==============================] - 0s 4ms/step - loss: 5.7543e-05 - accuracy: 0.5072 - val_loss: 0.0046 - val_accuracy: 0.4699\n",
            "Epoch 14/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.6541e-05 - accuracy: 0.5076 - val_loss: 0.0042 - val_accuracy: 0.4699\n",
            "Epoch 15/70\n",
            "140/140 [==============================] - 0s 4ms/step - loss: 5.7532e-05 - accuracy: 0.4852 - val_loss: 0.0044 - val_accuracy: 0.4699\n",
            "Epoch 16/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.6836e-05 - accuracy: 0.5040 - val_loss: 0.0042 - val_accuracy: 0.4699\n",
            "Epoch 17/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.5413e-05 - accuracy: 0.4955 - val_loss: 0.0043 - val_accuracy: 0.4699\n",
            "Epoch 18/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.4794e-05 - accuracy: 0.5121 - val_loss: 0.0045 - val_accuracy: 0.4699\n",
            "Epoch 19/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.3343e-05 - accuracy: 0.4839 - val_loss: 0.0042 - val_accuracy: 0.4659\n",
            "Epoch 20/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.4330e-05 - accuracy: 0.4893 - val_loss: 0.0043 - val_accuracy: 0.4699\n",
            "Epoch 21/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.4883e-05 - accuracy: 0.4946 - val_loss: 0.0043 - val_accuracy: 0.4699\n",
            "Epoch 22/70\n",
            "140/140 [==============================] - 0s 4ms/step - loss: 5.5540e-05 - accuracy: 0.5054 - val_loss: 0.0042 - val_accuracy: 0.4699\n",
            "Epoch 23/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.3338e-05 - accuracy: 0.5063 - val_loss: 0.0041 - val_accuracy: 0.4699\n",
            "Epoch 24/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.2009e-05 - accuracy: 0.4973 - val_loss: 0.0043 - val_accuracy: 0.4699\n",
            "Epoch 25/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.3009e-05 - accuracy: 0.4911 - val_loss: 0.0045 - val_accuracy: 0.4659\n",
            "Epoch 26/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.3565e-05 - accuracy: 0.5228 - val_loss: 0.0042 - val_accuracy: 0.4699\n",
            "Epoch 27/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.9918e-05 - accuracy: 0.4933 - val_loss: 0.0042 - val_accuracy: 0.4699\n",
            "Epoch 28/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.9342e-05 - accuracy: 0.4969 - val_loss: 0.0040 - val_accuracy: 0.4699\n",
            "Epoch 29/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.2838e-05 - accuracy: 0.5027 - val_loss: 0.0044 - val_accuracy: 0.4699\n",
            "Epoch 30/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.1567e-05 - accuracy: 0.5013 - val_loss: 0.0044 - val_accuracy: 0.4699\n",
            "Epoch 31/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.0074e-05 - accuracy: 0.5157 - val_loss: 0.0046 - val_accuracy: 0.4699\n",
            "Epoch 32/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.8780e-05 - accuracy: 0.4987 - val_loss: 0.0053 - val_accuracy: 0.4699\n",
            "Epoch 33/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.8938e-05 - accuracy: 0.4924 - val_loss: 0.0049 - val_accuracy: 0.4699\n",
            "Epoch 34/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 4.8725e-05 - accuracy: 0.4919 - val_loss: 0.0050 - val_accuracy: 0.4699\n",
            "Epoch 35/70\n",
            "140/140 [==============================] - 0s 4ms/step - loss: 5.0214e-05 - accuracy: 0.4897 - val_loss: 0.0050 - val_accuracy: 0.4699\n",
            "Epoch 36/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.7109e-05 - accuracy: 0.5009 - val_loss: 0.0047 - val_accuracy: 0.4779\n",
            "Epoch 37/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.7903e-05 - accuracy: 0.4826 - val_loss: 0.0049 - val_accuracy: 0.4699\n",
            "Epoch 38/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.5522e-05 - accuracy: 0.5134 - val_loss: 0.0047 - val_accuracy: 0.4699\n",
            "Epoch 39/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.6601e-05 - accuracy: 0.5072 - val_loss: 0.0040 - val_accuracy: 0.4699\n",
            "Epoch 40/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.7290e-05 - accuracy: 0.4718 - val_loss: 0.0064 - val_accuracy: 0.4699\n",
            "Epoch 41/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.4545e-05 - accuracy: 0.5054 - val_loss: 0.0053 - val_accuracy: 0.4739\n",
            "Epoch 42/70\n",
            "140/140 [==============================] - 0s 4ms/step - loss: 4.4019e-05 - accuracy: 0.4955 - val_loss: 0.0055 - val_accuracy: 0.4699\n",
            "Epoch 43/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.4685e-05 - accuracy: 0.5031 - val_loss: 0.0053 - val_accuracy: 0.4699\n",
            "Epoch 44/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 4.5345e-05 - accuracy: 0.5063 - val_loss: 0.0047 - val_accuracy: 0.4699\n",
            "Epoch 45/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.3426e-05 - accuracy: 0.4879 - val_loss: 0.0051 - val_accuracy: 0.4699\n",
            "Epoch 46/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 4.3848e-05 - accuracy: 0.5000 - val_loss: 0.0045 - val_accuracy: 0.4699\n",
            "Epoch 47/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.2447e-05 - accuracy: 0.5018 - val_loss: 0.0051 - val_accuracy: 0.4699\n",
            "Epoch 48/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.3559e-05 - accuracy: 0.5063 - val_loss: 0.0041 - val_accuracy: 0.4699\n",
            "Epoch 49/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.2689e-05 - accuracy: 0.5013 - val_loss: 0.0033 - val_accuracy: 0.4699\n",
            "Epoch 50/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.2925e-05 - accuracy: 0.4978 - val_loss: 0.0045 - val_accuracy: 0.4699\n",
            "Epoch 51/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.1634e-05 - accuracy: 0.5143 - val_loss: 0.0039 - val_accuracy: 0.4699\n",
            "Epoch 52/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 4.3645e-05 - accuracy: 0.4951 - val_loss: 0.0034 - val_accuracy: 0.4859\n",
            "Epoch 53/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.0844e-05 - accuracy: 0.5036 - val_loss: 0.0050 - val_accuracy: 0.4699\n",
            "Epoch 54/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.1386e-05 - accuracy: 0.4964 - val_loss: 0.0038 - val_accuracy: 0.4659\n",
            "Epoch 55/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 4.0226e-05 - accuracy: 0.4933 - val_loss: 0.0032 - val_accuracy: 0.4699\n",
            "Epoch 56/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.2942e-05 - accuracy: 0.5076 - val_loss: 0.0040 - val_accuracy: 0.4699\n",
            "Epoch 57/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.1228e-05 - accuracy: 0.5098 - val_loss: 0.0030 - val_accuracy: 0.4699\n",
            "Epoch 58/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.1331e-05 - accuracy: 0.4754 - val_loss: 0.0026 - val_accuracy: 0.4699\n",
            "Epoch 59/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 4.0467e-05 - accuracy: 0.4969 - val_loss: 0.0019 - val_accuracy: 0.4739\n",
            "Epoch 60/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8899e-05 - accuracy: 0.4996 - val_loss: 0.0019 - val_accuracy: 0.4739\n",
            "Epoch 61/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.9122e-05 - accuracy: 0.4888 - val_loss: 0.0019 - val_accuracy: 0.4699\n",
            "Epoch 62/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8390e-05 - accuracy: 0.4857 - val_loss: 0.0017 - val_accuracy: 0.4659\n",
            "Epoch 63/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 3.9128e-05 - accuracy: 0.4933 - val_loss: 0.0018 - val_accuracy: 0.4699\n",
            "Epoch 64/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8412e-05 - accuracy: 0.4884 - val_loss: 0.0023 - val_accuracy: 0.4699\n",
            "Epoch 65/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8668e-05 - accuracy: 0.5125 - val_loss: 0.0017 - val_accuracy: 0.4699\n",
            "Epoch 66/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8547e-05 - accuracy: 0.4964 - val_loss: 0.0016 - val_accuracy: 0.4699\n",
            "Epoch 67/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8867e-05 - accuracy: 0.5045 - val_loss: 0.0018 - val_accuracy: 0.4699\n",
            "Epoch 68/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.0064e-05 - accuracy: 0.5063 - val_loss: 0.0016 - val_accuracy: 0.4699\n",
            "Epoch 69/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.6658e-05 - accuracy: 0.5130 - val_loss: 0.0015 - val_accuracy: 0.4699\n",
            "Epoch 70/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.7412e-05 - accuracy: 0.5049 - val_loss: 0.0015 - val_accuracy: 0.4699\n",
            "Iteration 1 started on test\n",
            "         close\n",
            "0  1940.083984\n",
            "1  1994.331299\n",
            "2  1911.175659\n",
            "3  1880.382935\n",
            "4  1898.825195\n",
            "         close\n",
            "5  1930.672974\n",
            "6  1915.476440\n",
            "Accuracy: 1/2\n",
            "Iteration 1 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0583 - accuracy: 1.0000\n",
            "         close\n",
            "0  1940.083984\n",
            "1  1994.331299\n",
            "2  1911.175659\n",
            "3  1880.382935\n",
            "4  1898.825195\n",
            "         close\n",
            "5  1873.874512\n",
            "6  1864.214722\n",
            "Accuracy: 2/2\n",
            "Iteration 2 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0426 - accuracy: 1.0000\n",
            "         close\n",
            "2  1911.175659\n",
            "3  1880.382935\n",
            "4  1898.825195\n",
            "5  1895.552124\n",
            "6  1817.296631\n",
            "         close\n",
            "7  1839.972046\n",
            "8  1834.114380\n",
            "Accuracy: 0/2\n",
            "Iteration 3 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3726 - accuracy: 0.0000e+00\n",
            "         close\n",
            "4  1898.825195\n",
            "5  1895.552124\n",
            "6  1817.296631\n",
            "7  1787.510742\n",
            "8  1990.970825\n",
            "          close\n",
            "9   1914.126709\n",
            "10  1872.918945\n",
            "Accuracy: 0/2\n",
            "Iteration 4 started\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3564 - accuracy: 0.0000e+00\n",
            "          close\n",
            "6   1817.296631\n",
            "7   1787.510742\n",
            "8   1990.970825\n",
            "9   2025.202759\n",
            "10  2124.776611\n",
            "          close\n",
            "11  2103.081543\n",
            "12  2031.943115\n",
            "Accuracy: 0/2\n",
            "Iteration 5 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.0000e+00\n",
            "          close\n",
            "8   1990.970825\n",
            "9   2025.202759\n",
            "10  2124.776611\n",
            "11  2189.218750\n",
            "12  2191.373779\n",
            "          close\n",
            "13  2293.609131\n",
            "14  2190.839111\n",
            "Accuracy: 1/2\n",
            "Iteration 6 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1080 - accuracy: 0.0000e+00\n",
            "          close\n",
            "10  2124.776611\n",
            "11  2189.218750\n",
            "12  2191.373779\n",
            "13  2233.366699\n",
            "14  2298.333496\n",
            "          close\n",
            "15  2387.162354\n",
            "16  2306.494385\n",
            "Accuracy: 0/2\n",
            "Iteration 7 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.0000e+00\n",
            "          close\n",
            "12  2191.373779\n",
            "13  2233.366699\n",
            "14  2298.333496\n",
            "15  2296.545410\n",
            "16  2380.956787\n",
            "          close\n",
            "17  2456.166504\n",
            "18  2395.463867\n",
            "Accuracy: 1/2\n",
            "Iteration 8 started\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1601 - accuracy: 0.0000e+00\n",
            "          close\n",
            "14  2298.333496\n",
            "15  2296.545410\n",
            "16  2380.956787\n",
            "17  2466.961426\n",
            "18  2536.209961\n",
            "          close\n",
            "19  2676.568115\n",
            "20  2596.162598\n",
            "Accuracy: 1/2\n",
            "Iteration 9 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0424 - accuracy: 0.0000e+00\n",
            "          close\n",
            "16  2380.956787\n",
            "17  2466.961426\n",
            "18  2536.209961\n",
            "19  2561.852051\n",
            "20  2610.153320\n",
            "          close\n",
            "21  2813.554932\n",
            "22  2740.768799\n",
            "Accuracy: 0/2\n",
            "Iteration 10 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1977 - accuracy: 0.0000e+00\n",
            "          close\n",
            "18  2536.209961\n",
            "19  2561.852051\n",
            "20  2610.153320\n",
            "21  2502.349609\n",
            "22  2724.619873\n",
            "          close\n",
            "23  2858.791748\n",
            "24  2799.536133\n",
            "Accuracy: 1/2\n",
            "Iteration 11 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1477 - accuracy: 0.0000e+00\n",
            "          close\n",
            "20  2610.153320\n",
            "21  2502.349609\n",
            "22  2724.619873\n",
            "23  2827.328857\n",
            "24  2890.941650\n",
            "          close\n",
            "25  3095.073242\n",
            "26  3060.512695\n",
            "Accuracy: 2/2\n",
            "Iteration 12 started\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0108 - accuracy: 1.0000\n",
            "          close\n",
            "22  2724.619873\n",
            "23  2827.328857\n",
            "24  2890.941650\n",
            "25  3157.238770\n",
            "26  3013.732666\n",
            "          close\n",
            "27  3458.084473\n",
            "28  3511.018311\n",
            "Accuracy: 1/2\n",
            "Iteration 13 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.0000e+00\n",
            "          close\n",
            "24  2890.941650\n",
            "25  3157.238770\n",
            "26  3013.732666\n",
            "27  3167.856201\n",
            "28  3141.691162\n",
            "          close\n",
            "29  3496.442627\n",
            "30  3559.417969\n",
            "Accuracy: 1/2\n",
            "Iteration 14 started\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8543 - accuracy: 0.0000e+00\n",
            "          close\n",
            "26  3013.732666\n",
            "27  3167.856201\n",
            "28  3141.691162\n",
            "29  3164.245117\n",
            "30  3043.414307\n",
            "          close\n",
            "31  3134.292725\n",
            "32  3206.129883\n",
            "Accuracy: 1/2\n",
            "Iteration 15 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2190 - accuracy: 0.0000e+00\n",
            "          close\n",
            "28  3141.691162\n",
            "29  3164.245117\n",
            "30  3043.414307\n",
            "31  3322.211670\n",
            "32  3265.443359\n",
            "          close\n",
            "33  3392.726318\n",
            "34  3409.692383\n",
            "Accuracy: 1/2\n",
            "Iteration 16 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.0000e+00\n",
            "          close\n",
            "30  3043.414307\n",
            "31  3322.211670\n",
            "32  3265.443359\n",
            "33  3310.504150\n",
            "34  3156.509521\n",
            "          close\n",
            "35  3225.066650\n",
            "36  3276.429443\n",
            "Accuracy: 1/2\n",
            "Iteration 17 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6293 - accuracy: 1.0000\n",
            "          close\n",
            "32  3265.443359\n",
            "33  3310.504150\n",
            "34  3156.509521\n",
            "35  3014.845947\n",
            "36  3020.089844\n",
            "          close\n",
            "37  2940.632812\n",
            "38  2974.671875\n",
            "Accuracy: 1/2\n",
            "Iteration 18 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9446 - accuracy: 1.0000\n",
            "          close\n",
            "34  3156.509521\n",
            "35  3014.845947\n",
            "36  3020.089844\n",
            "37  3182.702148\n",
            "38  3286.935303\n",
            "          close\n",
            "39  3299.345703\n",
            "40  3283.286865\n",
            "Accuracy: 0/2\n",
            "Iteration 19 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0499 - accuracy: 0.0000e+00\n",
            "          close\n",
            "36  3020.089844\n",
            "37  3182.702148\n",
            "38  3286.935303\n",
            "39  3226.083984\n",
            "40  3242.115479\n",
            "          close\n",
            "41  3295.097412\n",
            "42  3302.471436\n",
            "Accuracy: 1/2\n",
            "Iteration 20 started\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1006 - accuracy: 0.0000e+00\n",
            "          close\n",
            "38  3286.935303\n",
            "39  3226.083984\n",
            "40  3242.115479\n",
            "41  3319.257324\n",
            "42  3172.456299\n",
            "          close\n",
            "43  3170.325195\n",
            "44  3196.087402\n",
            "Accuracy: 0/2\n",
            "Iteration 21 started\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1280 - accuracy: 0.0000e+00\n",
            "          close\n",
            "40  3242.115479\n",
            "41  3319.257324\n",
            "42  3172.456299\n",
            "43  3224.915283\n",
            "44  3100.325439\n",
            "          close\n",
            "45  3079.748291\n",
            "46  3098.484375\n",
            "Accuracy: 0/2\n",
            "Iteration 22 started\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6021 - accuracy: 0.0000e+00\n",
            "Total hits: 16. Total tries: 44. Accuracy: 0.36\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "69GeBLPWlQNF",
        "outputId": "98b3cbf7-bc15-49ba-fb55-ae28a7c9596c"
      },
      "source": [
        "seed(n_seed)\n",
        "tf.random.set_seed(n_seed)\n",
        "model = model_type(n_neurons=n_neurons, n_steps=n_steps, n_outputs=n_outputs, loss=loss, optimizer=optimizer)\n",
        "\n",
        "cm = evaluate(model, btc_stocks_close, ada_new_stocks_close, n_evaluations=n_evaluations, n_test=n_outputs, n_steps=n_steps, n_epochs=epochs, batch_size=batch_size)\n",
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 30)                3840      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 62        \n",
            "=================================================================\n",
            "Total params: 3,902\n",
            "Trainable params: 3,902\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training on train_ts\n",
            "Epoch 1/70\n",
            "140/140 [==============================] - 2s 6ms/step - loss: 0.0016 - accuracy: 0.5255 - val_loss: 0.0056 - val_accuracy: 0.5301\n",
            "Epoch 2/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.1606e-05 - accuracy: 0.5027 - val_loss: 0.0052 - val_accuracy: 0.5301\n",
            "Epoch 3/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.0187e-05 - accuracy: 0.5022 - val_loss: 0.0061 - val_accuracy: 0.5261\n",
            "Epoch 4/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.5907e-05 - accuracy: 0.5018 - val_loss: 0.0048 - val_accuracy: 0.5663\n",
            "Epoch 5/70\n",
            "140/140 [==============================] - 0s 4ms/step - loss: 6.1027e-05 - accuracy: 0.5000 - val_loss: 0.0044 - val_accuracy: 0.5341\n",
            "Epoch 6/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.8326e-05 - accuracy: 0.5013 - val_loss: 0.0047 - val_accuracy: 0.4699\n",
            "Epoch 7/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.1840e-05 - accuracy: 0.5107 - val_loss: 0.0048 - val_accuracy: 0.4739\n",
            "Epoch 8/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 6.1354e-05 - accuracy: 0.4942 - val_loss: 0.0045 - val_accuracy: 0.4739\n",
            "Epoch 9/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.7872e-05 - accuracy: 0.5085 - val_loss: 0.0044 - val_accuracy: 0.4699\n",
            "Epoch 10/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.8591e-05 - accuracy: 0.5045 - val_loss: 0.0047 - val_accuracy: 0.4739\n",
            "Epoch 11/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.8831e-05 - accuracy: 0.4911 - val_loss: 0.0041 - val_accuracy: 0.4699\n",
            "Epoch 12/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.5677e-05 - accuracy: 0.4870 - val_loss: 0.0040 - val_accuracy: 0.4659\n",
            "Epoch 13/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.7543e-05 - accuracy: 0.5072 - val_loss: 0.0046 - val_accuracy: 0.4699\n",
            "Epoch 14/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.6541e-05 - accuracy: 0.5076 - val_loss: 0.0042 - val_accuracy: 0.4699\n",
            "Epoch 15/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.7532e-05 - accuracy: 0.4852 - val_loss: 0.0044 - val_accuracy: 0.4699\n",
            "Epoch 16/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.6836e-05 - accuracy: 0.5040 - val_loss: 0.0042 - val_accuracy: 0.4699\n",
            "Epoch 17/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.5413e-05 - accuracy: 0.4955 - val_loss: 0.0043 - val_accuracy: 0.4699\n",
            "Epoch 18/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.4794e-05 - accuracy: 0.5121 - val_loss: 0.0045 - val_accuracy: 0.4699\n",
            "Epoch 19/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.3343e-05 - accuracy: 0.4839 - val_loss: 0.0042 - val_accuracy: 0.4659\n",
            "Epoch 20/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.4330e-05 - accuracy: 0.4893 - val_loss: 0.0043 - val_accuracy: 0.4699\n",
            "Epoch 21/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.4883e-05 - accuracy: 0.4946 - val_loss: 0.0043 - val_accuracy: 0.4699\n",
            "Epoch 22/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.5540e-05 - accuracy: 0.5054 - val_loss: 0.0042 - val_accuracy: 0.4699\n",
            "Epoch 23/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.3338e-05 - accuracy: 0.5063 - val_loss: 0.0041 - val_accuracy: 0.4699\n",
            "Epoch 24/70\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.2009e-05 - accuracy: 0.4973 - val_loss: 0.0043 - val_accuracy: 0.4699\n",
            "Epoch 25/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.3009e-05 - accuracy: 0.4911 - val_loss: 0.0045 - val_accuracy: 0.4659\n",
            "Epoch 26/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.3565e-05 - accuracy: 0.5228 - val_loss: 0.0042 - val_accuracy: 0.4699\n",
            "Epoch 27/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.9918e-05 - accuracy: 0.4933 - val_loss: 0.0042 - val_accuracy: 0.4699\n",
            "Epoch 28/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.9342e-05 - accuracy: 0.4969 - val_loss: 0.0040 - val_accuracy: 0.4699\n",
            "Epoch 29/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.2838e-05 - accuracy: 0.5027 - val_loss: 0.0044 - val_accuracy: 0.4699\n",
            "Epoch 30/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.1567e-05 - accuracy: 0.5013 - val_loss: 0.0044 - val_accuracy: 0.4699\n",
            "Epoch 31/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.0074e-05 - accuracy: 0.5157 - val_loss: 0.0046 - val_accuracy: 0.4699\n",
            "Epoch 32/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.8780e-05 - accuracy: 0.4987 - val_loss: 0.0053 - val_accuracy: 0.4699\n",
            "Epoch 33/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.8938e-05 - accuracy: 0.4924 - val_loss: 0.0049 - val_accuracy: 0.4699\n",
            "Epoch 34/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.8725e-05 - accuracy: 0.4919 - val_loss: 0.0050 - val_accuracy: 0.4699\n",
            "Epoch 35/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 5.0214e-05 - accuracy: 0.4897 - val_loss: 0.0050 - val_accuracy: 0.4699\n",
            "Epoch 36/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.7109e-05 - accuracy: 0.5009 - val_loss: 0.0047 - val_accuracy: 0.4779\n",
            "Epoch 37/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.7903e-05 - accuracy: 0.4826 - val_loss: 0.0049 - val_accuracy: 0.4699\n",
            "Epoch 38/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.5522e-05 - accuracy: 0.5134 - val_loss: 0.0047 - val_accuracy: 0.4699\n",
            "Epoch 39/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.6601e-05 - accuracy: 0.5072 - val_loss: 0.0040 - val_accuracy: 0.4699\n",
            "Epoch 40/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.7290e-05 - accuracy: 0.4718 - val_loss: 0.0064 - val_accuracy: 0.4699\n",
            "Epoch 41/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.4545e-05 - accuracy: 0.5054 - val_loss: 0.0053 - val_accuracy: 0.4739\n",
            "Epoch 42/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.4019e-05 - accuracy: 0.4955 - val_loss: 0.0055 - val_accuracy: 0.4699\n",
            "Epoch 43/70\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 4.4685e-05 - accuracy: 0.5031 - val_loss: 0.0053 - val_accuracy: 0.4699\n",
            "Epoch 44/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.5345e-05 - accuracy: 0.5063 - val_loss: 0.0047 - val_accuracy: 0.4699\n",
            "Epoch 45/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.3426e-05 - accuracy: 0.4879 - val_loss: 0.0051 - val_accuracy: 0.4699\n",
            "Epoch 46/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.3848e-05 - accuracy: 0.5000 - val_loss: 0.0045 - val_accuracy: 0.4699\n",
            "Epoch 47/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.2447e-05 - accuracy: 0.5018 - val_loss: 0.0051 - val_accuracy: 0.4699\n",
            "Epoch 48/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.3559e-05 - accuracy: 0.5063 - val_loss: 0.0041 - val_accuracy: 0.4699\n",
            "Epoch 49/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.2689e-05 - accuracy: 0.5013 - val_loss: 0.0033 - val_accuracy: 0.4699\n",
            "Epoch 50/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.2925e-05 - accuracy: 0.4978 - val_loss: 0.0045 - val_accuracy: 0.4699\n",
            "Epoch 51/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.1634e-05 - accuracy: 0.5143 - val_loss: 0.0039 - val_accuracy: 0.4699\n",
            "Epoch 52/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.3645e-05 - accuracy: 0.4951 - val_loss: 0.0034 - val_accuracy: 0.4859\n",
            "Epoch 53/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.0844e-05 - accuracy: 0.5036 - val_loss: 0.0050 - val_accuracy: 0.4699\n",
            "Epoch 54/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.1386e-05 - accuracy: 0.4964 - val_loss: 0.0038 - val_accuracy: 0.4659\n",
            "Epoch 55/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.0226e-05 - accuracy: 0.4933 - val_loss: 0.0032 - val_accuracy: 0.4699\n",
            "Epoch 56/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.2942e-05 - accuracy: 0.5076 - val_loss: 0.0040 - val_accuracy: 0.4699\n",
            "Epoch 57/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.1228e-05 - accuracy: 0.5098 - val_loss: 0.0030 - val_accuracy: 0.4699\n",
            "Epoch 58/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.1331e-05 - accuracy: 0.4754 - val_loss: 0.0026 - val_accuracy: 0.4699\n",
            "Epoch 59/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.0467e-05 - accuracy: 0.4969 - val_loss: 0.0019 - val_accuracy: 0.4739\n",
            "Epoch 60/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8899e-05 - accuracy: 0.4996 - val_loss: 0.0019 - val_accuracy: 0.4739\n",
            "Epoch 61/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.9122e-05 - accuracy: 0.4888 - val_loss: 0.0019 - val_accuracy: 0.4699\n",
            "Epoch 62/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8390e-05 - accuracy: 0.4857 - val_loss: 0.0017 - val_accuracy: 0.4659\n",
            "Epoch 63/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.9128e-05 - accuracy: 0.4933 - val_loss: 0.0018 - val_accuracy: 0.4699\n",
            "Epoch 64/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8412e-05 - accuracy: 0.4884 - val_loss: 0.0023 - val_accuracy: 0.4699\n",
            "Epoch 65/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8668e-05 - accuracy: 0.5125 - val_loss: 0.0017 - val_accuracy: 0.4699\n",
            "Epoch 66/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8547e-05 - accuracy: 0.4964 - val_loss: 0.0016 - val_accuracy: 0.4699\n",
            "Epoch 67/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.8867e-05 - accuracy: 0.5045 - val_loss: 0.0018 - val_accuracy: 0.4699\n",
            "Epoch 68/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 4.0064e-05 - accuracy: 0.5063 - val_loss: 0.0016 - val_accuracy: 0.4699\n",
            "Epoch 69/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.6658e-05 - accuracy: 0.5130 - val_loss: 0.0015 - val_accuracy: 0.4699\n",
            "Epoch 70/70\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 3.7412e-05 - accuracy: 0.5049 - val_loss: 0.0015 - val_accuracy: 0.4699\n",
            "Iteration 1 started on test\n",
            "      close\n",
            "0  1.265083\n",
            "1  1.262258\n",
            "2  1.223192\n",
            "3  1.173715\n",
            "4  1.172302\n",
            "       close\n",
            "5  52.311905\n",
            "6  63.295307\n",
            "Accuracy: 1/2\n",
            "Iteration 1 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0557 - accuracy: 0.0000e+00\n",
            "      close\n",
            "0  1.265083\n",
            "1  1.262258\n",
            "2  1.223192\n",
            "3  1.173715\n",
            "4  1.172302\n",
            "      close\n",
            "5  1.155457\n",
            "6  1.150180\n",
            "Accuracy: 1/2\n",
            "Iteration 2 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0396 - accuracy: 1.0000\n",
            "      close\n",
            "2  1.223192\n",
            "3  1.173715\n",
            "4  1.172302\n",
            "5  1.183698\n",
            "6  1.121116\n",
            "      close\n",
            "7  1.144568\n",
            "8  1.137114\n",
            "Accuracy: 0/2\n",
            "Iteration 3 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1719 - accuracy: 0.0000e+00\n",
            "      close\n",
            "4  1.172302\n",
            "5  1.183698\n",
            "6  1.121116\n",
            "7  1.056291\n",
            "8  1.168098\n",
            "       close\n",
            "9   1.134442\n",
            "10  1.106632\n",
            "Accuracy: 0/2\n",
            "Iteration 4 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2808 - accuracy: 0.0000e+00\n",
            "       close\n",
            "6   1.121116\n",
            "7   1.056291\n",
            "8   1.168098\n",
            "9   1.186161\n",
            "10  1.206307\n",
            "       close\n",
            "11  1.205812\n",
            "12  1.173007\n",
            "Accuracy: 1/2\n",
            "Iteration 5 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0720 - accuracy: 1.0000\n",
            "       close\n",
            "8   1.168098\n",
            "9   1.186161\n",
            "10  1.206307\n",
            "11  1.233497\n",
            "12  1.228501\n",
            "       close\n",
            "13  1.268747\n",
            "14  1.229207\n",
            "Accuracy: 1/2\n",
            "Iteration 6 started\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1815 - accuracy: 0.0000e+00\n",
            "       close\n",
            "10  1.206307\n",
            "11  1.233497\n",
            "12  1.228501\n",
            "13  1.258493\n",
            "14  1.278446\n",
            "       close\n",
            "15  1.296206\n",
            "16  1.274768\n",
            "Accuracy: 1/2\n",
            "Iteration 7 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0349 - accuracy: 0.0000e+00\n",
            "       close\n",
            "12  1.228501\n",
            "13  1.258493\n",
            "14  1.278446\n",
            "15  1.283504\n",
            "16  1.284084\n",
            "       close\n",
            "17  1.312440\n",
            "18  1.297655\n",
            "Accuracy: 1/2\n",
            "Iteration 8 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0803 - accuracy: 0.0000e+00\n",
            "       close\n",
            "14  1.278446\n",
            "15  1.283504\n",
            "16  1.284084\n",
            "17  1.308952\n",
            "18  1.322345\n",
            "       close\n",
            "19  1.357238\n",
            "20  1.340992\n",
            "Accuracy: 1/2\n",
            "Iteration 9 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "       close\n",
            "16  1.284084\n",
            "17  1.308952\n",
            "18  1.322345\n",
            "19  1.317730\n",
            "20  1.310068\n",
            "       close\n",
            "21  1.328769\n",
            "22  1.324848\n",
            "Accuracy: 1/2\n",
            "Iteration 10 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2397 - accuracy: 0.0000e+00\n",
            "       close\n",
            "18  1.322345\n",
            "19  1.317730\n",
            "20  1.310068\n",
            "21  1.365026\n",
            "22  1.376564\n",
            "       close\n",
            "23  1.412762\n",
            "24  1.399852\n",
            "Accuracy: 1/2\n",
            "Iteration 11 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0375 - accuracy: 0.0000e+00\n",
            "       close\n",
            "20  1.310068\n",
            "21  1.365026\n",
            "22  1.376564\n",
            "23  1.386145\n",
            "24  1.401786\n",
            "       close\n",
            "25  1.455783\n",
            "26  1.445100\n",
            "Accuracy: 2/2\n",
            "Iteration 12 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 1.0000\n",
            "       close\n",
            "22  1.376564\n",
            "23  1.386145\n",
            "24  1.401786\n",
            "25  1.470677\n",
            "26  1.427830\n",
            "       close\n",
            "27  1.538256\n",
            "28  1.531706\n",
            "Accuracy: 1/2\n",
            "Iteration 13 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1928 - accuracy: 0.0000e+00\n",
            "       close\n",
            "24  1.401786\n",
            "25  1.470677\n",
            "26  1.427830\n",
            "27  1.477640\n",
            "28  1.672566\n",
            "       close\n",
            "29  1.741328\n",
            "30  1.714764\n",
            "Accuracy: 1/2\n",
            "Iteration 14 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "       close\n",
            "26  1.427830\n",
            "27  1.477640\n",
            "28  1.672566\n",
            "29  1.798038\n",
            "30  1.823878\n",
            "       close\n",
            "31  2.180081\n",
            "32  2.153097\n",
            "Accuracy: 1/2\n",
            "Iteration 15 started\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0081 - accuracy: 0.0000e+00\n",
            "       close\n",
            "28  1.672566\n",
            "29  1.798038\n",
            "30  1.823878\n",
            "31  2.136079\n",
            "32  2.191687\n",
            "       close\n",
            "33  3.043323\n",
            "34  3.026376\n",
            "Accuracy: 1/2\n",
            "Iteration 16 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7639 - accuracy: 1.0000\n",
            "       close\n",
            "30  1.823878\n",
            "31  2.136079\n",
            "32  2.191687\n",
            "33  2.169153\n",
            "34  2.079417\n",
            "       close\n",
            "35  2.715224\n",
            "36  2.778765\n",
            "Accuracy: 1/2\n",
            "Iteration 17 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7547 - accuracy: 1.0000\n",
            "       close\n",
            "32  2.191687\n",
            "33  2.169153\n",
            "34  2.079417\n",
            "35  1.926601\n",
            "36  2.108560\n",
            "       close\n",
            "37  2.379377\n",
            "38  2.360126\n",
            "Accuracy: 1/2\n",
            "Iteration 18 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 1.0000\n",
            "       close\n",
            "34  2.079417\n",
            "35  1.926601\n",
            "36  2.108560\n",
            "37  2.428140\n",
            "38  2.457702\n",
            "       close\n",
            "39  2.768281\n",
            "40  2.747534\n",
            "Accuracy: 0/2\n",
            "Iteration 19 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0783 - accuracy: 0.0000e+00\n",
            "       close\n",
            "36  2.108560\n",
            "37  2.428140\n",
            "38  2.457702\n",
            "39  2.435435\n",
            "40  2.713725\n",
            "       close\n",
            "41  3.227755\n",
            "42  3.217978\n",
            "Accuracy: 2/2\n",
            "Iteration 20 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 1.0000\n",
            "       close\n",
            "38  2.457702\n",
            "39  2.435435\n",
            "40  2.713725\n",
            "41  2.917386\n",
            "42  2.721091\n",
            "       close\n",
            "43  3.237769\n",
            "44  3.289520\n",
            "Accuracy: 1/2\n",
            "Iteration 21 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.0000e+00\n",
            "       close\n",
            "40  2.713725\n",
            "41  2.917386\n",
            "42  2.721091\n",
            "43  2.738132\n",
            "44  2.535528\n",
            "       close\n",
            "45  2.689544\n",
            "46  2.749887\n",
            "Accuracy: 1/2\n",
            "Iteration 22 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3137 - accuracy: 0.0000e+00\n",
            "Total hits: 21. Total tries: 44. Accuracy: 0.48\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4WlN14m1lUNr",
        "outputId": "a9a13e10-2be3-4de8-c126-ec8bdb442417"
      },
      "source": [
        "seed(n_seed)\n",
        "tf.random.set_seed(n_seed)\n",
        "model = model_type(n_neurons=n_neurons, n_steps=n_steps, n_outputs=n_outputs, loss=loss, optimizer=optimizer)\n",
        "\n",
        "cm = evaluate(model, eth_stocks_close, btc_new_stocks_close, n_evaluations=n_evaluations, n_test=n_outputs, n_steps=n_steps, n_epochs=epochs, batch_size=batch_size)\n",
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 30)                3840      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 62        \n",
            "=================================================================\n",
            "Total params: 3,902\n",
            "Trainable params: 3,902\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training on train_ts\n",
            "Epoch 1/70\n",
            "122/122 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.4887 - val_loss: 0.0049 - val_accuracy: 0.5253\n",
            "Epoch 2/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 7.0073e-05 - accuracy: 0.4964 - val_loss: 0.0045 - val_accuracy: 0.5300\n",
            "Epoch 3/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.8896e-05 - accuracy: 0.5046 - val_loss: 0.0063 - val_accuracy: 0.4885\n",
            "Epoch 4/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.2083e-05 - accuracy: 0.5021 - val_loss: 0.0049 - val_accuracy: 0.4286\n",
            "Epoch 5/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.3850e-05 - accuracy: 0.5314 - val_loss: 0.0058 - val_accuracy: 0.4424\n",
            "Epoch 6/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.5314e-05 - accuracy: 0.5129 - val_loss: 0.0048 - val_accuracy: 0.4286\n",
            "Epoch 7/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.3990e-05 - accuracy: 0.5195 - val_loss: 0.0055 - val_accuracy: 0.4286\n",
            "Epoch 8/70\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 6.0208e-05 - accuracy: 0.4799 - val_loss: 0.0064 - val_accuracy: 0.4286\n",
            "Epoch 9/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.0810e-05 - accuracy: 0.5149 - val_loss: 0.0051 - val_accuracy: 0.4931\n",
            "Epoch 10/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.0674e-05 - accuracy: 0.4892 - val_loss: 0.0048 - val_accuracy: 0.4654\n",
            "Epoch 11/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8346e-05 - accuracy: 0.4959 - val_loss: 0.0040 - val_accuracy: 0.4286\n",
            "Epoch 12/70\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 6.0541e-05 - accuracy: 0.4820 - val_loss: 0.0052 - val_accuracy: 0.4286\n",
            "Epoch 13/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8821e-05 - accuracy: 0.5026 - val_loss: 0.0055 - val_accuracy: 0.4654\n",
            "Epoch 14/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.1203e-05 - accuracy: 0.4877 - val_loss: 0.0045 - val_accuracy: 0.4286\n",
            "Epoch 15/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8857e-05 - accuracy: 0.5324 - val_loss: 0.0042 - val_accuracy: 0.4931\n",
            "Epoch 16/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.1728e-05 - accuracy: 0.4938 - val_loss: 0.0037 - val_accuracy: 0.4562\n",
            "Epoch 17/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.7727e-05 - accuracy: 0.5051 - val_loss: 0.0038 - val_accuracy: 0.4378\n",
            "Epoch 18/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8433e-05 - accuracy: 0.5005 - val_loss: 0.0036 - val_accuracy: 0.4562\n",
            "Epoch 19/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.7368e-05 - accuracy: 0.4938 - val_loss: 0.0035 - val_accuracy: 0.4747\n",
            "Epoch 20/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8626e-05 - accuracy: 0.4918 - val_loss: 0.0037 - val_accuracy: 0.4286\n",
            "Epoch 21/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.6305e-05 - accuracy: 0.4913 - val_loss: 0.0034 - val_accuracy: 0.4286\n",
            "Epoch 22/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8220e-05 - accuracy: 0.4954 - val_loss: 0.0035 - val_accuracy: 0.4562\n",
            "Epoch 23/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.5999e-05 - accuracy: 0.4985 - val_loss: 0.0037 - val_accuracy: 0.4286\n",
            "Epoch 24/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.4703e-05 - accuracy: 0.4959 - val_loss: 0.0039 - val_accuracy: 0.4470\n",
            "Epoch 25/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.3977e-05 - accuracy: 0.4974 - val_loss: 0.0040 - val_accuracy: 0.5023\n",
            "Epoch 26/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.3797e-05 - accuracy: 0.5077 - val_loss: 0.0033 - val_accuracy: 0.4931\n",
            "Epoch 27/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.4889e-05 - accuracy: 0.4810 - val_loss: 0.0044 - val_accuracy: 0.4516\n",
            "Epoch 28/70\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 5.4462e-05 - accuracy: 0.5077 - val_loss: 0.0043 - val_accuracy: 0.4286\n",
            "Epoch 29/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.6183e-05 - accuracy: 0.5021 - val_loss: 0.0042 - val_accuracy: 0.4747\n",
            "Epoch 30/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.2373e-05 - accuracy: 0.5093 - val_loss: 0.0037 - val_accuracy: 0.4286\n",
            "Epoch 31/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.0349e-05 - accuracy: 0.4974 - val_loss: 0.0035 - val_accuracy: 0.4286\n",
            "Epoch 32/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.2833e-05 - accuracy: 0.4794 - val_loss: 0.0035 - val_accuracy: 0.4793\n",
            "Epoch 33/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.1680e-05 - accuracy: 0.4918 - val_loss: 0.0041 - val_accuracy: 0.4286\n",
            "Epoch 34/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.3696e-05 - accuracy: 0.4938 - val_loss: 0.0037 - val_accuracy: 0.4378\n",
            "Epoch 35/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.9240e-05 - accuracy: 0.5010 - val_loss: 0.0038 - val_accuracy: 0.4286\n",
            "Epoch 36/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.9166e-05 - accuracy: 0.4820 - val_loss: 0.0030 - val_accuracy: 0.4747\n",
            "Epoch 37/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.7534e-05 - accuracy: 0.5165 - val_loss: 0.0036 - val_accuracy: 0.5023\n",
            "Epoch 38/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.1551e-05 - accuracy: 0.4964 - val_loss: 0.0040 - val_accuracy: 0.4286\n",
            "Epoch 39/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.9238e-05 - accuracy: 0.5000 - val_loss: 0.0031 - val_accuracy: 0.4286\n",
            "Epoch 40/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.9384e-05 - accuracy: 0.5010 - val_loss: 0.0029 - val_accuracy: 0.5023\n",
            "Epoch 41/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.5646e-05 - accuracy: 0.4897 - val_loss: 0.0032 - val_accuracy: 0.4286\n",
            "Epoch 42/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.9639e-05 - accuracy: 0.4897 - val_loss: 0.0035 - val_accuracy: 0.4608\n",
            "Epoch 43/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.7566e-05 - accuracy: 0.4949 - val_loss: 0.0032 - val_accuracy: 0.4286\n",
            "Epoch 44/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.5804e-05 - accuracy: 0.4902 - val_loss: 0.0027 - val_accuracy: 0.4286\n",
            "Epoch 45/70\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 4.7036e-05 - accuracy: 0.4871 - val_loss: 0.0027 - val_accuracy: 0.4378\n",
            "Epoch 46/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.4484e-05 - accuracy: 0.4964 - val_loss: 0.0028 - val_accuracy: 0.4332\n",
            "Epoch 47/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.3484e-05 - accuracy: 0.4851 - val_loss: 0.0025 - val_accuracy: 0.4286\n",
            "Epoch 48/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.3732e-05 - accuracy: 0.4810 - val_loss: 0.0032 - val_accuracy: 0.4286\n",
            "Epoch 49/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.3967e-05 - accuracy: 0.5093 - val_loss: 0.0025 - val_accuracy: 0.4747\n",
            "Epoch 50/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.2210e-05 - accuracy: 0.5000 - val_loss: 0.0032 - val_accuracy: 0.4332\n",
            "Epoch 51/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.3406e-05 - accuracy: 0.5005 - val_loss: 0.0027 - val_accuracy: 0.4839\n",
            "Epoch 52/70\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 4.2919e-05 - accuracy: 0.4949 - val_loss: 0.0018 - val_accuracy: 0.4286\n",
            "Epoch 53/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.3269e-05 - accuracy: 0.4918 - val_loss: 0.0027 - val_accuracy: 0.4286\n",
            "Epoch 54/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.2156e-05 - accuracy: 0.4969 - val_loss: 0.0018 - val_accuracy: 0.4332\n",
            "Epoch 55/70\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 4.1920e-05 - accuracy: 0.5021 - val_loss: 0.0021 - val_accuracy: 0.4747\n",
            "Epoch 56/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.0265e-05 - accuracy: 0.4841 - val_loss: 0.0020 - val_accuracy: 0.4747\n",
            "Epoch 57/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.0528e-05 - accuracy: 0.4902 - val_loss: 0.0036 - val_accuracy: 0.4747\n",
            "Epoch 58/70\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 4.2699e-05 - accuracy: 0.5154 - val_loss: 0.0021 - val_accuracy: 0.4378\n",
            "Epoch 59/70\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 4.1101e-05 - accuracy: 0.5087 - val_loss: 0.0024 - val_accuracy: 0.4747\n",
            "Epoch 60/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.0965e-05 - accuracy: 0.5046 - val_loss: 0.0018 - val_accuracy: 0.4885\n",
            "Epoch 61/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.2302e-05 - accuracy: 0.5036 - val_loss: 0.0022 - val_accuracy: 0.4240\n",
            "Epoch 62/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.0845e-05 - accuracy: 0.4810 - val_loss: 0.0025 - val_accuracy: 0.4286\n",
            "Epoch 63/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.1386e-05 - accuracy: 0.4851 - val_loss: 0.0035 - val_accuracy: 0.4286\n",
            "Epoch 64/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.0537e-05 - accuracy: 0.4943 - val_loss: 0.0023 - val_accuracy: 0.5023\n",
            "Epoch 65/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.3360e-05 - accuracy: 0.5051 - val_loss: 0.0029 - val_accuracy: 0.4286\n",
            "Epoch 66/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 3.8781e-05 - accuracy: 0.4928 - val_loss: 0.0022 - val_accuracy: 0.4286\n",
            "Epoch 67/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.1058e-05 - accuracy: 0.4923 - val_loss: 0.0020 - val_accuracy: 0.4747\n",
            "Epoch 68/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 3.9901e-05 - accuracy: 0.4964 - val_loss: 0.0027 - val_accuracy: 0.4332\n",
            "Epoch 69/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 3.8370e-05 - accuracy: 0.5149 - val_loss: 0.0029 - val_accuracy: 0.4654\n",
            "Epoch 70/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 3.8881e-05 - accuracy: 0.5072 - val_loss: 0.0032 - val_accuracy: 0.4286\n",
            "Iteration 1 started on test\n",
            "          close\n",
            "0  32702.025391\n",
            "1  32822.347656\n",
            "2  31780.730469\n",
            "3  31421.539063\n",
            "4  31533.068359\n",
            "          close\n",
            "5  36135.187500\n",
            "6   4433.252441\n",
            "Accuracy: 2/2\n",
            "Iteration 1 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0518 - accuracy: 1.0000\n",
            "          close\n",
            "0  32702.025391\n",
            "1  32822.347656\n",
            "2  31780.730469\n",
            "3  31421.539063\n",
            "4  31533.068359\n",
            "          close\n",
            "5  31342.166016\n",
            "6  31095.294922\n",
            "Accuracy: 1/2\n",
            "Iteration 2 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0353 - accuracy: 1.0000\n",
            "          close\n",
            "2  31780.730469\n",
            "3  31421.539063\n",
            "4  31533.068359\n",
            "5  31796.810547\n",
            "6  30817.832031\n",
            "          close\n",
            "7  31076.611328\n",
            "8  30936.527344\n",
            "Accuracy: 0/2\n",
            "Iteration 3 started\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3791 - accuracy: 0.0000e+00\n",
            "          close\n",
            "4  31533.068359\n",
            "5  31796.810547\n",
            "6  30817.832031\n",
            "7  29807.347656\n",
            "8  32110.693359\n",
            "           close\n",
            "9   31183.878906\n",
            "10  30733.728516\n",
            "Accuracy: 0/2\n",
            "Iteration 4 started\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3243 - accuracy: 0.0000e+00\n",
            "           close\n",
            "6   30817.832031\n",
            "7   29807.347656\n",
            "8   32110.693359\n",
            "9   32313.105469\n",
            "10  33581.550781\n",
            "           close\n",
            "11  32809.582031\n",
            "12  32358.396484\n",
            "Accuracy: 0/2\n",
            "Iteration 5 started\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1942 - accuracy: 0.0000e+00\n",
            "           close\n",
            "8   32110.693359\n",
            "9   32313.105469\n",
            "10  33581.550781\n",
            "11  34292.445313\n",
            "12  35350.187500\n",
            "           close\n",
            "13  35395.152344\n",
            "14  34795.441406\n",
            "Accuracy: 1/2\n",
            "Iteration 6 started\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3116 - accuracy: 0.0000e+00\n",
            "           close\n",
            "10  33581.550781\n",
            "11  34292.445313\n",
            "12  35350.187500\n",
            "13  37337.535156\n",
            "14  39406.941406\n",
            "           close\n",
            "15  38646.820312\n",
            "16  38249.933594\n",
            "Accuracy: 0/2\n",
            "Iteration 7 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1094 - accuracy: 0.0000e+00\n",
            "           close\n",
            "12  35350.187500\n",
            "13  37337.535156\n",
            "14  39406.941406\n",
            "15  39995.906250\n",
            "16  40008.421875\n",
            "           close\n",
            "17  41771.105469\n",
            "18  41169.996094\n",
            "Accuracy: 2/2\n",
            "Iteration 8 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0456 - accuracy: 1.0000\n",
            "           close\n",
            "14  39406.941406\n",
            "15  39995.906250\n",
            "16  40008.421875\n",
            "17  42235.546875\n",
            "18  41626.195313\n",
            "           close\n",
            "19  44174.753906\n",
            "20  43635.019531\n",
            "Accuracy: 1/2\n",
            "Iteration 9 started\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6387 - accuracy: 1.0000\n",
            "           close\n",
            "16  40008.421875\n",
            "17  42235.546875\n",
            "18  41626.195313\n",
            "19  39974.894531\n",
            "20  39201.945313\n",
            "           close\n",
            "21  39808.121094\n",
            "22  39706.199219\n",
            "Accuracy: 0/2\n",
            "Iteration 10 started\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1251 - accuracy: 0.0000e+00\n",
            "           close\n",
            "18  41626.195313\n",
            "19  39974.894531\n",
            "20  39201.945313\n",
            "21  38152.980469\n",
            "22  39747.503906\n",
            "           close\n",
            "23  39826.578125\n",
            "24  39724.703125\n",
            "Accuracy: 1/2\n",
            "Iteration 11 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2300 - accuracy: 0.0000e+00\n",
            "           close\n",
            "20  39201.945313\n",
            "21  38152.980469\n",
            "22  39747.503906\n",
            "23  40869.554688\n",
            "24  42816.500000\n",
            "           close\n",
            "25  42094.210938\n",
            "26  42215.496094\n",
            "Accuracy: 0/2\n",
            "Iteration 12 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.0000e+00\n",
            "           close\n",
            "22  39747.503906\n",
            "23  40869.554688\n",
            "24  42816.500000\n",
            "25  44555.800781\n",
            "26  43798.117188\n",
            "           close\n",
            "27  45466.246094\n",
            "28  45615.355469\n",
            "Accuracy: 1/2\n",
            "Iteration 13 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.0000e+00\n",
            "           close\n",
            "24  42816.500000\n",
            "25  44555.800781\n",
            "26  43798.117188\n",
            "27  46365.402344\n",
            "28  45585.031250\n",
            "           close\n",
            "29  47648.761719\n",
            "30  47848.035156\n",
            "Accuracy: 1/2\n",
            "Iteration 14 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1555 - accuracy: 0.0000e+00\n",
            "           close\n",
            "26  43798.117188\n",
            "27  46365.402344\n",
            "28  45585.031250\n",
            "29  45593.636719\n",
            "30  44428.289063\n",
            "           close\n",
            "31  45358.804688\n",
            "32  45534.652344\n",
            "Accuracy: 1/2\n",
            "Iteration 15 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2742 - accuracy: 0.0000e+00\n",
            "           close\n",
            "28  45585.031250\n",
            "29  45593.636719\n",
            "30  44428.289063\n",
            "31  47793.320313\n",
            "32  47096.945313\n",
            "           close\n",
            "33  47782.105469\n",
            "34  47945.625000\n",
            "Accuracy: 0/2\n",
            "Iteration 16 started\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1099 - accuracy: 0.0000e+00\n",
            "           close\n",
            "30  44428.289063\n",
            "31  47793.320313\n",
            "32  47096.945313\n",
            "33  47047.003906\n",
            "34  46004.484375\n",
            "           close\n",
            "35  46972.656250\n",
            "36  47093.503906\n",
            "Accuracy: 1/2\n",
            "Iteration 17 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 1.0000\n",
            "           close\n",
            "32  47096.945313\n",
            "33  47047.003906\n",
            "34  46004.484375\n",
            "35  44695.359375\n",
            "36  44801.187500\n",
            "           close\n",
            "37  45338.648438\n",
            "38  45417.886719\n",
            "Accuracy: 2/2\n",
            "Iteration 18 started\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3335 - accuracy: 1.0000\n",
            "           close\n",
            "34  46004.484375\n",
            "35  44695.359375\n",
            "36  44801.187500\n",
            "37  46717.578125\n",
            "38  49339.175781\n",
            "           close\n",
            "39  48020.367188\n",
            "40  48194.125000\n",
            "Accuracy: 2/2\n",
            "Iteration 19 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0476 - accuracy: 1.0000\n",
            "           close\n",
            "36  44801.187500\n",
            "37  46717.578125\n",
            "38  49339.175781\n",
            "39  48905.492188\n",
            "40  49321.652344\n",
            "           close\n",
            "41  50144.906250\n",
            "42  50288.207031\n",
            "Accuracy: 1/2\n",
            "Iteration 20 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1458 - accuracy: 0.0000e+00\n",
            "           close\n",
            "38  49339.175781\n",
            "39  48905.492188\n",
            "40  49321.652344\n",
            "41  49546.148438\n",
            "42  47706.117188\n",
            "           close\n",
            "43  48749.296875\n",
            "44  48923.492188\n",
            "Accuracy: 1/2\n",
            "Iteration 21 started\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1943 - accuracy: 0.0000e+00\n",
            "           close\n",
            "40  49321.652344\n",
            "41  49546.148438\n",
            "42  47706.117188\n",
            "43  48960.789063\n",
            "44  46942.218750\n",
            "           close\n",
            "45  47369.386719\n",
            "46  47529.066406\n",
            "Accuracy: 1/2\n",
            "Iteration 22 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3495 - accuracy: 0.0000e+00\n",
            "Total hits: 19. Total tries: 44. Accuracy: 0.43\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0pnvYOpMj5Wh",
        "outputId": "c9d6a0c9-4d44-463d-da75-6117b24b3bad"
      },
      "source": [
        "seed(n_seed)\n",
        "tf.random.set_seed(n_seed)\n",
        "model = model_type(n_neurons=n_neurons, n_steps=n_steps, n_outputs=n_outputs, loss=loss, optimizer=optimizer)\n",
        "\n",
        "cm = evaluate(model, eth_stocks_close, eth_new_stocks_close, n_evaluations=n_evaluations, n_test=n_outputs, n_steps=n_steps, n_epochs=epochs, batch_size=batch_size)\n",
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 30)                3840      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 62        \n",
            "=================================================================\n",
            "Total params: 3,902\n",
            "Trainable params: 3,902\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training on train_ts\n",
            "Epoch 1/70\n",
            "122/122 [==============================] - 2s 6ms/step - loss: 0.0011 - accuracy: 0.4887 - val_loss: 0.0049 - val_accuracy: 0.5253\n",
            "Epoch 2/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 7.0073e-05 - accuracy: 0.4964 - val_loss: 0.0045 - val_accuracy: 0.5300\n",
            "Epoch 3/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.8896e-05 - accuracy: 0.5046 - val_loss: 0.0063 - val_accuracy: 0.4885\n",
            "Epoch 4/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.2083e-05 - accuracy: 0.5021 - val_loss: 0.0049 - val_accuracy: 0.4286\n",
            "Epoch 5/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.3850e-05 - accuracy: 0.5314 - val_loss: 0.0058 - val_accuracy: 0.4424\n",
            "Epoch 6/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.5314e-05 - accuracy: 0.5129 - val_loss: 0.0048 - val_accuracy: 0.4286\n",
            "Epoch 7/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.3990e-05 - accuracy: 0.5195 - val_loss: 0.0055 - val_accuracy: 0.4286\n",
            "Epoch 8/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.0208e-05 - accuracy: 0.4799 - val_loss: 0.0064 - val_accuracy: 0.4286\n",
            "Epoch 9/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.0810e-05 - accuracy: 0.5149 - val_loss: 0.0051 - val_accuracy: 0.4931\n",
            "Epoch 10/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.0674e-05 - accuracy: 0.4892 - val_loss: 0.0048 - val_accuracy: 0.4654\n",
            "Epoch 11/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8346e-05 - accuracy: 0.4959 - val_loss: 0.0040 - val_accuracy: 0.4286\n",
            "Epoch 12/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.0541e-05 - accuracy: 0.4820 - val_loss: 0.0052 - val_accuracy: 0.4286\n",
            "Epoch 13/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8821e-05 - accuracy: 0.5026 - val_loss: 0.0055 - val_accuracy: 0.4654\n",
            "Epoch 14/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.1203e-05 - accuracy: 0.4877 - val_loss: 0.0045 - val_accuracy: 0.4286\n",
            "Epoch 15/70\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 5.8857e-05 - accuracy: 0.5324 - val_loss: 0.0042 - val_accuracy: 0.4931\n",
            "Epoch 16/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.1728e-05 - accuracy: 0.4938 - val_loss: 0.0037 - val_accuracy: 0.4562\n",
            "Epoch 17/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.7727e-05 - accuracy: 0.5051 - val_loss: 0.0038 - val_accuracy: 0.4378\n",
            "Epoch 18/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8433e-05 - accuracy: 0.5005 - val_loss: 0.0036 - val_accuracy: 0.4562\n",
            "Epoch 19/70\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 5.7368e-05 - accuracy: 0.4938 - val_loss: 0.0035 - val_accuracy: 0.4747\n",
            "Epoch 20/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8626e-05 - accuracy: 0.4918 - val_loss: 0.0037 - val_accuracy: 0.4286\n",
            "Epoch 21/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.6305e-05 - accuracy: 0.4913 - val_loss: 0.0034 - val_accuracy: 0.4286\n",
            "Epoch 22/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8220e-05 - accuracy: 0.4954 - val_loss: 0.0035 - val_accuracy: 0.4562\n",
            "Epoch 23/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.5999e-05 - accuracy: 0.4985 - val_loss: 0.0037 - val_accuracy: 0.4286\n",
            "Epoch 24/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.4703e-05 - accuracy: 0.4959 - val_loss: 0.0039 - val_accuracy: 0.4470\n",
            "Epoch 25/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.3977e-05 - accuracy: 0.4974 - val_loss: 0.0040 - val_accuracy: 0.5023\n",
            "Epoch 26/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.3797e-05 - accuracy: 0.5077 - val_loss: 0.0033 - val_accuracy: 0.4931\n",
            "Epoch 27/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.4889e-05 - accuracy: 0.4810 - val_loss: 0.0044 - val_accuracy: 0.4516\n",
            "Epoch 28/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.4462e-05 - accuracy: 0.5077 - val_loss: 0.0043 - val_accuracy: 0.4286\n",
            "Epoch 29/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.6183e-05 - accuracy: 0.5021 - val_loss: 0.0042 - val_accuracy: 0.4747\n",
            "Epoch 30/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.2373e-05 - accuracy: 0.5093 - val_loss: 0.0037 - val_accuracy: 0.4286\n",
            "Epoch 31/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.0349e-05 - accuracy: 0.4974 - val_loss: 0.0035 - val_accuracy: 0.4286\n",
            "Epoch 32/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.2833e-05 - accuracy: 0.4794 - val_loss: 0.0035 - val_accuracy: 0.4793\n",
            "Epoch 33/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.1680e-05 - accuracy: 0.4918 - val_loss: 0.0041 - val_accuracy: 0.4286\n",
            "Epoch 34/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.3696e-05 - accuracy: 0.4938 - val_loss: 0.0037 - val_accuracy: 0.4378\n",
            "Epoch 35/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.9240e-05 - accuracy: 0.5010 - val_loss: 0.0038 - val_accuracy: 0.4286\n",
            "Epoch 36/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.9166e-05 - accuracy: 0.4820 - val_loss: 0.0030 - val_accuracy: 0.4747\n",
            "Epoch 37/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.7534e-05 - accuracy: 0.5165 - val_loss: 0.0036 - val_accuracy: 0.5023\n",
            "Epoch 38/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.1551e-05 - accuracy: 0.4964 - val_loss: 0.0040 - val_accuracy: 0.4286\n",
            "Epoch 39/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.9238e-05 - accuracy: 0.5000 - val_loss: 0.0031 - val_accuracy: 0.4286\n",
            "Epoch 40/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.9384e-05 - accuracy: 0.5010 - val_loss: 0.0029 - val_accuracy: 0.5023\n",
            "Epoch 41/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.5646e-05 - accuracy: 0.4897 - val_loss: 0.0032 - val_accuracy: 0.4286\n",
            "Epoch 42/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.9639e-05 - accuracy: 0.4897 - val_loss: 0.0035 - val_accuracy: 0.4608\n",
            "Epoch 43/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.7566e-05 - accuracy: 0.4949 - val_loss: 0.0032 - val_accuracy: 0.4286\n",
            "Epoch 44/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.5804e-05 - accuracy: 0.4902 - val_loss: 0.0027 - val_accuracy: 0.4286\n",
            "Epoch 45/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.7036e-05 - accuracy: 0.4871 - val_loss: 0.0027 - val_accuracy: 0.4378\n",
            "Epoch 46/70\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 4.4484e-05 - accuracy: 0.4964 - val_loss: 0.0028 - val_accuracy: 0.4332\n",
            "Epoch 47/70\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 4.3484e-05 - accuracy: 0.4851 - val_loss: 0.0025 - val_accuracy: 0.4286\n",
            "Epoch 48/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.3732e-05 - accuracy: 0.4810 - val_loss: 0.0032 - val_accuracy: 0.4286\n",
            "Epoch 49/70\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 4.3967e-05 - accuracy: 0.5093 - val_loss: 0.0025 - val_accuracy: 0.4747\n",
            "Epoch 50/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.2210e-05 - accuracy: 0.5000 - val_loss: 0.0032 - val_accuracy: 0.4332\n",
            "Epoch 51/70\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 4.3406e-05 - accuracy: 0.5005 - val_loss: 0.0027 - val_accuracy: 0.4839\n",
            "Epoch 52/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.2919e-05 - accuracy: 0.4949 - val_loss: 0.0018 - val_accuracy: 0.4286\n",
            "Epoch 53/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.3269e-05 - accuracy: 0.4918 - val_loss: 0.0027 - val_accuracy: 0.4286\n",
            "Epoch 54/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.2156e-05 - accuracy: 0.4969 - val_loss: 0.0018 - val_accuracy: 0.4332\n",
            "Epoch 55/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.1920e-05 - accuracy: 0.5021 - val_loss: 0.0021 - val_accuracy: 0.4747\n",
            "Epoch 56/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.0265e-05 - accuracy: 0.4841 - val_loss: 0.0020 - val_accuracy: 0.4747\n",
            "Epoch 57/70\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 4.0528e-05 - accuracy: 0.4902 - val_loss: 0.0036 - val_accuracy: 0.4747\n",
            "Epoch 58/70\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 4.2699e-05 - accuracy: 0.5154 - val_loss: 0.0021 - val_accuracy: 0.4378\n",
            "Epoch 59/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.1101e-05 - accuracy: 0.5087 - val_loss: 0.0024 - val_accuracy: 0.4747\n",
            "Epoch 60/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.0965e-05 - accuracy: 0.5046 - val_loss: 0.0018 - val_accuracy: 0.4885\n",
            "Epoch 61/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.2302e-05 - accuracy: 0.5036 - val_loss: 0.0022 - val_accuracy: 0.4240\n",
            "Epoch 62/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.0845e-05 - accuracy: 0.4810 - val_loss: 0.0025 - val_accuracy: 0.4286\n",
            "Epoch 63/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.1386e-05 - accuracy: 0.4851 - val_loss: 0.0035 - val_accuracy: 0.4286\n",
            "Epoch 64/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.0537e-05 - accuracy: 0.4943 - val_loss: 0.0023 - val_accuracy: 0.5023\n",
            "Epoch 65/70\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 4.3360e-05 - accuracy: 0.5051 - val_loss: 0.0029 - val_accuracy: 0.4286\n",
            "Epoch 66/70\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 3.8781e-05 - accuracy: 0.4928 - val_loss: 0.0022 - val_accuracy: 0.4286\n",
            "Epoch 67/70\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 4.1058e-05 - accuracy: 0.4923 - val_loss: 0.0020 - val_accuracy: 0.4747\n",
            "Epoch 68/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 3.9901e-05 - accuracy: 0.4964 - val_loss: 0.0027 - val_accuracy: 0.4332\n",
            "Epoch 69/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 3.8370e-05 - accuracy: 0.5149 - val_loss: 0.0029 - val_accuracy: 0.4654\n",
            "Epoch 70/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 3.8881e-05 - accuracy: 0.5072 - val_loss: 0.0032 - val_accuracy: 0.4286\n",
            "Iteration 1 started on test\n",
            "         close\n",
            "0  1940.083984\n",
            "1  1994.331299\n",
            "2  1911.175659\n",
            "3  1880.382935\n",
            "4  1898.825195\n",
            "         close\n",
            "5  1822.717529\n",
            "6  1724.209717\n",
            "Accuracy: 2/2\n",
            "Iteration 1 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0465 - accuracy: 1.0000\n",
            "         close\n",
            "0  1940.083984\n",
            "1  1994.331299\n",
            "2  1911.175659\n",
            "3  1880.382935\n",
            "4  1898.825195\n",
            "         close\n",
            "5  1876.107178\n",
            "6  1857.609131\n",
            "Accuracy: 2/2\n",
            "Iteration 2 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0320 - accuracy: 1.0000\n",
            "         close\n",
            "2  1911.175659\n",
            "3  1880.382935\n",
            "4  1898.825195\n",
            "5  1895.552124\n",
            "6  1817.296631\n",
            "         close\n",
            "7  1830.671875\n",
            "8  1819.994385\n",
            "Accuracy: 0/2\n",
            "Iteration 3 started\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4365 - accuracy: 0.0000e+00\n",
            "         close\n",
            "4  1898.825195\n",
            "5  1895.552124\n",
            "6  1817.296631\n",
            "7  1787.510742\n",
            "8  1990.970825\n",
            "          close\n",
            "9   1882.857544\n",
            "10  1852.468994\n",
            "Accuracy: 0/2\n",
            "Iteration 4 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.0000e+00\n",
            "          close\n",
            "6   1817.296631\n",
            "7   1787.510742\n",
            "8   1990.970825\n",
            "9   2025.202759\n",
            "10  2124.776611\n",
            "          close\n",
            "11  2051.206055\n",
            "12  2000.723755\n",
            "Accuracy: 0/2\n",
            "Iteration 5 started\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1815 - accuracy: 0.0000e+00\n",
            "          close\n",
            "8   1990.970825\n",
            "9   2025.202759\n",
            "10  2124.776611\n",
            "11  2189.218750\n",
            "12  2191.373779\n",
            "          close\n",
            "13  2241.822266\n",
            "14  2143.660645\n",
            "Accuracy: 1/2\n",
            "Iteration 6 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1422 - accuracy: 0.0000e+00\n",
            "          close\n",
            "10  2124.776611\n",
            "11  2189.218750\n",
            "12  2191.373779\n",
            "13  2233.366699\n",
            "14  2298.333496\n",
            "          close\n",
            "15  2342.804932\n",
            "16  2281.427246\n",
            "Accuracy: 0/2\n",
            "Iteration 7 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1339 - accuracy: 0.0000e+00\n",
            "          close\n",
            "12  2191.373779\n",
            "13  2233.366699\n",
            "14  2298.333496\n",
            "15  2296.545410\n",
            "16  2380.956787\n",
            "          close\n",
            "17  2410.520996\n",
            "18  2369.643799\n",
            "Accuracy: 1/2\n",
            "Iteration 8 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1978 - accuracy: 0.0000e+00\n",
            "          close\n",
            "14  2298.333496\n",
            "15  2296.545410\n",
            "16  2380.956787\n",
            "17  2466.961426\n",
            "18  2536.209961\n",
            "          close\n",
            "19  2608.392334\n",
            "20  2555.440186\n",
            "Accuracy: 1/2\n",
            "Iteration 9 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.0000e+00\n",
            "          close\n",
            "16  2380.956787\n",
            "17  2466.961426\n",
            "18  2536.209961\n",
            "19  2561.852051\n",
            "20  2610.153320\n",
            "          close\n",
            "21  2751.869629\n",
            "22  2687.568848\n",
            "Accuracy: 0/2\n",
            "Iteration 10 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1511 - accuracy: 0.0000e+00\n",
            "          close\n",
            "18  2536.209961\n",
            "19  2561.852051\n",
            "20  2610.153320\n",
            "21  2502.349609\n",
            "22  2724.619873\n",
            "          close\n",
            "23  2797.239258\n",
            "24  2749.840576\n",
            "Accuracy: 1/2\n",
            "Iteration 11 started\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1976 - accuracy: 0.0000e+00\n",
            "          close\n",
            "20  2610.153320\n",
            "21  2502.349609\n",
            "22  2724.619873\n",
            "23  2827.328857\n",
            "24  2890.941650\n",
            "          close\n",
            "25  3038.159668\n",
            "26  3015.244385\n",
            "Accuracy: 2/2\n",
            "Iteration 12 started\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "          close\n",
            "22  2724.619873\n",
            "23  2827.328857\n",
            "24  2890.941650\n",
            "25  3157.238770\n",
            "26  3013.732666\n",
            "          close\n",
            "27  3420.306641\n",
            "28  3378.514648\n",
            "Accuracy: 2/2\n",
            "Iteration 13 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0147 - accuracy: 1.0000\n",
            "          close\n",
            "24  2890.941650\n",
            "25  3157.238770\n",
            "26  3013.732666\n",
            "27  3167.856201\n",
            "28  3141.691162\n",
            "          close\n",
            "29  3524.239014\n",
            "30  3486.301270\n",
            "Accuracy: 2/2\n",
            "Iteration 14 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7662 - accuracy: 1.0000\n",
            "          close\n",
            "26  3013.732666\n",
            "27  3167.856201\n",
            "28  3141.691162\n",
            "29  3164.245117\n",
            "30  3043.414307\n",
            "          close\n",
            "31  3176.093750\n",
            "32  3157.479004\n",
            "Accuracy: 2/2\n",
            "Iteration 15 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2330 - accuracy: 0.0000e+00\n",
            "          close\n",
            "28  3141.691162\n",
            "29  3164.245117\n",
            "30  3043.414307\n",
            "31  3322.211670\n",
            "32  3265.443359\n",
            "          close\n",
            "33  3408.939697\n",
            "34  3397.248535\n",
            "Accuracy: 2/2\n",
            "Iteration 16 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 1.0000\n",
            "          close\n",
            "30  3043.414307\n",
            "31  3322.211670\n",
            "32  3265.443359\n",
            "33  3310.504150\n",
            "34  3156.509521\n",
            "          close\n",
            "35  3245.147217\n",
            "36  3234.760254\n",
            "Accuracy: 0/2\n",
            "Iteration 17 started\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5844 - accuracy: 0.0000e+00\n",
            "          close\n",
            "32  3265.443359\n",
            "33  3310.504150\n",
            "34  3156.509521\n",
            "35  3014.845947\n",
            "36  3020.089844\n",
            "          close\n",
            "37  3006.853271\n",
            "38  2960.195557\n",
            "Accuracy: 0/2\n",
            "Iteration 18 started\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8267 - accuracy: 0.0000e+00\n",
            "          close\n",
            "34  3156.509521\n",
            "35  3014.845947\n",
            "36  3020.089844\n",
            "37  3182.702148\n",
            "38  3286.935303\n",
            "          close\n",
            "39  3291.439453\n",
            "40  3291.291992\n",
            "Accuracy: 0/2\n",
            "Iteration 19 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0452 - accuracy: 0.0000e+00\n",
            "          close\n",
            "36  3020.089844\n",
            "37  3182.702148\n",
            "38  3286.935303\n",
            "39  3226.083984\n",
            "40  3242.115479\n",
            "          close\n",
            "41  3314.883301\n",
            "42  3295.149902\n",
            "Accuracy: 2/2\n",
            "Iteration 20 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0899 - accuracy: 1.0000\n",
            "          close\n",
            "38  3286.935303\n",
            "39  3226.083984\n",
            "40  3242.115479\n",
            "41  3319.257324\n",
            "42  3172.456299\n",
            "          close\n",
            "43  3194.427246\n",
            "44  3165.588135\n",
            "Accuracy: 2/2\n",
            "Iteration 21 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0738 - accuracy: 1.0000\n",
            "          close\n",
            "40  3242.115479\n",
            "41  3319.257324\n",
            "42  3172.456299\n",
            "43  3224.915283\n",
            "44  3100.325439\n",
            "          close\n",
            "45  3113.115479\n",
            "46  3091.468262\n",
            "Accuracy: 2/2\n",
            "Iteration 22 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 1.0000\n",
            "Total hits: 24. Total tries: 44. Accuracy: 0.55\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZeCpGD3RlWcl",
        "outputId": "51c8f528-5e12-4e39-d5e1-f56a111855b1"
      },
      "source": [
        "seed(n_seed)\n",
        "tf.random.set_seed(n_seed)\n",
        "model = model_type(n_neurons=n_neurons, n_steps=n_steps, n_outputs=n_outputs, loss=loss, optimizer=optimizer)\n",
        "\n",
        "cm = evaluate(model, eth_stocks_close, ada_new_stocks_close, n_evaluations=n_evaluations, n_test=n_outputs, n_steps=n_steps, n_epochs=epochs, batch_size=batch_size)\n",
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_5 (LSTM)                (None, 30)                3840      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 62        \n",
            "=================================================================\n",
            "Total params: 3,902\n",
            "Trainable params: 3,902\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training on train_ts\n",
            "Epoch 1/70\n",
            "122/122 [==============================] - 2s 6ms/step - loss: 0.0011 - accuracy: 0.4887 - val_loss: 0.0049 - val_accuracy: 0.5253\n",
            "Epoch 2/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 7.0073e-05 - accuracy: 0.4964 - val_loss: 0.0045 - val_accuracy: 0.5300\n",
            "Epoch 3/70\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 6.8896e-05 - accuracy: 0.5046 - val_loss: 0.0063 - val_accuracy: 0.4885\n",
            "Epoch 4/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.2083e-05 - accuracy: 0.5021 - val_loss: 0.0049 - val_accuracy: 0.4286\n",
            "Epoch 5/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.3850e-05 - accuracy: 0.5314 - val_loss: 0.0058 - val_accuracy: 0.4424\n",
            "Epoch 6/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.5314e-05 - accuracy: 0.5129 - val_loss: 0.0048 - val_accuracy: 0.4286\n",
            "Epoch 7/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.3990e-05 - accuracy: 0.5195 - val_loss: 0.0055 - val_accuracy: 0.4286\n",
            "Epoch 8/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.0208e-05 - accuracy: 0.4799 - val_loss: 0.0064 - val_accuracy: 0.4286\n",
            "Epoch 9/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.0810e-05 - accuracy: 0.5149 - val_loss: 0.0051 - val_accuracy: 0.4931\n",
            "Epoch 10/70\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 6.0674e-05 - accuracy: 0.4892 - val_loss: 0.0048 - val_accuracy: 0.4654\n",
            "Epoch 11/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8346e-05 - accuracy: 0.4959 - val_loss: 0.0040 - val_accuracy: 0.4286\n",
            "Epoch 12/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.0541e-05 - accuracy: 0.4820 - val_loss: 0.0052 - val_accuracy: 0.4286\n",
            "Epoch 13/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8821e-05 - accuracy: 0.5026 - val_loss: 0.0055 - val_accuracy: 0.4654\n",
            "Epoch 14/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 6.1203e-05 - accuracy: 0.4877 - val_loss: 0.0045 - val_accuracy: 0.4286\n",
            "Epoch 15/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8857e-05 - accuracy: 0.5324 - val_loss: 0.0042 - val_accuracy: 0.4931\n",
            "Epoch 16/70\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 6.1728e-05 - accuracy: 0.4938 - val_loss: 0.0037 - val_accuracy: 0.4562\n",
            "Epoch 17/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.7727e-05 - accuracy: 0.5051 - val_loss: 0.0038 - val_accuracy: 0.4378\n",
            "Epoch 18/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8433e-05 - accuracy: 0.5005 - val_loss: 0.0036 - val_accuracy: 0.4562\n",
            "Epoch 19/70\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 5.7368e-05 - accuracy: 0.4938 - val_loss: 0.0035 - val_accuracy: 0.4747\n",
            "Epoch 20/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8626e-05 - accuracy: 0.4918 - val_loss: 0.0037 - val_accuracy: 0.4286\n",
            "Epoch 21/70\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 5.6305e-05 - accuracy: 0.4913 - val_loss: 0.0034 - val_accuracy: 0.4286\n",
            "Epoch 22/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.8220e-05 - accuracy: 0.4954 - val_loss: 0.0035 - val_accuracy: 0.4562\n",
            "Epoch 23/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.5999e-05 - accuracy: 0.4985 - val_loss: 0.0037 - val_accuracy: 0.4286\n",
            "Epoch 24/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.4703e-05 - accuracy: 0.4959 - val_loss: 0.0039 - val_accuracy: 0.4470\n",
            "Epoch 25/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.3977e-05 - accuracy: 0.4974 - val_loss: 0.0040 - val_accuracy: 0.5023\n",
            "Epoch 26/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.3797e-05 - accuracy: 0.5077 - val_loss: 0.0033 - val_accuracy: 0.4931\n",
            "Epoch 27/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.4889e-05 - accuracy: 0.4810 - val_loss: 0.0044 - val_accuracy: 0.4516\n",
            "Epoch 28/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.4462e-05 - accuracy: 0.5077 - val_loss: 0.0043 - val_accuracy: 0.4286\n",
            "Epoch 29/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.6183e-05 - accuracy: 0.5021 - val_loss: 0.0042 - val_accuracy: 0.4747\n",
            "Epoch 30/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.2373e-05 - accuracy: 0.5093 - val_loss: 0.0037 - val_accuracy: 0.4286\n",
            "Epoch 31/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.0349e-05 - accuracy: 0.4974 - val_loss: 0.0035 - val_accuracy: 0.4286\n",
            "Epoch 32/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.2833e-05 - accuracy: 0.4794 - val_loss: 0.0035 - val_accuracy: 0.4793\n",
            "Epoch 33/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.1680e-05 - accuracy: 0.4918 - val_loss: 0.0041 - val_accuracy: 0.4286\n",
            "Epoch 34/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 5.3696e-05 - accuracy: 0.4938 - val_loss: 0.0037 - val_accuracy: 0.4378\n",
            "Epoch 35/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.9240e-05 - accuracy: 0.5010 - val_loss: 0.0038 - val_accuracy: 0.4286\n",
            "Epoch 36/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.9166e-05 - accuracy: 0.4820 - val_loss: 0.0030 - val_accuracy: 0.4747\n",
            "Epoch 37/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.7534e-05 - accuracy: 0.5165 - val_loss: 0.0036 - val_accuracy: 0.5023\n",
            "Epoch 38/70\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 5.1551e-05 - accuracy: 0.4964 - val_loss: 0.0040 - val_accuracy: 0.4286\n",
            "Epoch 39/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.9238e-05 - accuracy: 0.5000 - val_loss: 0.0031 - val_accuracy: 0.4286\n",
            "Epoch 40/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.9384e-05 - accuracy: 0.5010 - val_loss: 0.0029 - val_accuracy: 0.5023\n",
            "Epoch 41/70\n",
            "122/122 [==============================] - 1s 4ms/step - loss: 4.5646e-05 - accuracy: 0.4897 - val_loss: 0.0032 - val_accuracy: 0.4286\n",
            "Epoch 42/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.9639e-05 - accuracy: 0.4897 - val_loss: 0.0035 - val_accuracy: 0.4608\n",
            "Epoch 43/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.7566e-05 - accuracy: 0.4949 - val_loss: 0.0032 - val_accuracy: 0.4286\n",
            "Epoch 44/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.5804e-05 - accuracy: 0.4902 - val_loss: 0.0027 - val_accuracy: 0.4286\n",
            "Epoch 45/70\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 4.7036e-05 - accuracy: 0.4871 - val_loss: 0.0027 - val_accuracy: 0.4378\n",
            "Epoch 46/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.4484e-05 - accuracy: 0.4964 - val_loss: 0.0028 - val_accuracy: 0.4332\n",
            "Epoch 47/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.3484e-05 - accuracy: 0.4851 - val_loss: 0.0025 - val_accuracy: 0.4286\n",
            "Epoch 48/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.3732e-05 - accuracy: 0.4810 - val_loss: 0.0032 - val_accuracy: 0.4286\n",
            "Epoch 49/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.3967e-05 - accuracy: 0.5093 - val_loss: 0.0025 - val_accuracy: 0.4747\n",
            "Epoch 50/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.2210e-05 - accuracy: 0.5000 - val_loss: 0.0032 - val_accuracy: 0.4332\n",
            "Epoch 51/70\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 4.3406e-05 - accuracy: 0.5005 - val_loss: 0.0027 - val_accuracy: 0.4839\n",
            "Epoch 52/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.2919e-05 - accuracy: 0.4949 - val_loss: 0.0018 - val_accuracy: 0.4286\n",
            "Epoch 53/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.3269e-05 - accuracy: 0.4918 - val_loss: 0.0027 - val_accuracy: 0.4286\n",
            "Epoch 54/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.2156e-05 - accuracy: 0.4969 - val_loss: 0.0018 - val_accuracy: 0.4332\n",
            "Epoch 55/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.1920e-05 - accuracy: 0.5021 - val_loss: 0.0021 - val_accuracy: 0.4747\n",
            "Epoch 56/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.0265e-05 - accuracy: 0.4841 - val_loss: 0.0020 - val_accuracy: 0.4747\n",
            "Epoch 57/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.0528e-05 - accuracy: 0.4902 - val_loss: 0.0036 - val_accuracy: 0.4747\n",
            "Epoch 58/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.2699e-05 - accuracy: 0.5154 - val_loss: 0.0021 - val_accuracy: 0.4378\n",
            "Epoch 59/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.1101e-05 - accuracy: 0.5087 - val_loss: 0.0024 - val_accuracy: 0.4747\n",
            "Epoch 60/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.0965e-05 - accuracy: 0.5046 - val_loss: 0.0018 - val_accuracy: 0.4885\n",
            "Epoch 61/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.2302e-05 - accuracy: 0.5036 - val_loss: 0.0022 - val_accuracy: 0.4240\n",
            "Epoch 62/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.0845e-05 - accuracy: 0.4810 - val_loss: 0.0025 - val_accuracy: 0.4286\n",
            "Epoch 63/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.1386e-05 - accuracy: 0.4851 - val_loss: 0.0035 - val_accuracy: 0.4286\n",
            "Epoch 64/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.0537e-05 - accuracy: 0.4943 - val_loss: 0.0023 - val_accuracy: 0.5023\n",
            "Epoch 65/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.3360e-05 - accuracy: 0.5051 - val_loss: 0.0029 - val_accuracy: 0.4286\n",
            "Epoch 66/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 3.8781e-05 - accuracy: 0.4928 - val_loss: 0.0022 - val_accuracy: 0.4286\n",
            "Epoch 67/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 4.1058e-05 - accuracy: 0.4923 - val_loss: 0.0020 - val_accuracy: 0.4747\n",
            "Epoch 68/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 3.9901e-05 - accuracy: 0.4964 - val_loss: 0.0027 - val_accuracy: 0.4332\n",
            "Epoch 69/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 3.8370e-05 - accuracy: 0.5149 - val_loss: 0.0029 - val_accuracy: 0.4654\n",
            "Epoch 70/70\n",
            "122/122 [==============================] - 0s 4ms/step - loss: 3.8881e-05 - accuracy: 0.5072 - val_loss: 0.0032 - val_accuracy: 0.4286\n",
            "Iteration 1 started on test\n",
            "      close\n",
            "0  1.265083\n",
            "1  1.262258\n",
            "2  1.223192\n",
            "3  1.173715\n",
            "4  1.172302\n",
            "      close\n",
            "5  6.271215\n",
            "6  3.654568\n",
            "Accuracy: 2/2\n",
            "Iteration 1 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0382 - accuracy: 1.0000\n",
            "      close\n",
            "0  1.265083\n",
            "1  1.262258\n",
            "2  1.223192\n",
            "3  1.173715\n",
            "4  1.172302\n",
            "      close\n",
            "5  1.158146\n",
            "6  1.139222\n",
            "Accuracy: 1/2\n",
            "Iteration 2 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "      close\n",
            "2  1.223192\n",
            "3  1.173715\n",
            "4  1.172302\n",
            "5  1.183698\n",
            "6  1.121116\n",
            "      close\n",
            "7  1.139760\n",
            "8  1.127401\n",
            "Accuracy: 0/2\n",
            "Iteration 3 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1945 - accuracy: 0.0000e+00\n",
            "      close\n",
            "4  1.172302\n",
            "5  1.183698\n",
            "6  1.121116\n",
            "7  1.056291\n",
            "8  1.168098\n",
            "       close\n",
            "9   1.122993\n",
            "10  1.098048\n",
            "Accuracy: 0/2\n",
            "Iteration 4 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3556 - accuracy: 0.0000e+00\n",
            "       close\n",
            "6   1.121116\n",
            "7   1.056291\n",
            "8   1.168098\n",
            "9   1.186161\n",
            "10  1.206307\n",
            "       close\n",
            "11  1.191402\n",
            "12  1.166902\n",
            "Accuracy: 1/2\n",
            "Iteration 5 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0988 - accuracy: 1.0000\n",
            "       close\n",
            "8   1.168098\n",
            "9   1.186161\n",
            "10  1.206307\n",
            "11  1.233497\n",
            "12  1.228501\n",
            "       close\n",
            "13  1.258442\n",
            "14  1.221549\n",
            "Accuracy: 1/2\n",
            "Iteration 6 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1982 - accuracy: 0.0000e+00\n",
            "       close\n",
            "10  1.206307\n",
            "11  1.233497\n",
            "12  1.228501\n",
            "13  1.258493\n",
            "14  1.278446\n",
            "       close\n",
            "15  1.284948\n",
            "16  1.271724\n",
            "Accuracy: 1/2\n",
            "Iteration 7 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.0000e+00\n",
            "       close\n",
            "12  1.228501\n",
            "13  1.258493\n",
            "14  1.278446\n",
            "15  1.283504\n",
            "16  1.284084\n",
            "       close\n",
            "17  1.307893\n",
            "18  1.295377\n",
            "Accuracy: 1/2\n",
            "Iteration 8 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0825 - accuracy: 0.0000e+00\n",
            "       close\n",
            "14  1.278446\n",
            "15  1.283504\n",
            "16  1.284084\n",
            "17  1.308952\n",
            "18  1.322345\n",
            "       close\n",
            "19  1.351666\n",
            "20  1.341439\n",
            "Accuracy: 1/2\n",
            "Iteration 9 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "       close\n",
            "16  1.284084\n",
            "17  1.308952\n",
            "18  1.322345\n",
            "19  1.317730\n",
            "20  1.310068\n",
            "       close\n",
            "21  1.329962\n",
            "22  1.324805\n",
            "Accuracy: 1/2\n",
            "Iteration 10 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2213 - accuracy: 0.0000e+00\n",
            "       close\n",
            "18  1.322345\n",
            "19  1.317730\n",
            "20  1.310068\n",
            "21  1.365026\n",
            "22  1.376564\n",
            "       close\n",
            "23  1.405094\n",
            "24  1.399574\n",
            "Accuracy: 1/2\n",
            "Iteration 11 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0440 - accuracy: 0.0000e+00\n",
            "       close\n",
            "20  1.310068\n",
            "21  1.365026\n",
            "22  1.376564\n",
            "23  1.386145\n",
            "24  1.401786\n",
            "       close\n",
            "25  1.453979\n",
            "26  1.448195\n",
            "Accuracy: 2/2\n",
            "Iteration 12 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0154 - accuracy: 1.0000\n",
            "       close\n",
            "22  1.376564\n",
            "23  1.386145\n",
            "24  1.401786\n",
            "25  1.470677\n",
            "26  1.427830\n",
            "       close\n",
            "27  1.547393\n",
            "28  1.535048\n",
            "Accuracy: 1/2\n",
            "Iteration 13 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1710 - accuracy: 0.0000e+00\n",
            "       close\n",
            "24  1.401786\n",
            "25  1.470677\n",
            "26  1.427830\n",
            "27  1.477640\n",
            "28  1.672566\n",
            "       close\n",
            "29  1.715838\n",
            "30  1.714465\n",
            "Accuracy: 1/2\n",
            "Iteration 14 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0708 - accuracy: 0.0000e+00\n",
            "       close\n",
            "26  1.427830\n",
            "27  1.477640\n",
            "28  1.672566\n",
            "29  1.798038\n",
            "30  1.823878\n",
            "       close\n",
            "31  2.175102\n",
            "32  2.168585\n",
            "Accuracy: 1/2\n",
            "Iteration 15 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "       close\n",
            "28  1.672566\n",
            "29  1.798038\n",
            "30  1.823878\n",
            "31  2.136079\n",
            "32  2.191687\n",
            "       close\n",
            "33  3.107718\n",
            "34  3.101863\n",
            "Accuracy: 1/2\n",
            "Iteration 16 started\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7165 - accuracy: 0.0000e+00\n",
            "       close\n",
            "30  1.823878\n",
            "31  2.136079\n",
            "32  2.191687\n",
            "33  2.169153\n",
            "34  2.079417\n",
            "       close\n",
            "35  2.863950\n",
            "36  2.857018\n",
            "Accuracy: 0/2\n",
            "Iteration 17 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2525 - accuracy: 0.0000e+00\n",
            "       close\n",
            "32  2.191687\n",
            "33  2.169153\n",
            "34  2.079417\n",
            "35  1.926601\n",
            "36  2.108560\n",
            "       close\n",
            "37  2.495627\n",
            "38  2.470989\n",
            "Accuracy: 1/2\n",
            "Iteration 18 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0434 - accuracy: 1.0000\n",
            "       close\n",
            "34  2.079417\n",
            "35  1.926601\n",
            "36  2.108560\n",
            "37  2.428140\n",
            "38  2.457702\n",
            "       close\n",
            "39  2.751328\n",
            "40  2.763994\n",
            "Accuracy: 1/2\n",
            "Iteration 19 started\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0784 - accuracy: 1.0000\n",
            "       close\n",
            "36  2.108560\n",
            "37  2.428140\n",
            "38  2.457702\n",
            "39  2.435435\n",
            "40  2.713725\n",
            "       close\n",
            "41  3.291839\n",
            "42  3.311006\n",
            "Accuracy: 1/2\n",
            "Iteration 20 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0705 - accuracy: 0.0000e+00\n",
            "       close\n",
            "38  2.457702\n",
            "39  2.435435\n",
            "40  2.713725\n",
            "41  2.917386\n",
            "42  2.721091\n",
            "       close\n",
            "43  3.316009\n",
            "44  3.329103\n",
            "Accuracy: 1/2\n",
            "Iteration 21 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5365 - accuracy: 0.0000e+00\n",
            "       close\n",
            "40  2.713725\n",
            "41  2.917386\n",
            "42  2.721091\n",
            "43  2.738132\n",
            "44  2.535528\n",
            "       close\n",
            "45  2.756222\n",
            "46  2.771107\n",
            "Accuracy: 1/2\n",
            "Iteration 22 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2388 - accuracy: 0.0000e+00\n",
            "Total hits: 21. Total tries: 44. Accuracy: 0.48\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TKc1fCjTlYvP",
        "outputId": "0c2a4af9-8dfb-4dbc-d1d3-a11c1f575ff1"
      },
      "source": [
        "seed(n_seed)\n",
        "tf.random.set_seed(n_seed)\n",
        "model = model_type(n_neurons=n_neurons, n_steps=n_steps, n_outputs=n_outputs, loss=loss, optimizer=optimizer)\n",
        "\n",
        "cm = evaluate(model, ada_stocks_close, btc_new_stocks_close, n_evaluations=n_evaluations, n_test=n_outputs, n_steps=n_steps, n_epochs=epochs, batch_size=batch_size)\n",
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_6 (LSTM)                (None, 30)                3840      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 2)                 62        \n",
            "=================================================================\n",
            "Total params: 3,902\n",
            "Trainable params: 3,902\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training on train_ts\n",
            "Epoch 1/70\n",
            "78/78 [==============================] - 2s 7ms/step - loss: 0.0033 - accuracy: 0.5158 - val_loss: 0.0913 - val_accuracy: 0.4855\n",
            "Epoch 2/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 7.3338e-04 - accuracy: 0.5344 - val_loss: 0.0054 - val_accuracy: 0.4855\n",
            "Epoch 3/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.4582e-04 - accuracy: 0.4915 - val_loss: 0.0061 - val_accuracy: 0.5145\n",
            "Epoch 4/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.2902e-04 - accuracy: 0.5077 - val_loss: 0.0051 - val_accuracy: 0.4855\n",
            "Epoch 5/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.3119e-04 - accuracy: 0.5133 - val_loss: 0.0052 - val_accuracy: 0.4855\n",
            "Epoch 6/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.1462e-04 - accuracy: 0.4891 - val_loss: 0.0049 - val_accuracy: 0.4855\n",
            "Epoch 7/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.2153e-04 - accuracy: 0.5061 - val_loss: 0.0049 - val_accuracy: 0.4855\n",
            "Epoch 8/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.1003e-04 - accuracy: 0.4996 - val_loss: 0.0055 - val_accuracy: 0.4855\n",
            "Epoch 9/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.0850e-04 - accuracy: 0.4859 - val_loss: 0.0061 - val_accuracy: 0.4855\n",
            "Epoch 10/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.9626e-04 - accuracy: 0.5004 - val_loss: 0.0047 - val_accuracy: 0.5072\n",
            "Epoch 11/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.9168e-04 - accuracy: 0.4826 - val_loss: 0.0051 - val_accuracy: 0.4855\n",
            "Epoch 12/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.8240e-04 - accuracy: 0.5061 - val_loss: 0.0046 - val_accuracy: 0.4855\n",
            "Epoch 13/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.8562e-04 - accuracy: 0.4745 - val_loss: 0.0045 - val_accuracy: 0.4855\n",
            "Epoch 14/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.7728e-04 - accuracy: 0.4826 - val_loss: 0.0044 - val_accuracy: 0.4855\n",
            "Epoch 15/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.7531e-04 - accuracy: 0.4947 - val_loss: 0.0043 - val_accuracy: 0.4855\n",
            "Epoch 16/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.8022e-04 - accuracy: 0.5465 - val_loss: 0.0048 - val_accuracy: 0.5072\n",
            "Epoch 17/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.7841e-04 - accuracy: 0.4875 - val_loss: 0.0043 - val_accuracy: 0.5217\n",
            "Epoch 18/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.6190e-04 - accuracy: 0.4923 - val_loss: 0.0040 - val_accuracy: 0.5072\n",
            "Epoch 19/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.5709e-04 - accuracy: 0.4939 - val_loss: 0.0042 - val_accuracy: 0.4855\n",
            "Epoch 20/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.5327e-04 - accuracy: 0.4899 - val_loss: 0.0050 - val_accuracy: 0.4855\n",
            "Epoch 21/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.5011e-04 - accuracy: 0.4972 - val_loss: 0.0038 - val_accuracy: 0.5290\n",
            "Epoch 22/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4697e-04 - accuracy: 0.4608 - val_loss: 0.0051 - val_accuracy: 0.4855\n",
            "Epoch 23/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4878e-04 - accuracy: 0.4770 - val_loss: 0.0038 - val_accuracy: 0.4855\n",
            "Epoch 24/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4197e-04 - accuracy: 0.4980 - val_loss: 0.0037 - val_accuracy: 0.4855\n",
            "Epoch 25/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.3822e-04 - accuracy: 0.5012 - val_loss: 0.0035 - val_accuracy: 0.5145\n",
            "Epoch 26/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4071e-04 - accuracy: 0.5295 - val_loss: 0.0045 - val_accuracy: 0.5145\n",
            "Epoch 27/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.3578e-04 - accuracy: 0.4980 - val_loss: 0.0033 - val_accuracy: 0.5217\n",
            "Epoch 28/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4061e-04 - accuracy: 0.5069 - val_loss: 0.0039 - val_accuracy: 0.5290\n",
            "Epoch 29/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.2468e-04 - accuracy: 0.4737 - val_loss: 0.0033 - val_accuracy: 0.5145\n",
            "Epoch 30/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.2813e-04 - accuracy: 0.5053 - val_loss: 0.0035 - val_accuracy: 0.4855\n",
            "Epoch 31/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.2028e-04 - accuracy: 0.5028 - val_loss: 0.0035 - val_accuracy: 0.4783\n",
            "Epoch 32/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.2214e-04 - accuracy: 0.5085 - val_loss: 0.0047 - val_accuracy: 0.5072\n",
            "Epoch 33/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.1447e-04 - accuracy: 0.5069 - val_loss: 0.0034 - val_accuracy: 0.4783\n",
            "Epoch 34/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0919e-04 - accuracy: 0.4802 - val_loss: 0.0032 - val_accuracy: 0.4783\n",
            "Epoch 35/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0879e-04 - accuracy: 0.5101 - val_loss: 0.0034 - val_accuracy: 0.5290\n",
            "Epoch 36/70\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 2.0405e-04 - accuracy: 0.4931 - val_loss: 0.0037 - val_accuracy: 0.4855\n",
            "Epoch 37/70\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 1.9986e-04 - accuracy: 0.4996 - val_loss: 0.0036 - val_accuracy: 0.4783\n",
            "Epoch 38/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9976e-04 - accuracy: 0.4939 - val_loss: 0.0041 - val_accuracy: 0.4855\n",
            "Epoch 39/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0265e-04 - accuracy: 0.4875 - val_loss: 0.0060 - val_accuracy: 0.5217\n",
            "Epoch 40/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0337e-04 - accuracy: 0.4964 - val_loss: 0.0075 - val_accuracy: 0.4855\n",
            "Epoch 41/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0497e-04 - accuracy: 0.4875 - val_loss: 0.0041 - val_accuracy: 0.4855\n",
            "Epoch 42/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9987e-04 - accuracy: 0.5093 - val_loss: 0.0052 - val_accuracy: 0.5145\n",
            "Epoch 43/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0023e-04 - accuracy: 0.5044 - val_loss: 0.0082 - val_accuracy: 0.5507\n",
            "Epoch 44/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9898e-04 - accuracy: 0.4737 - val_loss: 0.0059 - val_accuracy: 0.4855\n",
            "Epoch 45/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9370e-04 - accuracy: 0.4648 - val_loss: 0.0059 - val_accuracy: 0.4855\n",
            "Epoch 46/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8906e-04 - accuracy: 0.4826 - val_loss: 0.0048 - val_accuracy: 0.4855\n",
            "Epoch 47/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8813e-04 - accuracy: 0.5077 - val_loss: 0.0069 - val_accuracy: 0.4928\n",
            "Epoch 48/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8369e-04 - accuracy: 0.4802 - val_loss: 0.0060 - val_accuracy: 0.4928\n",
            "Epoch 49/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9081e-04 - accuracy: 0.4972 - val_loss: 0.0053 - val_accuracy: 0.4928\n",
            "Epoch 50/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8856e-04 - accuracy: 0.4972 - val_loss: 0.0058 - val_accuracy: 0.4928\n",
            "Epoch 51/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8772e-04 - accuracy: 0.4947 - val_loss: 0.0055 - val_accuracy: 0.4855\n",
            "Epoch 52/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9525e-04 - accuracy: 0.4923 - val_loss: 0.0065 - val_accuracy: 0.5000\n",
            "Epoch 53/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8723e-04 - accuracy: 0.4867 - val_loss: 0.0058 - val_accuracy: 0.4928\n",
            "Epoch 54/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8330e-04 - accuracy: 0.4818 - val_loss: 0.0060 - val_accuracy: 0.4928\n",
            "Epoch 55/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8064e-04 - accuracy: 0.4907 - val_loss: 0.0051 - val_accuracy: 0.4855\n",
            "Epoch 56/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8386e-04 - accuracy: 0.4770 - val_loss: 0.0047 - val_accuracy: 0.4855\n",
            "Epoch 57/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8114e-04 - accuracy: 0.5133 - val_loss: 0.0051 - val_accuracy: 0.4928\n",
            "Epoch 58/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8855e-04 - accuracy: 0.5085 - val_loss: 0.0051 - val_accuracy: 0.4855\n",
            "Epoch 59/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9394e-04 - accuracy: 0.5020 - val_loss: 0.0038 - val_accuracy: 0.4855\n",
            "Epoch 60/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8930e-04 - accuracy: 0.4988 - val_loss: 0.0038 - val_accuracy: 0.4855\n",
            "Epoch 61/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8510e-04 - accuracy: 0.4713 - val_loss: 0.0039 - val_accuracy: 0.4855\n",
            "Epoch 62/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8623e-04 - accuracy: 0.4899 - val_loss: 0.0052 - val_accuracy: 0.4855\n",
            "Epoch 63/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7409e-04 - accuracy: 0.4972 - val_loss: 0.0041 - val_accuracy: 0.4855\n",
            "Epoch 64/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7779e-04 - accuracy: 0.4834 - val_loss: 0.0039 - val_accuracy: 0.4855\n",
            "Epoch 65/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7543e-04 - accuracy: 0.4891 - val_loss: 0.0073 - val_accuracy: 0.4855\n",
            "Epoch 66/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7371e-04 - accuracy: 0.4826 - val_loss: 0.0054 - val_accuracy: 0.4855\n",
            "Epoch 67/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7308e-04 - accuracy: 0.4883 - val_loss: 0.0044 - val_accuracy: 0.4855\n",
            "Epoch 68/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7251e-04 - accuracy: 0.5093 - val_loss: 0.0054 - val_accuracy: 0.4855\n",
            "Epoch 69/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7580e-04 - accuracy: 0.4964 - val_loss: 0.0038 - val_accuracy: 0.4855\n",
            "Epoch 70/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8323e-04 - accuracy: 0.5263 - val_loss: 0.0045 - val_accuracy: 0.4855\n",
            "Iteration 1 started on test\n",
            "          close\n",
            "0  32702.025391\n",
            "1  32822.347656\n",
            "2  31780.730469\n",
            "3  31421.539063\n",
            "4  31533.068359\n",
            "         close\n",
            "5  4926.954590\n",
            "6 -6043.633301\n",
            "Accuracy: 1/2\n",
            "Iteration 1 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 1.0000\n",
            "          close\n",
            "0  32702.025391\n",
            "1  32822.347656\n",
            "2  31780.730469\n",
            "3  31421.539063\n",
            "4  31533.068359\n",
            "          close\n",
            "5  31134.923828\n",
            "6  30934.546875\n",
            "Accuracy: 1/2\n",
            "Iteration 2 started\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0562 - accuracy: 1.0000\n",
            "          close\n",
            "2  31780.730469\n",
            "3  31421.539063\n",
            "4  31533.068359\n",
            "5  31796.810547\n",
            "6  30817.832031\n",
            "          close\n",
            "7  31185.273438\n",
            "8  31123.771484\n",
            "Accuracy: 0/2\n",
            "Iteration 3 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3149 - accuracy: 0.0000e+00\n",
            "          close\n",
            "4  31533.068359\n",
            "5  31796.810547\n",
            "6  30817.832031\n",
            "7  29807.347656\n",
            "8  32110.693359\n",
            "           close\n",
            "9   31038.263672\n",
            "10  30711.169922\n",
            "Accuracy: 0/2\n",
            "Iteration 4 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3034 - accuracy: 0.0000e+00\n",
            "           close\n",
            "6   30817.832031\n",
            "7   29807.347656\n",
            "8   32110.693359\n",
            "9   32313.105469\n",
            "10  33581.550781\n",
            "           close\n",
            "11  32693.162109\n",
            "12  32469.777344\n",
            "Accuracy: 0/2\n",
            "Iteration 5 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1640 - accuracy: 0.0000e+00\n",
            "           close\n",
            "8   32110.693359\n",
            "9   32313.105469\n",
            "10  33581.550781\n",
            "11  34292.445313\n",
            "12  35350.187500\n",
            "           close\n",
            "13  35083.164062\n",
            "14  34822.210938\n",
            "Accuracy: 0/2\n",
            "Iteration 6 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2571 - accuracy: 0.0000e+00\n",
            "           close\n",
            "10  33581.550781\n",
            "11  34292.445313\n",
            "12  35350.187500\n",
            "13  37337.535156\n",
            "14  39406.941406\n",
            "           close\n",
            "15  38495.601562\n",
            "16  38437.246094\n",
            "Accuracy: 0/2\n",
            "Iteration 7 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0906 - accuracy: 0.0000e+00\n",
            "           close\n",
            "12  35350.187500\n",
            "13  37337.535156\n",
            "14  39406.941406\n",
            "15  39995.906250\n",
            "16  40008.421875\n",
            "           close\n",
            "17  41270.652344\n",
            "18  41218.011719\n",
            "Accuracy: 2/2\n",
            "Iteration 8 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0392 - accuracy: 0.0000e+00\n",
            "           close\n",
            "14  39406.941406\n",
            "15  39995.906250\n",
            "16  40008.421875\n",
            "17  42235.546875\n",
            "18  41626.195313\n",
            "           close\n",
            "19  43856.207031\n",
            "20  43851.371094\n",
            "Accuracy: 1/2\n",
            "Iteration 9 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6517 - accuracy: 0.0000e+00\n",
            "           close\n",
            "16  40008.421875\n",
            "17  42235.546875\n",
            "18  41626.195313\n",
            "19  39974.894531\n",
            "20  39201.945313\n",
            "           close\n",
            "21  40026.136719\n",
            "22  40145.714844\n",
            "Accuracy: 1/2\n",
            "Iteration 10 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2012 - accuracy: 1.0000\n",
            "           close\n",
            "18  41626.195313\n",
            "19  39974.894531\n",
            "20  39201.945313\n",
            "21  38152.980469\n",
            "22  39747.503906\n",
            "           close\n",
            "23  39904.128906\n",
            "24  39874.382812\n",
            "Accuracy: 1/2\n",
            "Iteration 11 started\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1968 - accuracy: 0.0000e+00\n",
            "           close\n",
            "20  39201.945313\n",
            "21  38152.980469\n",
            "22  39747.503906\n",
            "23  40869.554688\n",
            "24  42816.500000\n",
            "           close\n",
            "25  42035.984375\n",
            "26  42266.863281\n",
            "Accuracy: 0/2\n",
            "Iteration 12 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0892 - accuracy: 0.0000e+00\n",
            "           close\n",
            "22  39747.503906\n",
            "23  40869.554688\n",
            "24  42816.500000\n",
            "25  44555.800781\n",
            "26  43798.117188\n",
            "           close\n",
            "27  44993.941406\n",
            "28  45427.878906\n",
            "Accuracy: 1/2\n",
            "Iteration 13 started\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0449 - accuracy: 0.0000e+00\n",
            "           close\n",
            "24  42816.500000\n",
            "25  44555.800781\n",
            "26  43798.117188\n",
            "27  46365.402344\n",
            "28  45585.031250\n",
            "           close\n",
            "29  47181.964844\n",
            "30  47650.992188\n",
            "Accuracy: 1/2\n",
            "Iteration 14 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1351 - accuracy: 0.0000e+00\n",
            "           close\n",
            "26  43798.117188\n",
            "27  46365.402344\n",
            "28  45585.031250\n",
            "29  45593.636719\n",
            "30  44428.289063\n",
            "           close\n",
            "31  45631.355469\n",
            "32  45880.679688\n",
            "Accuracy: 1/2\n",
            "Iteration 15 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2043 - accuracy: 0.0000e+00\n",
            "           close\n",
            "28  45585.031250\n",
            "29  45593.636719\n",
            "30  44428.289063\n",
            "31  47793.320313\n",
            "32  47096.945313\n",
            "           close\n",
            "33  47526.144531\n",
            "34  47763.101562\n",
            "Accuracy: 0/2\n",
            "Iteration 16 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.0000e+00\n",
            "           close\n",
            "30  44428.289063\n",
            "31  47793.320313\n",
            "32  47096.945313\n",
            "33  47047.003906\n",
            "34  46004.484375\n",
            "           close\n",
            "35  47113.703125\n",
            "36  47271.355469\n",
            "Accuracy: 1/2\n",
            "Iteration 17 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5277 - accuracy: 1.0000\n",
            "           close\n",
            "32  47096.945313\n",
            "33  47047.003906\n",
            "34  46004.484375\n",
            "35  44695.359375\n",
            "36  44801.187500\n",
            "           close\n",
            "37  45495.859375\n",
            "38  45604.328125\n",
            "Accuracy: 2/2\n",
            "Iteration 18 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2825 - accuracy: 1.0000\n",
            "           close\n",
            "34  46004.484375\n",
            "35  44695.359375\n",
            "36  44801.187500\n",
            "37  46717.578125\n",
            "38  49339.175781\n",
            "           close\n",
            "39  48012.515625\n",
            "40  48151.875000\n",
            "Accuracy: 2/2\n",
            "Iteration 19 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 1.0000\n",
            "           close\n",
            "36  44801.187500\n",
            "37  46717.578125\n",
            "38  49339.175781\n",
            "39  48905.492188\n",
            "40  49321.652344\n",
            "           close\n",
            "41  49574.351562\n",
            "42  49719.984375\n",
            "Accuracy: 1/2\n",
            "Iteration 20 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0893 - accuracy: 0.0000e+00\n",
            "           close\n",
            "38  49339.175781\n",
            "39  48905.492188\n",
            "40  49321.652344\n",
            "41  49546.148438\n",
            "42  47706.117188\n",
            "           close\n",
            "43  49110.683594\n",
            "44  49223.617188\n",
            "Accuracy: 1/2\n",
            "Iteration 21 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2397 - accuracy: 0.0000e+00\n",
            "           close\n",
            "40  49321.652344\n",
            "41  49546.148438\n",
            "42  47706.117188\n",
            "43  48960.789063\n",
            "44  46942.218750\n",
            "           close\n",
            "45  47725.628906\n",
            "46  47846.761719\n",
            "Accuracy: 1/2\n",
            "Iteration 22 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2132 - accuracy: 0.0000e+00\n",
            "Total hits: 18. Total tries: 44. Accuracy: 0.41\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mjd9AGnelbd0",
        "outputId": "c907259d-4b1e-409b-dfc2-d233452f9ebd"
      },
      "source": [
        "seed(n_seed)\n",
        "tf.random.set_seed(n_seed)\n",
        "model = model_type(n_neurons=n_neurons, n_steps=n_steps, n_outputs=n_outputs, loss=loss, optimizer=optimizer)\n",
        "\n",
        "cm = evaluate(model, ada_stocks_close, eth_new_stocks_close, n_evaluations=n_evaluations, n_test=n_outputs, n_steps=n_steps, n_epochs=epochs, batch_size=batch_size)\n",
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_7 (LSTM)                (None, 30)                3840      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 62        \n",
            "=================================================================\n",
            "Total params: 3,902\n",
            "Trainable params: 3,902\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training on train_ts\n",
            "Epoch 1/70\n",
            "78/78 [==============================] - 2s 7ms/step - loss: 0.0033 - accuracy: 0.5158 - val_loss: 0.0913 - val_accuracy: 0.4855\n",
            "Epoch 2/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 7.3338e-04 - accuracy: 0.5344 - val_loss: 0.0054 - val_accuracy: 0.4855\n",
            "Epoch 3/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.4582e-04 - accuracy: 0.4915 - val_loss: 0.0061 - val_accuracy: 0.5145\n",
            "Epoch 4/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.2902e-04 - accuracy: 0.5077 - val_loss: 0.0051 - val_accuracy: 0.4855\n",
            "Epoch 5/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.3119e-04 - accuracy: 0.5133 - val_loss: 0.0052 - val_accuracy: 0.4855\n",
            "Epoch 6/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.1462e-04 - accuracy: 0.4891 - val_loss: 0.0049 - val_accuracy: 0.4855\n",
            "Epoch 7/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.2153e-04 - accuracy: 0.5061 - val_loss: 0.0049 - val_accuracy: 0.4855\n",
            "Epoch 8/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.1003e-04 - accuracy: 0.4996 - val_loss: 0.0055 - val_accuracy: 0.4855\n",
            "Epoch 9/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.0850e-04 - accuracy: 0.4859 - val_loss: 0.0061 - val_accuracy: 0.4855\n",
            "Epoch 10/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.9626e-04 - accuracy: 0.5004 - val_loss: 0.0047 - val_accuracy: 0.5072\n",
            "Epoch 11/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.9168e-04 - accuracy: 0.4826 - val_loss: 0.0051 - val_accuracy: 0.4855\n",
            "Epoch 12/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.8240e-04 - accuracy: 0.5061 - val_loss: 0.0046 - val_accuracy: 0.4855\n",
            "Epoch 13/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.8562e-04 - accuracy: 0.4745 - val_loss: 0.0045 - val_accuracy: 0.4855\n",
            "Epoch 14/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.7728e-04 - accuracy: 0.4826 - val_loss: 0.0044 - val_accuracy: 0.4855\n",
            "Epoch 15/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.7531e-04 - accuracy: 0.4947 - val_loss: 0.0043 - val_accuracy: 0.4855\n",
            "Epoch 16/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.8022e-04 - accuracy: 0.5465 - val_loss: 0.0048 - val_accuracy: 0.5072\n",
            "Epoch 17/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.7841e-04 - accuracy: 0.4875 - val_loss: 0.0043 - val_accuracy: 0.5217\n",
            "Epoch 18/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.6190e-04 - accuracy: 0.4923 - val_loss: 0.0040 - val_accuracy: 0.5072\n",
            "Epoch 19/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.5709e-04 - accuracy: 0.4939 - val_loss: 0.0042 - val_accuracy: 0.4855\n",
            "Epoch 20/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.5327e-04 - accuracy: 0.4899 - val_loss: 0.0050 - val_accuracy: 0.4855\n",
            "Epoch 21/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.5011e-04 - accuracy: 0.4972 - val_loss: 0.0038 - val_accuracy: 0.5290\n",
            "Epoch 22/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4697e-04 - accuracy: 0.4608 - val_loss: 0.0051 - val_accuracy: 0.4855\n",
            "Epoch 23/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4878e-04 - accuracy: 0.4770 - val_loss: 0.0038 - val_accuracy: 0.4855\n",
            "Epoch 24/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4197e-04 - accuracy: 0.4980 - val_loss: 0.0037 - val_accuracy: 0.4855\n",
            "Epoch 25/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.3822e-04 - accuracy: 0.5012 - val_loss: 0.0035 - val_accuracy: 0.5145\n",
            "Epoch 26/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4071e-04 - accuracy: 0.5295 - val_loss: 0.0045 - val_accuracy: 0.5145\n",
            "Epoch 27/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.3578e-04 - accuracy: 0.4980 - val_loss: 0.0033 - val_accuracy: 0.5217\n",
            "Epoch 28/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4061e-04 - accuracy: 0.5069 - val_loss: 0.0039 - val_accuracy: 0.5290\n",
            "Epoch 29/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.2468e-04 - accuracy: 0.4737 - val_loss: 0.0033 - val_accuracy: 0.5145\n",
            "Epoch 30/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.2813e-04 - accuracy: 0.5053 - val_loss: 0.0035 - val_accuracy: 0.4855\n",
            "Epoch 31/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.2028e-04 - accuracy: 0.5028 - val_loss: 0.0035 - val_accuracy: 0.4783\n",
            "Epoch 32/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.2214e-04 - accuracy: 0.5085 - val_loss: 0.0047 - val_accuracy: 0.5072\n",
            "Epoch 33/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.1447e-04 - accuracy: 0.5069 - val_loss: 0.0034 - val_accuracy: 0.4783\n",
            "Epoch 34/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0919e-04 - accuracy: 0.4802 - val_loss: 0.0032 - val_accuracy: 0.4783\n",
            "Epoch 35/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0879e-04 - accuracy: 0.5101 - val_loss: 0.0034 - val_accuracy: 0.5290\n",
            "Epoch 36/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0405e-04 - accuracy: 0.4931 - val_loss: 0.0037 - val_accuracy: 0.4855\n",
            "Epoch 37/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9986e-04 - accuracy: 0.4996 - val_loss: 0.0036 - val_accuracy: 0.4783\n",
            "Epoch 38/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9976e-04 - accuracy: 0.4939 - val_loss: 0.0041 - val_accuracy: 0.4855\n",
            "Epoch 39/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0265e-04 - accuracy: 0.4875 - val_loss: 0.0060 - val_accuracy: 0.5217\n",
            "Epoch 40/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0337e-04 - accuracy: 0.4964 - val_loss: 0.0075 - val_accuracy: 0.4855\n",
            "Epoch 41/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0497e-04 - accuracy: 0.4875 - val_loss: 0.0041 - val_accuracy: 0.4855\n",
            "Epoch 42/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9987e-04 - accuracy: 0.5093 - val_loss: 0.0052 - val_accuracy: 0.5145\n",
            "Epoch 43/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0023e-04 - accuracy: 0.5044 - val_loss: 0.0082 - val_accuracy: 0.5507\n",
            "Epoch 44/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9898e-04 - accuracy: 0.4737 - val_loss: 0.0059 - val_accuracy: 0.4855\n",
            "Epoch 45/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9370e-04 - accuracy: 0.4648 - val_loss: 0.0059 - val_accuracy: 0.4855\n",
            "Epoch 46/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8906e-04 - accuracy: 0.4826 - val_loss: 0.0048 - val_accuracy: 0.4855\n",
            "Epoch 47/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8813e-04 - accuracy: 0.5077 - val_loss: 0.0069 - val_accuracy: 0.4928\n",
            "Epoch 48/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8369e-04 - accuracy: 0.4802 - val_loss: 0.0060 - val_accuracy: 0.4928\n",
            "Epoch 49/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9081e-04 - accuracy: 0.4972 - val_loss: 0.0053 - val_accuracy: 0.4928\n",
            "Epoch 50/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8856e-04 - accuracy: 0.4972 - val_loss: 0.0058 - val_accuracy: 0.4928\n",
            "Epoch 51/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8772e-04 - accuracy: 0.4947 - val_loss: 0.0055 - val_accuracy: 0.4855\n",
            "Epoch 52/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9525e-04 - accuracy: 0.4923 - val_loss: 0.0065 - val_accuracy: 0.5000\n",
            "Epoch 53/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8723e-04 - accuracy: 0.4867 - val_loss: 0.0058 - val_accuracy: 0.4928\n",
            "Epoch 54/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8330e-04 - accuracy: 0.4818 - val_loss: 0.0060 - val_accuracy: 0.4928\n",
            "Epoch 55/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8064e-04 - accuracy: 0.4907 - val_loss: 0.0051 - val_accuracy: 0.4855\n",
            "Epoch 56/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8386e-04 - accuracy: 0.4770 - val_loss: 0.0047 - val_accuracy: 0.4855\n",
            "Epoch 57/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8114e-04 - accuracy: 0.5133 - val_loss: 0.0051 - val_accuracy: 0.4928\n",
            "Epoch 58/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8855e-04 - accuracy: 0.5085 - val_loss: 0.0051 - val_accuracy: 0.4855\n",
            "Epoch 59/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9394e-04 - accuracy: 0.5020 - val_loss: 0.0038 - val_accuracy: 0.4855\n",
            "Epoch 60/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8930e-04 - accuracy: 0.4988 - val_loss: 0.0038 - val_accuracy: 0.4855\n",
            "Epoch 61/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8510e-04 - accuracy: 0.4713 - val_loss: 0.0039 - val_accuracy: 0.4855\n",
            "Epoch 62/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8623e-04 - accuracy: 0.4899 - val_loss: 0.0052 - val_accuracy: 0.4855\n",
            "Epoch 63/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7409e-04 - accuracy: 0.4972 - val_loss: 0.0041 - val_accuracy: 0.4855\n",
            "Epoch 64/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7779e-04 - accuracy: 0.4834 - val_loss: 0.0039 - val_accuracy: 0.4855\n",
            "Epoch 65/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7543e-04 - accuracy: 0.4891 - val_loss: 0.0073 - val_accuracy: 0.4855\n",
            "Epoch 66/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7371e-04 - accuracy: 0.4826 - val_loss: 0.0054 - val_accuracy: 0.4855\n",
            "Epoch 67/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7308e-04 - accuracy: 0.4883 - val_loss: 0.0044 - val_accuracy: 0.4855\n",
            "Epoch 68/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7251e-04 - accuracy: 0.5093 - val_loss: 0.0054 - val_accuracy: 0.4855\n",
            "Epoch 69/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7580e-04 - accuracy: 0.4964 - val_loss: 0.0038 - val_accuracy: 0.4855\n",
            "Epoch 70/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8323e-04 - accuracy: 0.5263 - val_loss: 0.0045 - val_accuracy: 0.4855\n",
            "Iteration 1 started on test\n",
            "         close\n",
            "0  1940.083984\n",
            "1  1994.331299\n",
            "2  1911.175659\n",
            "3  1880.382935\n",
            "4  1898.825195\n",
            "        close\n",
            "5  338.954071\n",
            "6 -371.911407\n",
            "Accuracy: 2/2\n",
            "Iteration 1 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 1.0000\n",
            "         close\n",
            "0  1940.083984\n",
            "1  1994.331299\n",
            "2  1911.175659\n",
            "3  1880.382935\n",
            "4  1898.825195\n",
            "         close\n",
            "5  1868.445801\n",
            "6  1844.108521\n",
            "Accuracy: 2/2\n",
            "Iteration 2 started\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 1.0000\n",
            "         close\n",
            "2  1911.175659\n",
            "3  1880.382935\n",
            "4  1898.825195\n",
            "5  1895.552124\n",
            "6  1817.296631\n",
            "         close\n",
            "7  1847.288940\n",
            "8  1836.421631\n",
            "Accuracy: 0/2\n",
            "Iteration 3 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3693 - accuracy: 0.0000e+00\n",
            "         close\n",
            "4  1898.825195\n",
            "5  1895.552124\n",
            "6  1817.296631\n",
            "7  1787.510742\n",
            "8  1990.970825\n",
            "         close\n",
            "9   1886.31958\n",
            "10  1850.87500\n",
            "Accuracy: 0/2\n",
            "Iteration 4 started\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3810 - accuracy: 0.0000e+00\n",
            "          close\n",
            "6   1817.296631\n",
            "7   1787.510742\n",
            "8   1990.970825\n",
            "9   2025.202759\n",
            "10  2124.776611\n",
            "          close\n",
            "11  2068.746582\n",
            "12  2023.348389\n",
            "Accuracy: 0/2\n",
            "Iteration 5 started\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1264 - accuracy: 0.0000e+00\n",
            "          close\n",
            "8   1990.970825\n",
            "9   2025.202759\n",
            "10  2124.776611\n",
            "11  2189.218750\n",
            "12  2191.373779\n",
            "          close\n",
            "13  2288.322266\n",
            "14  2206.716309\n",
            "Accuracy: 1/2\n",
            "Iteration 6 started\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0867 - accuracy: 0.0000e+00\n",
            "          close\n",
            "10  2124.776611\n",
            "11  2189.218750\n",
            "12  2191.373779\n",
            "13  2233.366699\n",
            "14  2298.333496\n",
            "          close\n",
            "15  2366.236084\n",
            "16  2314.908447\n",
            "Accuracy: 0/2\n",
            "Iteration 7 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0804 - accuracy: 0.0000e+00\n",
            "          close\n",
            "12  2191.373779\n",
            "13  2233.366699\n",
            "14  2298.333496\n",
            "15  2296.545410\n",
            "16  2380.956787\n",
            "          close\n",
            "17  2434.989014\n",
            "18  2404.876709\n",
            "Accuracy: 1/2\n",
            "Iteration 8 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1151 - accuracy: 0.0000e+00\n",
            "          close\n",
            "14  2298.333496\n",
            "15  2296.545410\n",
            "16  2380.956787\n",
            "17  2466.961426\n",
            "18  2536.209961\n",
            "          close\n",
            "19  2643.698486\n",
            "20  2609.032471\n",
            "Accuracy: 1/2\n",
            "Iteration 9 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0286 - accuracy: 0.0000e+00\n",
            "          close\n",
            "16  2380.956787\n",
            "17  2466.961426\n",
            "18  2536.209961\n",
            "19  2561.852051\n",
            "20  2610.153320\n",
            "          close\n",
            "21  2807.596680\n",
            "22  2774.802734\n",
            "Accuracy: 0/2\n",
            "Iteration 10 started\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1881 - accuracy: 0.0000e+00\n",
            "          close\n",
            "18  2536.209961\n",
            "19  2561.852051\n",
            "20  2610.153320\n",
            "21  2502.349609\n",
            "22  2724.619873\n",
            "          close\n",
            "23  2841.468506\n",
            "24  2824.083984\n",
            "Accuracy: 1/2\n",
            "Iteration 11 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.0000e+00\n",
            "          close\n",
            "20  2610.153320\n",
            "21  2502.349609\n",
            "22  2724.619873\n",
            "23  2827.328857\n",
            "24  2890.941650\n",
            "          close\n",
            "25  3051.833496\n",
            "26  3073.874756\n",
            "Accuracy: 1/2\n",
            "Iteration 12 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0181 - accuracy: 0.0000e+00\n",
            "          close\n",
            "22  2724.619873\n",
            "23  2827.328857\n",
            "24  2890.941650\n",
            "25  3157.238770\n",
            "26  3013.732666\n",
            "          close\n",
            "27  3538.490723\n",
            "28  3606.269531\n",
            "Accuracy: 1/2\n",
            "Iteration 13 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0935 - accuracy: 0.0000e+00\n",
            "          close\n",
            "24  2890.941650\n",
            "25  3157.238770\n",
            "26  3013.732666\n",
            "27  3167.856201\n",
            "28  3141.691162\n",
            "          close\n",
            "29  3578.757812\n",
            "30  3638.944092\n",
            "Accuracy: 1/2\n",
            "Iteration 14 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0303 - accuracy: 0.0000e+00\n",
            "          close\n",
            "26  3013.732666\n",
            "27  3167.856201\n",
            "28  3141.691162\n",
            "29  3164.245117\n",
            "30  3043.414307\n",
            "          close\n",
            "31  3272.981201\n",
            "32  3304.149414\n",
            "Accuracy: 1/2\n",
            "Iteration 15 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1039 - accuracy: 0.0000e+00\n",
            "          close\n",
            "28  3141.691162\n",
            "29  3164.245117\n",
            "30  3043.414307\n",
            "31  3322.211670\n",
            "32  3265.443359\n",
            "          close\n",
            "33  3397.977783\n",
            "34  3430.482422\n",
            "Accuracy: 1/2\n",
            "Iteration 16 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.0000e+00\n",
            "          close\n",
            "30  3043.414307\n",
            "31  3322.211670\n",
            "32  3265.443359\n",
            "33  3310.504150\n",
            "34  3156.509521\n",
            "          close\n",
            "35  3318.812500\n",
            "36  3335.637939\n",
            "Accuracy: 1/2\n",
            "Iteration 17 started\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1805 - accuracy: 1.0000\n",
            "          close\n",
            "32  3265.443359\n",
            "33  3310.504150\n",
            "34  3156.509521\n",
            "35  3014.845947\n",
            "36  3020.089844\n",
            "          close\n",
            "37  3079.303223\n",
            "38  3063.557861\n",
            "Accuracy: 1/2\n",
            "Iteration 18 started\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3667 - accuracy: 0.0000e+00\n",
            "          close\n",
            "34  3156.509521\n",
            "35  3014.845947\n",
            "36  3020.089844\n",
            "37  3182.702148\n",
            "38  3286.935303\n",
            "          close\n",
            "39  3252.189209\n",
            "40  3271.309326\n",
            "Accuracy: 2/2\n",
            "Iteration 19 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "          close\n",
            "36  3020.089844\n",
            "37  3182.702148\n",
            "38  3286.935303\n",
            "39  3226.083984\n",
            "40  3242.115479\n",
            "          close\n",
            "41  3309.819092\n",
            "42  3331.523926\n",
            "Accuracy: 1/2\n",
            "Iteration 20 started\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1454 - accuracy: 0.0000e+00\n",
            "          close\n",
            "38  3286.935303\n",
            "39  3226.083984\n",
            "40  3242.115479\n",
            "41  3319.257324\n",
            "42  3172.456299\n",
            "          close\n",
            "43  3267.557129\n",
            "44  3269.753174\n",
            "Accuracy: 1/2\n",
            "Iteration 21 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2214 - accuracy: 0.0000e+00\n",
            "          close\n",
            "40  3242.115479\n",
            "41  3319.257324\n",
            "42  3172.456299\n",
            "43  3224.915283\n",
            "44  3100.325439\n",
            "          close\n",
            "45  3163.089844\n",
            "46  3155.087158\n",
            "Accuracy: 2/2\n",
            "Iteration 22 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2038 - accuracy: 1.0000\n",
            "Total hits: 21. Total tries: 44. Accuracy: 0.48\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tfAQYnJqj_bT",
        "outputId": "e864f14c-027f-47a3-901b-dcacdc714ce4"
      },
      "source": [
        "seed(n_seed)\n",
        "tf.random.set_seed(n_seed)\n",
        "model = model_type(n_neurons=n_neurons, n_steps=n_steps, n_outputs=n_outputs, loss=loss, optimizer=optimizer)\n",
        "\n",
        "cm = evaluate(model, ada_stocks_close, ada_new_stocks_close, n_evaluations=n_evaluations, n_test=n_outputs, n_steps=n_steps, n_epochs=epochs, batch_size=batch_size)\n",
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_8 (LSTM)                (None, 30)                3840      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 62        \n",
            "=================================================================\n",
            "Total params: 3,902\n",
            "Trainable params: 3,902\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training on train_ts\n",
            "Epoch 1/70\n",
            "78/78 [==============================] - 2s 6ms/step - loss: 0.0033 - accuracy: 0.5158 - val_loss: 0.0913 - val_accuracy: 0.4855\n",
            "Epoch 2/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 7.3338e-04 - accuracy: 0.5344 - val_loss: 0.0054 - val_accuracy: 0.4855\n",
            "Epoch 3/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.4582e-04 - accuracy: 0.4915 - val_loss: 0.0061 - val_accuracy: 0.5145\n",
            "Epoch 4/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.2902e-04 - accuracy: 0.5077 - val_loss: 0.0051 - val_accuracy: 0.4855\n",
            "Epoch 5/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.3119e-04 - accuracy: 0.5133 - val_loss: 0.0052 - val_accuracy: 0.4855\n",
            "Epoch 6/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.1462e-04 - accuracy: 0.4891 - val_loss: 0.0049 - val_accuracy: 0.4855\n",
            "Epoch 7/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.2153e-04 - accuracy: 0.5061 - val_loss: 0.0049 - val_accuracy: 0.4855\n",
            "Epoch 8/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.1003e-04 - accuracy: 0.4996 - val_loss: 0.0055 - val_accuracy: 0.4855\n",
            "Epoch 9/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 3.0850e-04 - accuracy: 0.4859 - val_loss: 0.0061 - val_accuracy: 0.4855\n",
            "Epoch 10/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.9626e-04 - accuracy: 0.5004 - val_loss: 0.0047 - val_accuracy: 0.5072\n",
            "Epoch 11/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.9168e-04 - accuracy: 0.4826 - val_loss: 0.0051 - val_accuracy: 0.4855\n",
            "Epoch 12/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.8240e-04 - accuracy: 0.5061 - val_loss: 0.0046 - val_accuracy: 0.4855\n",
            "Epoch 13/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.8562e-04 - accuracy: 0.4745 - val_loss: 0.0045 - val_accuracy: 0.4855\n",
            "Epoch 14/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.7728e-04 - accuracy: 0.4826 - val_loss: 0.0044 - val_accuracy: 0.4855\n",
            "Epoch 15/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.7531e-04 - accuracy: 0.4947 - val_loss: 0.0043 - val_accuracy: 0.4855\n",
            "Epoch 16/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.8022e-04 - accuracy: 0.5465 - val_loss: 0.0048 - val_accuracy: 0.5072\n",
            "Epoch 17/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.7841e-04 - accuracy: 0.4875 - val_loss: 0.0043 - val_accuracy: 0.5217\n",
            "Epoch 18/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.6190e-04 - accuracy: 0.4923 - val_loss: 0.0040 - val_accuracy: 0.5072\n",
            "Epoch 19/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.5709e-04 - accuracy: 0.4939 - val_loss: 0.0042 - val_accuracy: 0.4855\n",
            "Epoch 20/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.5327e-04 - accuracy: 0.4899 - val_loss: 0.0050 - val_accuracy: 0.4855\n",
            "Epoch 21/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.5011e-04 - accuracy: 0.4972 - val_loss: 0.0038 - val_accuracy: 0.5290\n",
            "Epoch 22/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4697e-04 - accuracy: 0.4608 - val_loss: 0.0051 - val_accuracy: 0.4855\n",
            "Epoch 23/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4878e-04 - accuracy: 0.4770 - val_loss: 0.0038 - val_accuracy: 0.4855\n",
            "Epoch 24/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4197e-04 - accuracy: 0.4980 - val_loss: 0.0037 - val_accuracy: 0.4855\n",
            "Epoch 25/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.3822e-04 - accuracy: 0.5012 - val_loss: 0.0035 - val_accuracy: 0.5145\n",
            "Epoch 26/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4071e-04 - accuracy: 0.5295 - val_loss: 0.0045 - val_accuracy: 0.5145\n",
            "Epoch 27/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.3578e-04 - accuracy: 0.4980 - val_loss: 0.0033 - val_accuracy: 0.5217\n",
            "Epoch 28/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.4061e-04 - accuracy: 0.5069 - val_loss: 0.0039 - val_accuracy: 0.5290\n",
            "Epoch 29/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.2468e-04 - accuracy: 0.4737 - val_loss: 0.0033 - val_accuracy: 0.5145\n",
            "Epoch 30/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.2813e-04 - accuracy: 0.5053 - val_loss: 0.0035 - val_accuracy: 0.4855\n",
            "Epoch 31/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.2028e-04 - accuracy: 0.5028 - val_loss: 0.0035 - val_accuracy: 0.4783\n",
            "Epoch 32/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.2214e-04 - accuracy: 0.5085 - val_loss: 0.0047 - val_accuracy: 0.5072\n",
            "Epoch 33/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.1447e-04 - accuracy: 0.5069 - val_loss: 0.0034 - val_accuracy: 0.4783\n",
            "Epoch 34/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0919e-04 - accuracy: 0.4802 - val_loss: 0.0032 - val_accuracy: 0.4783\n",
            "Epoch 35/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0879e-04 - accuracy: 0.5101 - val_loss: 0.0034 - val_accuracy: 0.5290\n",
            "Epoch 36/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0405e-04 - accuracy: 0.4931 - val_loss: 0.0037 - val_accuracy: 0.4855\n",
            "Epoch 37/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9986e-04 - accuracy: 0.4996 - val_loss: 0.0036 - val_accuracy: 0.4783\n",
            "Epoch 38/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9976e-04 - accuracy: 0.4939 - val_loss: 0.0041 - val_accuracy: 0.4855\n",
            "Epoch 39/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0265e-04 - accuracy: 0.4875 - val_loss: 0.0060 - val_accuracy: 0.5217\n",
            "Epoch 40/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0337e-04 - accuracy: 0.4964 - val_loss: 0.0075 - val_accuracy: 0.4855\n",
            "Epoch 41/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0497e-04 - accuracy: 0.4875 - val_loss: 0.0041 - val_accuracy: 0.4855\n",
            "Epoch 42/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9987e-04 - accuracy: 0.5093 - val_loss: 0.0052 - val_accuracy: 0.5145\n",
            "Epoch 43/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 2.0023e-04 - accuracy: 0.5044 - val_loss: 0.0082 - val_accuracy: 0.5507\n",
            "Epoch 44/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9898e-04 - accuracy: 0.4737 - val_loss: 0.0059 - val_accuracy: 0.4855\n",
            "Epoch 45/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9370e-04 - accuracy: 0.4648 - val_loss: 0.0059 - val_accuracy: 0.4855\n",
            "Epoch 46/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8906e-04 - accuracy: 0.4826 - val_loss: 0.0048 - val_accuracy: 0.4855\n",
            "Epoch 47/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8813e-04 - accuracy: 0.5077 - val_loss: 0.0069 - val_accuracy: 0.4928\n",
            "Epoch 48/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8369e-04 - accuracy: 0.4802 - val_loss: 0.0060 - val_accuracy: 0.4928\n",
            "Epoch 49/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9081e-04 - accuracy: 0.4972 - val_loss: 0.0053 - val_accuracy: 0.4928\n",
            "Epoch 50/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8856e-04 - accuracy: 0.4972 - val_loss: 0.0058 - val_accuracy: 0.4928\n",
            "Epoch 51/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8772e-04 - accuracy: 0.4947 - val_loss: 0.0055 - val_accuracy: 0.4855\n",
            "Epoch 52/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9525e-04 - accuracy: 0.4923 - val_loss: 0.0065 - val_accuracy: 0.5000\n",
            "Epoch 53/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8723e-04 - accuracy: 0.4867 - val_loss: 0.0058 - val_accuracy: 0.4928\n",
            "Epoch 54/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8330e-04 - accuracy: 0.4818 - val_loss: 0.0060 - val_accuracy: 0.4928\n",
            "Epoch 55/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8064e-04 - accuracy: 0.4907 - val_loss: 0.0051 - val_accuracy: 0.4855\n",
            "Epoch 56/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8386e-04 - accuracy: 0.4770 - val_loss: 0.0047 - val_accuracy: 0.4855\n",
            "Epoch 57/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8114e-04 - accuracy: 0.5133 - val_loss: 0.0051 - val_accuracy: 0.4928\n",
            "Epoch 58/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8855e-04 - accuracy: 0.5085 - val_loss: 0.0051 - val_accuracy: 0.4855\n",
            "Epoch 59/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.9394e-04 - accuracy: 0.5020 - val_loss: 0.0038 - val_accuracy: 0.4855\n",
            "Epoch 60/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8930e-04 - accuracy: 0.4988 - val_loss: 0.0038 - val_accuracy: 0.4855\n",
            "Epoch 61/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8510e-04 - accuracy: 0.4713 - val_loss: 0.0039 - val_accuracy: 0.4855\n",
            "Epoch 62/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8623e-04 - accuracy: 0.4899 - val_loss: 0.0052 - val_accuracy: 0.4855\n",
            "Epoch 63/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7409e-04 - accuracy: 0.4972 - val_loss: 0.0041 - val_accuracy: 0.4855\n",
            "Epoch 64/70\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 1.7779e-04 - accuracy: 0.4834 - val_loss: 0.0039 - val_accuracy: 0.4855\n",
            "Epoch 65/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7543e-04 - accuracy: 0.4891 - val_loss: 0.0073 - val_accuracy: 0.4855\n",
            "Epoch 66/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7371e-04 - accuracy: 0.4826 - val_loss: 0.0054 - val_accuracy: 0.4855\n",
            "Epoch 67/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7308e-04 - accuracy: 0.4883 - val_loss: 0.0044 - val_accuracy: 0.4855\n",
            "Epoch 68/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7251e-04 - accuracy: 0.5093 - val_loss: 0.0054 - val_accuracy: 0.4855\n",
            "Epoch 69/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.7580e-04 - accuracy: 0.4964 - val_loss: 0.0038 - val_accuracy: 0.4855\n",
            "Epoch 70/70\n",
            "78/78 [==============================] - 0s 4ms/step - loss: 1.8323e-04 - accuracy: 0.5263 - val_loss: 0.0045 - val_accuracy: 0.4855\n",
            "Iteration 1 started on test\n",
            "      close\n",
            "0  1.265083\n",
            "1  1.262258\n",
            "2  1.223192\n",
            "3  1.173715\n",
            "4  1.172302\n",
            "      close\n",
            "5  1.134980\n",
            "6  1.082859\n",
            "Accuracy: 1/2\n",
            "Iteration 1 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 1.0000\n",
            "      close\n",
            "0  1.265083\n",
            "1  1.262258\n",
            "2  1.223192\n",
            "3  1.173715\n",
            "4  1.172302\n",
            "      close\n",
            "5  1.149024\n",
            "6  1.135297\n",
            "Accuracy: 1/2\n",
            "Iteration 2 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0339 - accuracy: 1.0000\n",
            "      close\n",
            "2  1.223192\n",
            "3  1.173715\n",
            "4  1.172302\n",
            "5  1.183698\n",
            "6  1.121116\n",
            "      close\n",
            "7  1.146779\n",
            "8  1.139346\n",
            "Accuracy: 0/2\n",
            "Iteration 3 started\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1748 - accuracy: 0.0000e+00\n",
            "      close\n",
            "4  1.172302\n",
            "5  1.183698\n",
            "6  1.121116\n",
            "7  1.056291\n",
            "8  1.168098\n",
            "       close\n",
            "9   1.118370\n",
            "10  1.096624\n",
            "Accuracy: 0/2\n",
            "Iteration 4 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.0000e+00\n",
            "       close\n",
            "6   1.121116\n",
            "7   1.056291\n",
            "8   1.168098\n",
            "9   1.186161\n",
            "10  1.206307\n",
            "       close\n",
            "11  1.181251\n",
            "12  1.163322\n",
            "Accuracy: 1/2\n",
            "Iteration 5 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1080 - accuracy: 1.0000\n",
            "       close\n",
            "8   1.168098\n",
            "9   1.186161\n",
            "10  1.206307\n",
            "11  1.233497\n",
            "12  1.228501\n",
            "       close\n",
            "13  1.247877\n",
            "14  1.222229\n",
            "Accuracy: 1/2\n",
            "Iteration 6 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1718 - accuracy: 0.0000e+00\n",
            "       close\n",
            "10  1.206307\n",
            "11  1.233497\n",
            "12  1.228501\n",
            "13  1.258493\n",
            "14  1.278446\n",
            "       close\n",
            "15  1.278439\n",
            "16  1.268368\n",
            "Accuracy: 0/2\n",
            "Iteration 7 started\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0619 - accuracy: 0.0000e+00\n",
            "       close\n",
            "12  1.228501\n",
            "13  1.258493\n",
            "14  1.278446\n",
            "15  1.283504\n",
            "16  1.284084\n",
            "       close\n",
            "17  1.302328\n",
            "18  1.293634\n",
            "Accuracy: 1/2\n",
            "Iteration 8 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0739 - accuracy: 0.0000e+00\n",
            "       close\n",
            "14  1.278446\n",
            "15  1.283504\n",
            "16  1.284084\n",
            "17  1.308952\n",
            "18  1.322345\n",
            "       close\n",
            "19  1.342479\n",
            "20  1.334301\n",
            "Accuracy: 1/2\n",
            "Iteration 9 started\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "       close\n",
            "16  1.284084\n",
            "17  1.308952\n",
            "18  1.322345\n",
            "19  1.317730\n",
            "20  1.310068\n",
            "       close\n",
            "21  1.331707\n",
            "22  1.327980\n",
            "Accuracy: 1/2\n",
            "Iteration 10 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1643 - accuracy: 0.0000e+00\n",
            "       close\n",
            "18  1.322345\n",
            "19  1.317730\n",
            "20  1.310068\n",
            "21  1.365026\n",
            "22  1.376564\n",
            "       close\n",
            "23  1.399683\n",
            "24  1.394589\n",
            "Accuracy: 1/2\n",
            "Iteration 11 started\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0358 - accuracy: 0.0000e+00\n",
            "       close\n",
            "20  1.310068\n",
            "21  1.365026\n",
            "22  1.376564\n",
            "23  1.386145\n",
            "24  1.401786\n",
            "       close\n",
            "25  1.444669\n",
            "26  1.439354\n",
            "Accuracy: 2/2\n",
            "Iteration 12 started\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0147 - accuracy: 1.0000\n",
            "       close\n",
            "22  1.376564\n",
            "23  1.386145\n",
            "24  1.401786\n",
            "25  1.470677\n",
            "26  1.427830\n",
            "       close\n",
            "27  1.549639\n",
            "28  1.539813\n",
            "Accuracy: 1/2\n",
            "Iteration 13 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1361 - accuracy: 0.0000e+00\n",
            "       close\n",
            "24  1.401786\n",
            "25  1.470677\n",
            "26  1.427830\n",
            "27  1.477640\n",
            "28  1.672566\n",
            "       close\n",
            "29  1.719354\n",
            "30  1.715561\n",
            "Accuracy: 1/2\n",
            "Iteration 14 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.0000e+00\n",
            "       close\n",
            "26  1.427830\n",
            "27  1.477640\n",
            "28  1.672566\n",
            "29  1.798038\n",
            "30  1.823878\n",
            "       close\n",
            "31  2.128052\n",
            "32  2.119740\n",
            "Accuracy: 1/2\n",
            "Iteration 15 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "       close\n",
            "28  1.672566\n",
            "29  1.798038\n",
            "30  1.823878\n",
            "31  2.136079\n",
            "32  2.191687\n",
            "       close\n",
            "33  2.979281\n",
            "34  2.972360\n",
            "Accuracy: 1/2\n",
            "Iteration 16 started\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5930 - accuracy: 0.0000e+00\n",
            "       close\n",
            "30  1.823878\n",
            "31  2.136079\n",
            "32  2.191687\n",
            "33  2.169153\n",
            "34  2.079417\n",
            "       close\n",
            "35  2.823098\n",
            "36  2.821277\n",
            "Accuracy: 0/2\n",
            "Iteration 17 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1167 - accuracy: 1.0000\n",
            "       close\n",
            "32  2.191687\n",
            "33  2.169153\n",
            "34  2.079417\n",
            "35  1.926601\n",
            "36  2.108560\n",
            "       close\n",
            "37  2.422397\n",
            "38  2.395403\n",
            "Accuracy: 1/2\n",
            "Iteration 18 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0370 - accuracy: 1.0000\n",
            "       close\n",
            "34  2.079417\n",
            "35  1.926601\n",
            "36  2.108560\n",
            "37  2.428140\n",
            "38  2.457702\n",
            "       close\n",
            "39  2.699366\n",
            "40  2.709816\n",
            "Accuracy: 1/2\n",
            "Iteration 19 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0751 - accuracy: 1.0000\n",
            "       close\n",
            "36  2.108560\n",
            "37  2.428140\n",
            "38  2.457702\n",
            "39  2.435435\n",
            "40  2.713725\n",
            "       close\n",
            "41  3.165256\n",
            "42  3.184832\n",
            "Accuracy: 1/2\n",
            "Iteration 20 started\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0591 - accuracy: 0.0000e+00\n",
            "       close\n",
            "38  2.457702\n",
            "39  2.435435\n",
            "40  2.713725\n",
            "41  2.917386\n",
            "42  2.721091\n",
            "       close\n",
            "43  3.304478\n",
            "44  3.323394\n",
            "Accuracy: 1/2\n",
            "Iteration 21 started\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5549 - accuracy: 0.0000e+00\n",
            "       close\n",
            "40  2.713725\n",
            "41  2.917386\n",
            "42  2.721091\n",
            "43  2.738132\n",
            "44  2.535528\n",
            "       close\n",
            "45  2.827493\n",
            "46  2.851120\n",
            "Accuracy: 1/2\n",
            "Iteration 22 started\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1123 - accuracy: 0.0000e+00\n",
            "Total hits: 19. Total tries: 44. Accuracy: 0.43\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEYCAYAAABC0LFYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAenUlEQVR4nO3deXxU9b3G8c83GyCb4goBRItKtVpRwKUutC4oFfHaVuvWalW6adHeulyv1rWt1yraVnsRVwTFpVetC1jcKrhQwA0XpIKIJAEEZJM1JN/7xznQgZJfJiGTc2byvF+vvJI5JzPzzJnf5MlZ5oy5OyIiInUpSjqAiIikm4pCRESCVBQiIhKkohARkSAVhYiIBKkoREQkSEXRQpjZNWY2OukcIk1NYzv3VBR5xMw+NbOjk86RycyuN7P3zGy9mV2TdB7JT2kb22a2k5mNMbMqM1tmZq+Z2UFJ50qKikK21kzgUuDZpIOINKF2wBTgQKATMBJ41szaJZoqISqKPGVmZ5vZq2Z2s5ktMbPZZnZ8xvzdzOwVM1thZs8DO2x2/YPN7HUzW2pm75pZ/3j6oWa2yMy6xZe/Ht9+ry3lcPeR7j4OWJGrxyotSxrGtrt/4u7D3H2eu9e4+wigDNgrhw89tVQU+e0gYAbRC+Um4B4zs3jeQ8Cb8bzrgR9uuJKZlROtAdxA9N/Sr4D/M7Md3f114E5gpJm1AUYDV7n7R83zkESAlI1tM9ufqChmNsmjyzMqivw2x93vcvcaolXjzsDOZtYd6Ev0Iljr7hOApzOudyYw1t3Hunutuz8PTAUGxvOvAToCk4FK4I7meTgiG6VmbJtZB2AUcK27L2uah5dfVBT5bf6GH9x9VfxjO6ALsMTdV2b87pyMn3cFvhevmi81s6XAYUQvRty9Grgf+Bpwi+vMkdL8UjG24zWPp4FJ7v67rXpEeawk6QCSE/OA7cysbcYLqjuw4UUxFxjl7udv6crx6vvVwH3ALWbW193X5jq0SBaabWybWSvgSaAC+HHTPYT8ozWKAuTuc4hWt681szIzOwwYlPEro4FBZjbAzIrNrLWZ9TezrvF24PuBe4BziV6Y19d1X2ZWamaticZSSXxbxTl6aNLCNdfYNrNS4C/AauCH7l6bu0eVfiqKwnU60Q7BL4j+g3pgwwx3nwsMBq4AFhL9F3YJ0Xj4BbAT0TZgB84BzjGzw+u4n7uIXkynAf8d/3xWDh6PyAbNMbYPBU4AjgWWmtmX8Vddr4OCZtr8LCIiIVqjEBGRIBWFiIgEqShERCRIRSEiIkEF+T6KkrJy7aFvgAe37590hLxy6rwHrf7fanrjd/6+xnUD3Fy2NOkIeWX83OfqHNdaoxARkSAVhYiIBKkoREQkSEUhIiJBKgoREQlSUYiISJCKQkREglQUIiISpKIQEZEgFYWIiASpKEREJEhFISIiQSoKEREJUlGIiEiQikJERIJUFCIiEqSiEBGRIBWFiIgEqShERCRIRSEiIkElSQdoCQYc259hw66juKiIe+8bw02/vyPpSKl2wuTbqP5yDV5Ti9fU8PxxVyUdSepQ0mEb9hn2Y9r16oo7fHDxcJZN/TjpWKlU2qqUW/5yM6VlpRQXFzNx7ERGDRuddKysqChyrKioiD/+4TccN/A0KirmMemNsTz9zHimT9eLKeTl797Aui++TDqG1KPXDT9k0cvv8O55t2KlxRS3aZV0pNSqXlvNpadexppVayguKebWx29hystT+ejtj5KOVi9tesqxfn17M2vWp8ye/RnV1dU8+uhfOXHQgKRjiWy1kvZt2O6Qr1L54MsAeHUN65evSjhVuq1ZtQaAkpISiktKwD3hRNlJ3RqFmfUCBgPl8aRK4Cl3n55cqsbrUr4LcyuqNl6uqJxHv769E0yUfu5O/4cvxx1mjXqRT0a/nHSkJlFoY7tN951Yt3g5+/zhp7TfpzvLp81mxpUjqVm1NuloqVVUVMQdY/9Elx5deGrk03z0zoykI2UlVWsUZnYZ8DBgwOT4y4AxZnZ5PdcdYmZTzWxqbe3K3IeVnHlp8HWMP/ZKJpx+E3ucfQw7Htwr6UhbrbFjO3Ncj109q3nCZslKimm/725UjHyeSUf/FzWr1tLjwsFJx0q12tpafnrczzm935nstf9e9Nhr16QjZSVtaxTnAvu4e3XmRDMbBnwA3FjXFd19BDACoKSsPDXrc1WV8+nWtcvGy13LO1NVNT/BROm3ev4SANYuXk7FuKl02n93Fk5K/3bcejRqbGeO6/E7fz814xpgTdVi1lZ9wbK3ZgKw4Ol/sNuFJyacKj+sXL6Sd19/lz79+/DpjDlJx6lXqtYogFqgyxamd47n5Z0pU9+hZ8/d6NGjG6WlpZxyymCefmZ80rFSq7hNK0ratt748y5H7suyGRUJp2oSBTe21y1cxpqqxWzzlc4AbH/411j5z8qEU6VXx04daduhLQBlrcs44IgDmDtzbsKpspO2NYqLgBfN7GNgwxLsDvQELkgq1Naoqalh6EVXMvbZhyguKuL+kY/w4Yf/TDpWarXesQOH3XsxEG3amPPE68x/eVrCqZrERRTY2Ab46Ir72PfPF1BUVsLqOZ/z/tDhSUdKrU47deKSW/+TouJiioqMV56ewD9enJx0rKyYp2yvu5kVAf3YdIffFHevyfY20rTpKR88uH3/pCPklVPnPWiNud7Wju20bXpKu5vLliYdIa+Mn/tcneM6bWsUuHstMCnpHCJNTWNb8lXa9lGIiEjKqChERCRIRSEiIkEqChERCVJRiIhIkIpCRESCVBQiIhKkohARkSAVhYiIBKkoREQkSEUhIiJBKgoREQlSUYiISJCKQkREglQUIiISpKIQEZEgFYWIiASpKEREJEhFISIiQeZeeJ/X/kjnMwrvQeXQye9dn3SEvFK6w+51fgh9LlUv+kTjugHadDk86Qh5Zf26yjrHtdYoREQkSEUhIiJBKgoREQlSUYiISJCKQkREglQUIiISpKIQEZEgFYWIiASpKEREJEhFISIiQSoKEREJUlGIiEiQikJERIJUFCIiEqSiEBGRIBWFiIgEqShERCRIRSEiIkEqChERCSpJOkBLcMLk26j+cg1eU4vX1PD8cVclHSlVrvztMCa8NplO223Lk6OHA3Dz7Xfzymv/oKS0hG7lnbnhil/SoX27hJOKnqvGu2vELXx74NF8vnAR+/c+Kuk4DaI1imby8ndvYPwxV6gktuCkgccwfNgNm0w7pG9vnhg1nCce+F96dCvn7lGPJJROMum5arwHHniUb59wRtIxGkVFIYnrs/++dOzQfpNp3zjoQEpKigHYb59eLPh8URLRZDN6rhpv4qv/4IslS5OO0Sja9NQM3J3+D1+OO8wa9SKfjH456Uh55Ylnx3PcUUcmHUOyoOeqMBXMGoWZDTGzqWY29YVVM5OOs4mXBl/H+GOvZMLpN7HH2cew48G9ko6UN+4cOYbi4mJOOPabSUdJROa4vvuBMUnHCWrpz1Uhy6uiMLNz6prn7iPcvY+79zl6m57NGateq+cvAWDt4uVUjJtKp/13TzhRfnjy2eeZ8Npk/ufqSzGzpOPkTLbj+rwfnNacsRqkpTxXLVVeFQVwbdIBGqq4TStK2rbe+PMuR+7LshkVCadKv1cnTeXehx7jT/9zNW1at046Tq7l3bjO1MKeqxbJ3D3pDJsws2l1zQL2dPdW9d3GI53PSM2Datt9Rw6792IArKSYOU+8zvQ//DXhVJs6+b3rE73/S66+kSlvT2Pp0uVs32lbfnbuWdw96hHWVVezbYcOQLST9OpLL0w05walO+ze4H+Zm2JcVy/6JPFxnU/PVZsuhycdYROjR93BkUccwg47dGLBgkVce93N3Hf/w0nH2mj9uso6x3Uai2IBMABYsvks4HV371LfbaSpKPJB0kWRbxpZFFs9rtNQFPkkbUWRdqGiSONRT88A7dz9nc1nmNnfmz2NSNPQuJa8lbqicPdzA/NOb84sIk1F41ryWb7tzBYRkWamohARkSAVhYiIBKkoREQkSEUhIiJBKgoREQlSUYiISJCKQkREglQUIiISpKIQEZEgFYWIiASpKEREJEhFISIiQSoKEREJqvM042Y2Cqj3g1Lc/QdNmkhERFIl9HkUM5sthYiIpFadReHuef2B7yIi0jSy/oQ7MysD9gJ2IPqcXwDc/aUc5BIRkZQw9/o/r93MDgMeA1oBHYDlQHtgrrvvntOEBcTMhrj7iKRz5Astr/yg56lh8nF5ZXvU063ATe7eCVgRf78e+HPOkhWmIUkHyDNaXvlBz1PD5N3yyrYo9gT+sNm0G4GLmzaOiIikTbZFsYxokxPAPDPbG9gOaJeTVCIikhrZFsXjwMD453uBl4E3gb/kIlQBy6vtkimg5ZUf9Dw1TN4tr6x2Zv/blcwOJ1qb+Ju71zZ5KmlyZnYN0NPdz0w6i0gamZkDe7i73kO2mUadwsPdJ7r7OJVE8zKzT83s6KRzZDKzl81soZktN7N3zWxw0pmksJjZlxlftWa2OuPyGXVcp7+ZVTR31kKV1fsozGwidZzOw92PaNJEkm+GAh+6+3ozOwh4wcz2dPd5SQeTwuDuG/eFmtmnwHnu/kJyiVqebNco7gbuyfh6FtgF0JOVBTM7zsxmmNlMM7u8iW7zbDN71cxuNrMlZjbbzI7PmL+bmb1iZivM7HmiN0pmXv9gM3vdzJbGawL94+mHmtkiM+sWX/56fPu9tpTD3ae5+/oNF4FSoNtWPrZ7zexzM3t/a25Hci8XY7sB993KzG4zs6r467Z4WltgHNAlY82ji5n1M7M34jE/z8xuj99I3Fx583dcu3ujvoCewMTGXr+lfAHFwCxgd6AMeBfYu5G39SlwdPzz2UA1cH58Hz8FqvjXfqc3gGFEb5I8AlgBjI7nlQOLiQ5QKAKOiS/vGM//DfAS0AZ4D7ignlzPAGuIiuI5oGgrl9kRwAHA+0k/f/oKPk9NNrYbcJ+Zr4HrgEnATsCOwOvA9fG8/kDFZtc9EDiYaEtKD2A6cFHGfCfaj5er7Hk7rrfmNOOVwH5bcf2Woh8w090/cfd1wMNAU23Hn+Pud7l7DTAS6AzsbGbdgb7AVe6+1t0nAE9nXO9MYKy7j3X3Wnd/HpjKv45suwboCEwmep7vCIVw9xOI3qk/EBjvW7nvKs77xdbchjSLXI7tbJwBXOfun7v7QuBa4Ky6ftnd33T3Se6+3t0/Be4EjmyeqPk9rrPdR/GjzSZtA5xM1OYSVg7MzbhcARzURLc9f8MP7r7KzCA6Gm0HYIm7r8z43Tn8a5PQrsD3zGxQxvxSosOecfdqM7sf+CPwS4//HQpx92pgnJkNNbOZ7v5U4x+W5Ilcju1sdCEa1xvMiadtkZntSbSW3Yfob1gJ0WH+Uo9sTwq4eUuvJFrNu7Vp40gTmQdsZ2ZtM8qiO/86IGEuMMrdz9/Slc2sHLgauA+4xcz6uvvaLO+7BPhK46OLZK2K6J+eD+LL3eNpsOWDb/4XeBs4zd1XmNlFwHdzHbIQZLXpyd2/udnXCe5+pbsvznXAAlDJpjt3u8bTcsbd5xBtSrrWzMrikzpmrj2MBgaZ2QAzKzaz1vHhhF0tWi25n+ighXOJSuf6Ld2PmfUys+PNrI2ZlZrZmUTbYV/J4cOT9Gj2sb2ZMcCVZrajme0A/JpobAMsALY3s44Zv9+e6ISmX8YHZ/y0GbPmtayKwsy2uF3NzD5v2jgFaQqwR3wUUhnwfaA5NsucTrQZ4AuitYMHNsxw97lE25KvABYSrWFcQjQefkG0c/CqeJPTOcA58ZssN2dE+zM+j29nKHCqu7+Vm4ckKZPU2N7gBqJ/iKYRHXTxVjwNd/+IqEg+iY9y6gL8iuh1sQK4C3ikGbPmtWxPM77C3dtvNq0UmO/u2+cqXKEws4HAbURHidzr7r9JNlG6mdkYoqNWdiD6z/Bqd78n0VCyRRrb2cvncR0siow32h1CdLhlpq7AB+4+6N+uKCIiBaO+ndl3E21e6Eu0zXoDJ2pEfbqdiEiBy3bTU694m5+IiLQw2b7h7mdmdmjmhPhUD7c1fSQREUmTbNcoFgLl8bsvN0xrRfSZ2TvlMF+jlJSVN/zc6SJZWr+u0pK4X43rhvnWzvsmHSGvjJ/7XJ3jOts1Ct/C7xY34PoiIpKnsv1DPxG4wcyKAOLv18bTRUSkgGV7Co+hRGcInWdmc4jeNl/Fpu/2FRGRApRVUbh7hZkdQHS2yG5Eh8aeRHR20TpPwiUiIvkv2zUKgO2JTglxNtHpxScSrWmIiEgBCxZFfJqOE4nKYQAwk+j8Kd2BU9xd53oSESlw9e3MXkD04R4zgIPdfW93vx5YF76aiIgUivqKYhqwLdEmp75mtl3OE4mISKoEi8Ld+xN9CM14olP0zjezp4G2RJ+IJiIiBa7e91G4+xx3v97d9wCOIvogm1rgXTO7KdcBRUQkWQ16Z7W7v+ruQ4BdgAsBvUdeRKTANeoUHO6+xt3HuPvxTR1IRETSRedqEhGRIBWFiIgEqShERCRIRSEiIkEqChERCVJRiIhIkIpCRESCVBQiIhKkomgGA47tzwfvT+CjD1/l0kt+nnSc1NPyyh8dO3bgkYdH8P57r/DetL9z8EEHJh0p1U4+7z8Y8cKdjHhhOP91++WUtsqPU+apKHKsqKiIP/7hN5ww6Ez2/fo3OfXUk/jqV/dIOlZqaXnll1uHXcff/vYyX9v3SA448Bimf/Rx0pFSa/tdtuekcwZzwQkXMuTon1BUVET/E/snHSsrKooc69e3N7Nmfcrs2Z9RXV3No4/+lRMHDUg6VmppeeWPDh3ac/hhB3HvfWMAqK6uZtmy5QmnSrfikmJatS6jqLiIVm1a8cWCxUlHykpDPgq1WZhZL2AwUB5PqgSecvfpyaVqvC7luzC3omrj5YrKefTr2zvBROlWyMur0Mb2brt1Z9Gixdxz963st9/evPXWNC7+5a9ZtWp10tFSafH8xTx2518YPWkUa9es5a0Jb/HmhLeSjpWVVK1RmNllwMOAAZPjLwPGmNnl9Vx3iJlNNbOptbUrcx9WpAEaO7bTPK5Liovp3Xtf7rzzAfr2G8DKlau47NILko6VWu06tuPQYw/hB4eezWl9zqD1Nq056j++lXSsrKRtjeJcYB93r86caGbDgA+AG+u6oruPAEYAlJSVey5DNkRV5Xy6de2y8XLX8s5UVc1PMFG6FfDyatTYTuu4hmhtr6JiHpOnvA3A448/y6WXqCjq0vuw3syfu4BlXywD4NVxr7F3n6/y4hMvJZysfqlaoyD6QKQuW5jeOZ6Xd6ZMfYeePXejR49ulJaWcsopg3n6mfFJx0qtAl5eBTe2FyxYSEVFFXvu+RUAvvWtw5g+/Z8Jp0qvhZWf06t3L1q1bgVA72/sz2cfz004VXbStkZxEfCimX0MbFiC3YGeQF7+q1JTU8PQi65k7LMPUVxUxP0jH+HDD/ViqksBL6+LKLCxDTD04qt4YOSfKCsrZfbszzj3vF8mHSm1PnpnBhPHTuTP426npqaGme/PYuxD45KOlRVzT9XaLGZWBPRj0x1+U9y9JtvbSNsquhSW9esqrTHX29qxrXHdMN/aWR/A2RDj5z5X57hO2xoF7l4LTEo6h0hT09iWfJW2fRQiIpIyKgoREQlSUYiISJCKQkREglQUIiISpKIQEZEgFYWIiASpKEREJEhFISIiQSoKEREJUlGIiEiQikJERIJUFCIiEqSiEBGRIBWFiIgEqShERCRIRSEiIkEqChERCUrdR6GKyJatrpqYdIS8suL8c5KOUDC0RiEiIkEqChERCVJRiIhIkIpCRESCVBQiIhKkohARkSAVhYiIBKkoREQkSEUhIiJBKgoREQlSUYiISJCKQkREglQUIiISpKIQEZEgFYWIiASpKEREJEhFISIiQSoKEREJUlGIiEiQikJERIJKkg7QEgw4tj/Dhl1HcVER9943hpt+f0fSkVJNyyu9rvztMCa8NplO223Lk6OHA/CfV/2OTz+rAGDFl1/Svl07/m+knjOAthdcRmmfQ6hdtoTlQ88BoM1pP6K032HgtfiypXz5x9/hSxYnnDTM3D3pDE2upKw8NQ+qqKiI6R9M5LiBp1FRMY9Jb4zlzLN+xvTpHycdLZXyYXmtX1dpSdxv9aJPEh/XU995j23atOGK62/eWBSZfv+nu2jXdht++qMzEki3qRXnn5N0BEr23g9fs5q2Q6/YWBS02QZWrwKg1be/Q3G3XVk1fFiCKSOdnnilznGtTU851q9vb2bN+pTZsz+jurqaRx/9KycOGpB0rNTS8kq3PvvvS8cO7bc4z9157qUJDDymf/OGSrH1H07DV6zYdGJcEgDWqjUkXv/1U1HkWJfyXZhbUbXxckXlPLp02SXBROmm5ZW/3nz3fbbfbjt27VaedJTUa3PGeXS86zHKjjya1WPuSTpOvfKqKMysznVJMxtiZlPNbGpt7crmjCWyVbId13c/MKY5YzXY2Of/zsBjjkw6Rl5Y/eDdLDv/e6x75QVaDzw56Tj1yquiAK6ta4a7j3D3Pu7ep6iobXNmCqqqnE+3rl02Xu5a3pmqqvkJJkq3Frq8shrX5/3gtObM1CDr19fwwiuvc9xRRyQdJa+sm/A8pYekf5ml7qgnM5tW1yxg5+bM0hSmTH2Hnj13o0ePblRWzueUUwZz1g9+nnSs1CrU5VVo43pzk6a+ze67dmWXnXZMOkrqFXUup3ZeJQCl/Q6jtuKzhBPVL3VFQfSiGQAs2Wy6Aa83f5ytU1NTw9CLrmTssw9RXFTE/SMf4cMP/5l0rNQq4OVVEOP6kqtvZMrb01i6dDlHnXQmPzv3LL4zaADjXniF44/un3S81Gn7y19Tus/+WIeObHvXY6x6+D7KDjyYovJuUOvULlzAyuG3JB2zXqk7PNbM7gHuc/dXtzDvIXc/vb7bSNPhsVJ4GnN4bFOM6zQcHptP0nB4bD4JHR6bujUKdz83MK/eF5NIGmlcSz7Lt53ZIiLSzFQUIiISpKIQEZEgFYWIiASpKEREJEhFISIiQSoKEREJUlGIiEiQikJERIJUFCIiEqSiEBGRIBWFiIgEqShERCRIRSEiIkEqChERCVJRiIhIkIpCRESCVBQiIhKkohARkSBz1+e1NxczG+LuI5LOkS+0vPKDnqeGycflpTWK5jUk6QB5RssrP+h5api8W14qChERCVJRiIhIkIqieeXVdskU0PLKD3qeGibvlpd2ZouISJDWKEREJEhFISIiQSqKZmBmx5nZDDObaWaXJ50n7czsXjP73MzeTzqLhGlsZy+fx7WKIsfMrBi4Azge2Bs4zcz2TjZV6t0PHJd0CAnT2G6w+8nTca2iyL1+wEx3/8Td1wEPA4MTzpRq7j4B+CLpHFIvje0GyOdxraLIvXJgbsbliniaSL7T2G4hVBQiIhKkosi9SqBbxuWu8TSRfKex3UKoKHJvCrCHme1mZmXA94GnEs4k0hQ0tlsIFUWOuft64ALgb8B04FF3/yDZVOlmZmOAN4C9zKzCzM5NOpP8O43thsnnca1TeIiISJDWKEREJEhFISIiQSoKEREJUlGIiEiQikKkCZjZ/WZ2Q/zz4WY2o5nu182sZ3Pcl7RcKgppUczsUzNbbWZfmtmC+A98u6a8D3ef6O57ZZHlbDN7tSnvWyQXVBTSEg1y93bAAUAf4MrMmWZWkkgqkZRSUUiL5e6VwDjga/EmnJ+b2cfAxwBmdoKZvWNmS83sdTPbb8N1zay3mb1lZivM7BGgdca8/mZWkXG5m5k9bmYLzWyxmd1uZl8FhgOHxGs3S+PfbWVmN5vZZ/Eaz3Aza5NxW5eY2TwzqzKzH+V4EYkAKgppwcysGzAQeDuedBJwELC3mfUG7gV+DGwP3Ak8Ff8hLwOeBEYBnYDHgO/UcR/FwDPAHKAH0dlVH3b36cBPgDfcvZ27bxtf5UZgT2B/oGf8+7+Ob+s44FfAMcAewNFbvRBEsqCikJboyfg/+FeBV4DfxtN/5+5fuPtqYAhwp7v/w91r3H0ksBY4OP4qBW5z92p3/wvReY+2pB/QBbjE3Ve6+xp33+J+CTOz+H4vjnOsiLN9P/6VU4D73P19d18JXLM1C0EkW9oWKy3RSe7+QuaE6G/0Jp+tsCvwQzO7MGNaGdEffQcqfdPz38yp4766AXPi8yLVZ0dgG+DNOA+AAcXxz12AN7O4T5EmpTUKkX/J/MM/F/iNu2+b8bWNu48B5gHllvHXHOhex23OBbrXsYN88xOtLQJWA/tk3GfHeMc78f1mnta7rvsUaVIqCpEtuwv4iZkdZJG2ZvZtM2tPdAbQ9cAvzKzUzE4m2sS0JZOJ/sDfGN9GazP7RjxvAdA13ueBu9fG93urme0EYGblZjYg/v1HgbPNbG8z2wa4OgePW+TfqChEtsDdpwLnA7cDS4CZwNnxvHXAyfHlL4BTgcfruJ0aYBDRjunPiD4u9NR49kvAB8B8M1sUT7ssvq9JZrYceAHYK76tccBt8fVmxt9Fck6nGRcRkSCtUYiISJCKQkREglQUIiISpKIQEZEgFYWIiASpKEREJEhFISIiQSoKEREJ+n+puScDsxQlQwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}